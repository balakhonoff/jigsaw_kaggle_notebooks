{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch BERT baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, I convert https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic into pytorch version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please upvote the kernel if you find it helpful**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are not allowed to use internet I've created required datasets and commands to setup Hugging Face Transformers setup in offline mode. You can find the required github codebases in the datasets.\n",
    "\n",
    "* sacremoses dependency - https://www.kaggle.com/axel81/sacremoses\n",
    "* transformers - https://www.kaggle.com/axel81/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# !pip install ./sacremoses/sacremoses-master/\n",
    "# !pip install ./transformers/transformers-master/\n",
    "\n",
    "STRIDE = 1\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        ipy_str = str(type(get_ipython()))\n",
    "        if 'zmqshell' in ipy_str:\n",
    "            return True\n",
    "        \n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports\n",
    "\n",
    "I've added imports that will be used in training too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from random import shuffle as shfl\n",
    "from auc import MyAUCCallback\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max.columns', 500)\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] ='1'\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-10.1/lib64'\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from shutil import copyfile\n",
    "from catalyst.dl import SupervisedRunner, AlchemyLogger, CriterionCallback\n",
    "from catalyst.dl.callbacks.metrics import AUCCallback\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler,Dataset\n",
    "batch_size =50\n",
    "token = \"d1dd16f08d518293bcbeddd313b49aa4\"\n",
    "DATA_DIR = '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on desktop\n"
     ]
    }
   ],
   "source": [
    "if os.uname()[1] == 'kb-Z370P-D3':\n",
    "    # desktop\n",
    "    LOG_PATH = '/media/ssd/logs/jigsaw'\n",
    "    SERVER = False\n",
    "    print('Working on desktop')\n",
    "elif os.uname()[1] == 'kb-server':\n",
    "    # server\n",
    "    LOG_PATH = '/home/kb/logs/jigsaw'\n",
    "    SERVER = True\n",
    "    print('Working on server')\n",
    "else:\n",
    "    raise Exception('which hostname???')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\[\n",
      "\n",
      "<>:5: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\d\n",
      "\n",
      "<>:6: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\(\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text = text.fillna(\"fillna\")#.str.lower()\n",
    "    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\(http://.*?\\s\\(http://.*\\)\",'',str(x)))\n",
    "    return text\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"havent\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"thats\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"theres\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"theyre\":  \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"}\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = tokenizer.tokenize(x)\n",
    "    return x\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x).replace(\"\\n\",\"\")\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def clean_data(df, columns: list):\n",
    "    for col in columns:\n",
    "        pass\n",
    "        df[col] = df[col].apply(lambda x: clean_numbers(x))\n",
    "        df[col] = clean(df[col])\n",
    "        df[col] = df[col].apply(lambda x: clean_text(x)) \n",
    "        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n",
    "# #         df[col] = df[col].apply(lambda x: handle_contractions(x))  \n",
    "#         df[col] = df[col].apply(lambda x: fix_quote(x))   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
    "train2 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\n",
    "train2.toxic = train2.toxic.round().astype(int)\n",
    "\n",
    "df_valid = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train1 with a subset of train2\n",
    "df_train = pd.concat([\n",
    "    train1[['comment_text', 'toxic']],\n",
    "    train2[['comment_text', 'toxic']].query('toxic==1'),\n",
    "    train2[['comment_text', 'toxic']].query('toxic==0').sample(n=100000, random_state=0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>5743</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Now I also saw your change will be written onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>merhaba.revizyo work to my attention in this u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>2457</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>I think you're wrong, this can be a real event...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>3211</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>Add: This comment Jaqen. Before sawing the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>6181</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>He had seen the child page, but have not yet e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id lang  toxic                                       comment_text\n",
       "5743  5743   tr      0  Now I also saw your change will be written onl...\n",
       "473    473   tr      0  merhaba.revizyo work to my attention in this u...\n",
       "2457  2457   tr      0  I think you're wrong, this can be a real event...\n",
       "3211  3211   it      0  Add: This comment Jaqen. Before sawing the thr...\n",
       "6181  6181   es      0  He had seen the child page, but have not yet e..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_en = shuffle(pd.read_csv(DATA_DIR + 'validation_en.csv'))\n",
    "df_valid_en = df_valid_en.drop(['comment_text'],axis=1).rename(columns={'comment_text_en':'comment_text'})\n",
    "# df_valid_en = clean_data(df_valid_en, ['comment_text'])\n",
    "df_valid_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">es</th>\n",
       "      <th>0</th>\n",
       "      <td>2078</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">it</th>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">tr</th>\n",
       "      <th>0</th>\n",
       "      <td>2680</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  comment_text\n",
       "lang toxic                    \n",
       "es   0      2078          2078\n",
       "     1       422           422\n",
       "it   0      2012          2012\n",
       "     1       488           488\n",
       "tr   0      2680          2680\n",
       "     1       320           320"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_en.groupby(['lang', 'toxic']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.groupby(['lang']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  toxic\n",
       "0   0    0.5\n",
       "1   1    0.5\n",
       "2   2    0.5\n",
       "3   3    0.5\n",
       "4   4    0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'toxic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import time\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "#import torch.utils.data as data\n",
    "from torchvision import datasets, models, transforms\n",
    "from transformers import *\n",
    "import random\n",
    "from math import floor, ceil\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "MAX_LEN = 192#192#512\n",
    "SEP_TOKEN_ID = 102\n",
    "\n",
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train_mode=True, labeled=True):\n",
    "        \n",
    "            \n",
    "        self.df = df\n",
    "        if train_mode:\n",
    "            self.labels = df.toxic.values\n",
    "            self.toxic_inds = np.where(self.labels==1)[0]\n",
    "            self.normal_inds = np.where(self.labels==0)[0]            \n",
    "            \n",
    "            \n",
    "            print(f'Here is {len(self.labels)} samples, {len(self.toxic_inds)} samples and {len(self.normal_inds)} samples')\n",
    "            print(f'Class balance is {len(self.toxic_inds)/len(self.labels):.2f}')\n",
    "            \n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')#, \n",
    "#                                                              return_attention_masks=False, \n",
    "#                                                                 return_token_type_ids=False,\n",
    "#                                                                 pad_to_max_length=True,\n",
    "#                                                                 max_length=MAX_LEN)\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased',\n",
    "#                                                                 do_lower_case=False,\n",
    "#                                                                 do_basic_tokenize=True,\n",
    "#                                                                 never_split=None,\n",
    "#                                                                 unk_token='[UNK]',\n",
    "#                                                                 sep_token='[SEP]',\n",
    "#                                                                 pad_token='[PAD]',\n",
    "#                                                                 cls_token='[CLS]',\n",
    "#                                                                 mask_token='[MASK]',\n",
    "#                                                                 tokenize_chinese_chars=True,)\n",
    "        #distil\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        token_ids = self.get_token_ids(row)\n",
    "        \n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return {'features': token_ids, 'targets': labels}\n",
    "\n",
    "        else:\n",
    "            return {'features': token_ids}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def trim_input(self, text, max_sequence_length=MAX_LEN):\n",
    "        t = self.tokenizer.tokenize(text)\n",
    "        t_len = len(t)\n",
    "\n",
    "        if t_len + 2 > max_sequence_length:\n",
    "\n",
    "            t_new_len = int(max_sequence_length) - 2\n",
    "\n",
    "            t = t[:t_new_len]\n",
    "\n",
    "        return t\n",
    "        \n",
    "    def get_token_ids(self, row):\n",
    "        token_ids = self.tokenizer.encode(row.comment_text, max_length=MAX_LEN)\n",
    "#         print(token_ids)\n",
    "#         print(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            ids = torch.tensor(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "        else:\n",
    "            ids = torch.tensor(token_ids[:MAX_LEN])\n",
    "#         print(ids.shape)\n",
    "        \n",
    "#         t_tokens = self.trim_input(row.comment_text)\n",
    "\n",
    "# #         tokens = ['[CLS]'] + t_tokens  + ['[SEP]']+ t_tokens[-1::-1]+ ['[SEP]']\n",
    "#         tokens = ['[CLS]'] + t_tokens  + ['[SEP]']\n",
    "#         token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "#         if len(token_ids) < MAX_LEN:\n",
    "#             token_ids += [0] * (MAX_LEN - len(token_ids))\n",
    "            \n",
    "#         ids = torch.tensor(token_ids)\n",
    "#         print(ids.shape, torch.tensor(token_ids).shape)\n",
    "#         print(torch.tensor(token_ids))\n",
    "#         print(len(ids))\n",
    "        return ids\n",
    "\n",
    "    def get_label(self, row):\n",
    "#         label = torch.tensor(row[target_column].astype(np.long))\n",
    "        label = np.round(row[target_column])\n",
    "        return torch.tensor([1-label, label]).float()\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "\n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[1] for x in batch])\n",
    "            return {'features': token_ids, 'targets': labels}\n",
    "        else:\n",
    "            return {'features': token_ids}\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(QuestModel, self).__init__()\n",
    "        self.model_name = 'QuestModel'\n",
    "        \n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "#        self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base', \n",
    "                                                          #output_hidden_states=False, \n",
    "                                                          #output_attentions=False)\n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "        self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')#,\n",
    "#                                                           output_hidden_states=False, \n",
    "#                                                           output_attentions=False)\n",
    "    \n",
    "        self.fc = nn.Linear(768, n_classes)\n",
    "#         self.fc = nn.Linear(1024, n_classes)\n",
    "\n",
    "    def forward(self, ids):\n",
    "#         attention_mask = (ids > 0)\n",
    "#         print(ids.shape)\n",
    "        layers = self.bert_model(input_ids=ids)#, attention_mask=attention_mask)\n",
    "#         print(layers[0].shape)\n",
    "#         out = F.dropout(layers[0][:, 0, :], p=0.2, training=self.training)\n",
    "#         print(layers[0].shape)\n",
    "#         print([l.shape for l in layers])\n",
    "#         out = F.dropout(layers[-1][:, 0, :], p=0.35, training=self.training)\n",
    "        out = F.dropout(layers[0][:, 0, :], p=0.2, training=self.training)\n",
    "        logit = self.fc(out)#.unsqueeze(1)\n",
    "        return logit #, 'for_auc': logit[:, 1]}#[:,1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, dataset):\n",
    "       \n",
    "        self.toxic_inds = dataset.toxic_inds.copy()\n",
    "        self.normal_inds = dataset.normal_inds.copy()\n",
    "        \n",
    "        self.num_samples = 2*min(len(self.toxic_inds), len(self.normal_inds))\n",
    "        \n",
    "        shfl(self.toxic_inds)\n",
    "        shfl(self.normal_inds)\n",
    "        \n",
    "        self.inds = []\n",
    "        for i in range(min(len(self.toxic_inds), len(self.normal_inds))):\n",
    "            self.inds.append(self.normal_inds[i%len(self.normal_inds)])\n",
    "            self.inds.append(self.toxic_inds[i%len(self.toxic_inds)])\n",
    "\n",
    "    def __iter__(self):\n",
    "        #print ('\\tcalling Sampler:__iter__')\n",
    "        return iter(self.inds)\n",
    "\n",
    "    def __len__(self):\n",
    "        #print ('\\tcalling Sampler:__len__')\n",
    "        return self.num_samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "\n",
    "        # define custom callback\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        if self.callback_get_label:\n",
    "            return self.callback_get_label(dataset, idx)\n",
    "        else:\n",
    "            dataset.labels[idx]\n",
    "#             raise NotImplementedError\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(to_balance=True, shuffle_before=True):\n",
    "    if SERVER:\n",
    "        workers=1\n",
    "    else:\n",
    "        workers = 6    \n",
    "    \n",
    "#     train_dataset = QuestDataset(df_train.iloc[::STRIDE], train_mode=True)\n",
    "    \n",
    "    if STRIDE == 1:\n",
    "        train_dataset = QuestDataset(df_train.iloc[::STRIDE], train_mode=True)\n",
    "    elif STRIDE<=10:\n",
    "        df_train_pos = df_train[df_train[target_column]==1].reset_index(drop=True)\n",
    "        df_train_neg = df_train[df_train[target_column]==0].reset_index(drop=True).iloc[::STRIDE]\n",
    "        train_dataset = QuestDataset(df_train_pos.append(df_train_neg).reset_index(drop=True), train_mode=True)\n",
    "    else:\n",
    "        df_train_pos = df_train[df_train[target_column]==1].reset_index(drop=True).iloc[::int(STRIDE/10)]\n",
    "        df_train_neg = df_train[df_train[target_column]==0].reset_index(drop=True).iloc[::STRIDE]\n",
    "        train_dataset = QuestDataset(df_train_pos.append(df_train_neg).reset_index(drop=True), train_mode=True)\n",
    "        \n",
    "    \n",
    "    valid_dataset = QuestDataset(df_valid, train_mode=False)\n",
    "   \n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        num_workers=workers,\n",
    "        sampler=BalancedSampler(train_dataset) if to_balance else None,#ImbalancedDatasetSampler(train_dataset) if to_balance else None,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        num_workers=workers,\n",
    "        batch_size=batch_size,\n",
    "    )    \n",
    "    \n",
    "       \n",
    "    loaders = {}\n",
    "    loaders['train'] = train_loader\n",
    "    \n",
    "    loaders['valid'] = valid_loader\n",
    "    \n",
    "    \n",
    "    for i in ['es', 'it', 'tr']:\n",
    "        df = df_valid\n",
    "        df = df[df['lang']==i]\n",
    "\n",
    "        loaders['valid_'+ i] = DataLoader(\n",
    "            QuestDataset(df, train_mode=False),\n",
    "            num_workers=workers,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is 435775 samples, 133610 samples and 302165 samples\n",
      "Class balance is 0.31\n",
      "----------------Experiment: simple\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "1/300 * Epoch (train):   0% 1/5345 [00:00<57:13,  1.56it/s, loss=0.053]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning:\n",
      "\n",
      "This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 * Epoch (train):  37% 1992/5345 [08:03<13:29,  4.14it/s, loss=0.017]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "1/300 * Epoch (train):  67% 3593/5345 [14:33<07:06,  4.10it/s, loss=0.019]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "1/300 * Epoch (train):  85% 4537/5345 [18:23<03:17,  4.10it/s, loss=0.031]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "1/300 * Epoch (train): 100% 5345/5345 [21:40<00:00,  4.11it/s, loss=0.010]\n",
      "1/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.94it/s, loss=0.018]\n",
      "1/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.83it/s, loss=0.028]\n",
      "1/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.045]\n",
      "1/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.99it/s, loss=0.020]\n",
      "[2020-05-01 19:29:55,475] \n",
      "1/300 * Epoch 1 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): auc/_mean=0.9372 | auc/class_0=0.9372 | loss=0.0228\n",
      "1/300 * Epoch 1 (valid): auc/_mean=0.8695 | auc/class_0=0.8695 | es_auc/_mean=0.8670 | es_auc/class_0=0.8670 | es_loss=0.0290 | it_auc/_mean=0.8234 | it_auc/class_0=0.8234 | it_loss=0.0373 | loss=0.0301 | tr_auc/_mean=0.9166 | tr_auc/class_0=0.9166 | tr_loss=0.0249\n",
      "1/300 * Epoch 1 (valid_es): auc/_mean=0.8670 | auc/class_0=0.8670 | loss=0.0290\n",
      "1/300 * Epoch 1 (valid_it): auc/_mean=0.8234 | auc/class_0=0.8234 | loss=0.0373\n",
      "1/300 * Epoch 1 (valid_tr): auc/_mean=0.9166 | auc/class_0=0.9166 | loss=0.0249\n",
      "2/300 * Epoch (train):  25% 1330/5345 [05:23<16:17,  4.11it/s, loss=0.007]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2/300 * Epoch (train): 100% 5345/5345 [21:41<00:00,  4.11it/s, loss=0.007]\n",
      "2/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.78it/s, loss=0.022]\n",
      "2/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.53it/s, loss=0.021]\n",
      "2/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.31it/s, loss=0.037]\n",
      "2/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.54it/s, loss=0.030]\n",
      "[2020-05-01 19:52:33,783] \n",
      "2/300 * Epoch 2 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): auc/_mean=0.9783 | auc/class_0=0.9783 | loss=0.0136\n",
      "2/300 * Epoch 2 (valid): auc/_mean=0.8618 | auc/class_0=0.8618 | es_auc/_mean=0.8710 | es_auc/class_0=0.8710 | es_loss=0.0302 | it_auc/_mean=0.8314 | it_auc/class_0=0.8314 | it_loss=0.0397 | loss=0.0361 | tr_auc/_mean=0.8802 | tr_auc/class_0=0.8802 | tr_loss=0.0381\n",
      "2/300 * Epoch 2 (valid_es): auc/_mean=0.8710 | auc/class_0=0.8710 | loss=0.0302\n",
      "2/300 * Epoch 2 (valid_it): auc/_mean=0.8314 | auc/class_0=0.8314 | loss=0.0397\n",
      "2/300 * Epoch 2 (valid_tr): auc/_mean=0.8802 | auc/class_0=0.8802 | loss=0.0381\n",
      "3/300 * Epoch (train):  11% 614/5345 [02:30<19:17,  4.09it/s, loss=0.007]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "3/300 * Epoch (train):  73% 3912/5345 [15:54<05:49,  4.10it/s, loss=0.013]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "3/300 * Epoch (train): 100% 5345/5345 [21:43<00:00,  4.10it/s, loss=0.007]\n",
      "3/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.97it/s, loss=0.022]\n",
      "3/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.75it/s, loss=0.026]\n",
      "3/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.036]\n",
      "3/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.034]\n",
      "[2020-05-01 20:15:03,827] \n",
      "3/300 * Epoch 3 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): auc/_mean=0.9836 | auc/class_0=0.9836 | loss=0.0117\n",
      "3/300 * Epoch 3 (valid): auc/_mean=0.8683 | auc/class_0=0.8683 | es_auc/_mean=0.8703 | es_auc/class_0=0.8703 | es_loss=0.0320 | it_auc/_mean=0.8451 | it_auc/class_0=0.8451 | it_loss=0.0382 | loss=0.0363 | tr_auc/_mean=0.8873 | tr_auc/class_0=0.8873 | tr_loss=0.0384\n",
      "3/300 * Epoch 3 (valid_es): auc/_mean=0.8703 | auc/class_0=0.8703 | loss=0.0320\n",
      "3/300 * Epoch 3 (valid_it): auc/_mean=0.8451 | auc/class_0=0.8451 | loss=0.0382\n",
      "3/300 * Epoch 3 (valid_tr): auc/_mean=0.8873 | auc/class_0=0.8873 | loss=0.0384\n",
      "4/300 * Epoch (train):  50% 2650/5345 [10:44<10:57,  4.10it/s, loss=0.015]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "4/300 * Epoch (train):  92% 4924/5345 [19:57<01:42,  4.11it/s, loss=0.010]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "4/300 * Epoch (train): 100% 5345/5345 [21:40<00:00,  4.11it/s, loss=0.008]\n",
      "4/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.02it/s, loss=0.027]\n",
      "4/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.82it/s, loss=0.021]\n",
      "4/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.72it/s, loss=0.036]\n",
      "4/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.00it/s, loss=0.044]\n",
      "[2020-05-01 20:37:30,677] \n",
      "4/300 * Epoch 4 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): auc/_mean=0.9877 | auc/class_0=0.9877 | loss=0.0101\n",
      "4/300 * Epoch 4 (valid): auc/_mean=0.8454 | auc/class_0=0.8454 | es_auc/_mean=0.8603 | es_auc/class_0=0.8603 | es_loss=0.0405 | it_auc/_mean=0.8267 | it_auc/class_0=0.8267 | it_loss=0.0516 | loss=0.0503 | tr_auc/_mean=0.8357 | tr_auc/class_0=0.8357 | tr_loss=0.0573\n",
      "4/300 * Epoch 4 (valid_es): auc/_mean=0.8603 | auc/class_0=0.8603 | loss=0.0405\n",
      "4/300 * Epoch 4 (valid_it): auc/_mean=0.8267 | auc/class_0=0.8267 | loss=0.0516\n",
      "4/300 * Epoch 4 (valid_tr): auc/_mean=0.8357 | auc/class_0=0.8357 | loss=0.0573\n",
      "5/300 * Epoch (train):   7% 361/5345 [01:27<20:12,  4.11it/s, loss=0.014]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "5/300 * Epoch (train):  77% 4126/5345 [16:43<04:57,  4.10it/s, loss=0.018]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "5/300 * Epoch (train): 100% 5345/5345 [21:40<00:00,  4.11it/s, loss=0.008]    \n",
      "5/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.91it/s, loss=0.032]\n",
      "5/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.74it/s, loss=0.020]\n",
      "5/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.51it/s, loss=0.043]\n",
      "5/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.90it/s, loss=0.047]\n",
      "[2020-05-01 20:59:58,977] \n",
      "5/300 * Epoch 5 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): auc/_mean=0.9910 | auc/class_0=0.9910 | loss=0.0086\n",
      "5/300 * Epoch 5 (valid): auc/_mean=0.8266 | auc/class_0=0.8266 | es_auc/_mean=0.8526 | es_auc/class_0=0.8526 | es_loss=0.0471 | it_auc/_mean=0.8291 | it_auc/class_0=0.8291 | it_loss=0.0599 | loss=0.0578 | tr_auc/_mean=0.7551 | tr_auc/class_0=0.7551 | tr_loss=0.0650\n",
      "5/300 * Epoch 5 (valid_es): auc/_mean=0.8526 | auc/class_0=0.8526 | loss=0.0471\n",
      "5/300 * Epoch 5 (valid_it): auc/_mean=0.8291 | auc/class_0=0.8291 | loss=0.0599\n",
      "5/300 * Epoch 5 (valid_tr): auc/_mean=0.7551 | auc/class_0=0.7551 | loss=0.0650\n",
      "6/300 * Epoch (train):  22% 1161/5345 [04:42<16:58,  4.11it/s, loss=0.011]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "6/300 * Epoch (train): 100% 5345/5345 [21:41<00:00,  4.11it/s, loss=0.006]    \n",
      "6/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.83it/s, loss=0.035]\n",
      "6/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.45it/s, loss=0.034]\n",
      "6/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.35it/s, loss=0.054]\n",
      "6/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.69it/s, loss=0.049]\n",
      "[2020-05-01 21:22:26,878] \n",
      "6/300 * Epoch 6 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): auc/_mean=0.9937 | auc/class_0=0.9937 | loss=0.0072\n",
      "6/300 * Epoch 6 (valid): auc/_mean=0.8547 | auc/class_0=0.8547 | es_auc/_mean=0.8637 | es_auc/class_0=0.8637 | es_loss=0.0525 | it_auc/_mean=0.8342 | it_auc/class_0=0.8342 | it_loss=0.0676 | loss=0.0615 | tr_auc/_mean=0.8535 | tr_auc/class_0=0.8535 | tr_loss=0.0638\n",
      "6/300 * Epoch 6 (valid_es): auc/_mean=0.8637 | auc/class_0=0.8637 | loss=0.0525\n",
      "6/300 * Epoch 6 (valid_it): auc/_mean=0.8342 | auc/class_0=0.8342 | loss=0.0676\n",
      "6/300 * Epoch 6 (valid_tr): auc/_mean=0.8535 | auc/class_0=0.8535 | loss=0.0638\n",
      "7/300 * Epoch (train):  12% 615/5345 [02:30<19:12,  4.10it/s, loss=0.007]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "7/300 * Epoch (train):  17% 902/5345 [03:39<18:02,  4.11it/s, loss=0.007]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/300 * Epoch (train): 100% 5345/5345 [21:42<00:00,  4.11it/s, loss=3.998e-04]\n",
      "7/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.96it/s, loss=0.035]\n",
      "7/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.70it/s, loss=0.022]\n",
      "7/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.80it/s, loss=0.076]\n",
      "7/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.99it/s, loss=0.054]\n",
      "[2020-05-01 21:44:54,842] \n",
      "7/300 * Epoch 7 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): auc/_mean=0.9957 | auc/class_0=0.9957 | loss=0.0060\n",
      "7/300 * Epoch 7 (valid): auc/_mean=0.8525 | auc/class_0=0.8525 | es_auc/_mean=0.8583 | es_auc/class_0=0.8583 | es_loss=0.0657 | it_auc/_mean=0.8248 | it_auc/class_0=0.8248 | it_loss=0.0859 | loss=0.0747 | tr_auc/_mean=0.8704 | tr_auc/class_0=0.8704 | tr_loss=0.0730\n",
      "7/300 * Epoch 7 (valid_es): auc/_mean=0.8583 | auc/class_0=0.8583 | loss=0.0657\n",
      "7/300 * Epoch 7 (valid_it): auc/_mean=0.8248 | auc/class_0=0.8248 | loss=0.0859\n",
      "7/300 * Epoch 7 (valid_tr): auc/_mean=0.8704 | auc/class_0=0.8704 | loss=0.0730\n",
      "8/300 * Epoch (train):   4% 205/5345 [00:50<20:46,  4.12it/s, loss=4.527e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "8/300 * Epoch (train):  81% 4356/5345 [17:39<04:00,  4.11it/s, loss=0.002]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "8/300 * Epoch (train): 100% 5345/5345 [21:40<00:00,  4.11it/s, loss=8.198e-04]\n",
      "8/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.96it/s, loss=0.036]\n",
      "8/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.75it/s, loss=0.031]\n",
      "8/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.76it/s, loss=0.089]\n",
      "8/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.01it/s, loss=0.047]\n",
      "[2020-05-01 22:07:20,951] \n",
      "8/300 * Epoch 8 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): auc/_mean=0.9971 | auc/class_0=0.9971 | loss=0.0049\n",
      "8/300 * Epoch 8 (valid): auc/_mean=0.8470 | auc/class_0=0.8470 | es_auc/_mean=0.8597 | es_auc/class_0=0.8597 | es_loss=0.0636 | it_auc/_mean=0.8233 | it_auc/class_0=0.8233 | it_loss=0.0776 | loss=0.0654 | tr_auc/_mean=0.8389 | tr_auc/class_0=0.8389 | tr_loss=0.0566\n",
      "8/300 * Epoch 8 (valid_es): auc/_mean=0.8597 | auc/class_0=0.8597 | loss=0.0636\n",
      "8/300 * Epoch 8 (valid_it): auc/_mean=0.8233 | auc/class_0=0.8233 | loss=0.0776\n",
      "8/300 * Epoch 8 (valid_tr): auc/_mean=0.8389 | auc/class_0=0.8389 | loss=0.0566\n",
      "9/300 * Epoch (train):   3% 136/5345 [00:33<21:02,  4.13it/s, loss=0.004]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "9/300 * Epoch (train): 100% 5345/5345 [21:36<00:00,  4.12it/s, loss=1.629e-04]\n",
      "9/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.96it/s, loss=0.043]\n",
      "9/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.79it/s, loss=0.043]\n",
      "9/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.82it/s, loss=0.089]\n",
      "9/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.054]\n",
      "[2020-05-01 22:29:43,958] \n",
      "9/300 * Epoch 9 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): auc/_mean=0.9981 | auc/class_0=0.9981 | loss=0.0040\n",
      "9/300 * Epoch 9 (valid): auc/_mean=0.8553 | auc/class_0=0.8553 | es_auc/_mean=0.8539 | es_auc/class_0=0.8539 | es_loss=0.0718 | it_auc/_mean=0.8214 | it_auc/class_0=0.8214 | it_loss=0.0934 | loss=0.0773 | tr_auc/_mean=0.8798 | tr_auc/class_0=0.8798 | tr_loss=0.0684\n",
      "9/300 * Epoch 9 (valid_es): auc/_mean=0.8539 | auc/class_0=0.8539 | loss=0.0718\n",
      "9/300 * Epoch 9 (valid_it): auc/_mean=0.8214 | auc/class_0=0.8214 | loss=0.0934\n",
      "9/300 * Epoch 9 (valid_tr): auc/_mean=0.8798 | auc/class_0=0.8798 | loss=0.0684\n",
      "10/300 * Epoch (train):   0% 17/5345 [00:04<21:33,  4.12it/s, loss=0.003]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "10/300 * Epoch (train):  22% 1166/5345 [04:43<16:55,  4.11it/s, loss=9.878e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "10/300 * Epoch (train): 100% 5345/5345 [21:38<00:00,  4.11it/s, loss=3.379e-04]\n",
      "10/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.97it/s, loss=0.037]\n",
      "10/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.71it/s, loss=0.054]\n",
      "10/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.095]\n",
      "10/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.056]\n",
      "[2020-05-01 22:52:09,235] \n",
      "10/300 * Epoch 10 (_base): lr=1.000e-05 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): auc/_mean=0.9987 | auc/class_0=0.9987 | loss=0.0034\n",
      "10/300 * Epoch 10 (valid): auc/_mean=0.8658 | auc/class_0=0.8658 | es_auc/_mean=0.8620 | es_auc/class_0=0.8620 | es_loss=0.0668 | it_auc/_mean=0.8335 | it_auc/class_0=0.8335 | it_loss=0.0838 | loss=0.0695 | tr_auc/_mean=0.8975 | tr_auc/class_0=0.8975 | tr_loss=0.0597\n",
      "10/300 * Epoch 10 (valid_es): auc/_mean=0.8620 | auc/class_0=0.8620 | loss=0.0668\n",
      "10/300 * Epoch 10 (valid_it): auc/_mean=0.8335 | auc/class_0=0.8335 | loss=0.0838\n",
      "10/300 * Epoch 10 (valid_tr): auc/_mean=0.8975 | auc/class_0=0.8975 | loss=0.0597\n",
      "11/300 * Epoch (train):  10% 525/5345 [02:07<19:30,  4.12it/s, loss=7.904e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "11/300 * Epoch (train):  12% 632/5345 [02:33<19:04,  4.12it/s, loss=2.957e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "11/300 * Epoch (train):  20% 1067/5345 [04:19<17:16,  4.13it/s, loss=0.004]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "11/300 * Epoch (train): 100% 5345/5345 [21:38<00:00,  4.12it/s, loss=1.021e-04]\n",
      "11/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.99it/s, loss=0.043]\n",
      "11/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.86it/s, loss=0.045]\n",
      "11/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.84it/s, loss=0.115]\n",
      "11/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.04it/s, loss=0.068]\n",
      "[2020-05-01 23:14:33,793] \n",
      "11/300 * Epoch 11 (_base): lr=2.500e-06 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): auc/_mean=0.9991 | auc/class_0=0.9991 | loss=0.0028\n",
      "11/300 * Epoch 11 (valid): auc/_mean=0.8521 | auc/class_0=0.8521 | es_auc/_mean=0.8505 | es_auc/class_0=0.8505 | es_loss=0.0789 | it_auc/_mean=0.8115 | it_auc/class_0=0.8115 | it_loss=0.1034 | loss=0.0834 | tr_auc/_mean=0.8847 | tr_auc/class_0=0.8847 | tr_loss=0.0705\n",
      "11/300 * Epoch 11 (valid_es): auc/_mean=0.8505 | auc/class_0=0.8505 | loss=0.0789\n",
      "11/300 * Epoch 11 (valid_it): auc/_mean=0.8115 | auc/class_0=0.8115 | loss=0.1034\n",
      "11/300 * Epoch 11 (valid_tr): auc/_mean=0.8847 | auc/class_0=0.8847 | loss=0.0705\n",
      "12/300 * Epoch (train):  75% 4012/5345 [16:15<05:26,  4.09it/s, loss=1.802e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "12/300 * Epoch (train):  75% 4023/5345 [16:18<05:21,  4.12it/s, loss=2.140e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "12/300 * Epoch (train): 100% 5345/5345 [21:40<00:00,  4.11it/s, loss=5.592e-06]\n",
      "12/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.82it/s, loss=0.038]\n",
      "12/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.56it/s, loss=0.076]\n",
      "12/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.45it/s, loss=0.108]\n",
      "12/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.85it/s, loss=0.079]\n",
      "[2020-05-01 23:37:00,417] \n",
      "12/300 * Epoch 12 (_base): lr=2.500e-06 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): auc/_mean=0.9996 | auc/class_0=0.9996 | loss=0.0019\n",
      "12/300 * Epoch 12 (valid): auc/_mean=0.8703 | auc/class_0=0.8703 | es_auc/_mean=0.8660 | es_auc/class_0=0.8660 | es_loss=0.0836 | it_auc/_mean=0.8374 | it_auc/class_0=0.8374 | it_loss=0.1039 | loss=0.0854 | tr_auc/_mean=0.9006 | tr_auc/class_0=0.9006 | tr_loss=0.0715\n",
      "12/300 * Epoch 12 (valid_es): auc/_mean=0.8660 | auc/class_0=0.8660 | loss=0.0836\n",
      "12/300 * Epoch 12 (valid_it): auc/_mean=0.8374 | auc/class_0=0.8374 | loss=0.1039\n",
      "12/300 * Epoch 12 (valid_tr): auc/_mean=0.9006 | auc/class_0=0.9006 | loss=0.0715\n",
      "13/300 * Epoch (train):  16% 856/5345 [03:27<18:07,  4.13it/s, loss=0.001]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "13/300 * Epoch (train):  54% 2908/5345 [11:45<09:52,  4.12it/s, loss=1.335e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/300 * Epoch (train): 100% 5345/5345 [21:37<00:00,  4.12it/s, loss=1.128e-05]\n",
      "13/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.05it/s, loss=0.035]\n",
      "13/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.79it/s, loss=0.063]\n",
      "13/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.81it/s, loss=0.115]\n",
      "13/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.072]\n",
      "[2020-05-02 00:00:01,178] \n",
      "13/300 * Epoch 13 (_base): lr=2.500e-06 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): auc/_mean=0.9998 | auc/class_0=0.9998 | loss=0.0014\n",
      "13/300 * Epoch 13 (valid): auc/_mean=0.8728 | auc/class_0=0.8728 | es_auc/_mean=0.8673 | es_auc/class_0=0.8673 | es_loss=0.0831 | it_auc/_mean=0.8347 | it_auc/class_0=0.8347 | it_loss=0.1015 | loss=0.0810 | tr_auc/_mean=0.9099 | tr_auc/class_0=0.9099 | tr_loss=0.0621\n",
      "13/300 * Epoch 13 (valid_es): auc/_mean=0.8673 | auc/class_0=0.8673 | loss=0.0831\n",
      "13/300 * Epoch 13 (valid_it): auc/_mean=0.8347 | auc/class_0=0.8347 | loss=0.1015\n",
      "13/300 * Epoch 13 (valid_tr): auc/_mean=0.9099 | auc/class_0=0.9099 | loss=0.0621\n",
      "14/300 * Epoch (train):   2% 107/5345 [00:26<21:02,  4.15it/s, loss=1.799e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "14/300 * Epoch (train):  52% 2793/5345 [11:16<10:17,  4.13it/s, loss=2.571e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "14/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=2.256e-04]\n",
      "14/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.99it/s, loss=0.039]\n",
      "14/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.68it/s, loss=0.060]\n",
      "14/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.69it/s, loss=0.114]\n",
      "14/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.97it/s, loss=0.074]    \n",
      "[2020-05-02 00:22:57,383] \n",
      "14/300 * Epoch 14 (_base): lr=2.500e-06 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): auc/_mean=0.9998 | auc/class_0=0.9998 | loss=0.0011\n",
      "14/300 * Epoch 14 (valid): auc/_mean=0.8661 | auc/class_0=0.8661 | es_auc/_mean=0.8644 | es_auc/class_0=0.8644 | es_loss=0.0904 | it_auc/_mean=0.8315 | it_auc/class_0=0.8315 | it_loss=0.1113 | loss=0.0898 | tr_auc/_mean=0.8939 | tr_auc/class_0=0.8939 | tr_loss=0.0715\n",
      "14/300 * Epoch 14 (valid_es): auc/_mean=0.8644 | auc/class_0=0.8644 | loss=0.0904\n",
      "14/300 * Epoch 14 (valid_it): auc/_mean=0.8315 | auc/class_0=0.8315 | loss=0.1113\n",
      "14/300 * Epoch 14 (valid_tr): auc/_mean=0.8939 | auc/class_0=0.8939 | loss=0.0715\n",
      "15/300 * Epoch (train):   0% 17/5345 [00:04<21:28,  4.14it/s, loss=5.594e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "15/300 * Epoch (train):  81% 4352/5345 [17:34<04:00,  4.13it/s, loss=2.322e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "15/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.12it/s, loss=6.236e-06]\n",
      "15/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.04it/s, loss=0.044]\n",
      "15/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.071]\n",
      "15/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.80it/s, loss=0.126]\n",
      "15/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.11it/s, loss=0.078]\n",
      "[2020-05-02 00:45:18,998] \n",
      "15/300 * Epoch 15 (_base): lr=2.500e-06 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): auc/_mean=0.9999 | auc/class_0=0.9999 | loss=0.0010\n",
      "15/300 * Epoch 15 (valid): auc/_mean=0.8426 | auc/class_0=0.8426 | es_auc/_mean=0.8580 | es_auc/class_0=0.8580 | es_loss=0.0939 | it_auc/_mean=0.8171 | it_auc/class_0=0.8171 | it_loss=0.1188 | loss=0.0968 | tr_auc/_mean=0.8309 | tr_auc/class_0=0.8309 | tr_loss=0.0808\n",
      "15/300 * Epoch 15 (valid_es): auc/_mean=0.8580 | auc/class_0=0.8580 | loss=0.0939\n",
      "15/300 * Epoch 15 (valid_it): auc/_mean=0.8171 | auc/class_0=0.8171 | loss=0.1188\n",
      "15/300 * Epoch 15 (valid_tr): auc/_mean=0.8309 | auc/class_0=0.8309 | loss=0.0808\n",
      "16/300 * Epoch (train):   0% 20/5345 [00:05<21:26,  4.14it/s, loss=1.424e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "16/300 * Epoch (train):  38% 2010/5345 [08:06<13:26,  4.14it/s, loss=1.717e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "16/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=7.996e-06]\n",
      "16/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.99it/s, loss=0.038]\n",
      "16/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.70it/s, loss=0.061]\n",
      "16/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.123]\n",
      "16/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.89it/s, loss=0.074]\n",
      "[2020-05-02 01:07:39,311] \n",
      "16/300 * Epoch 16 (_base): lr=2.500e-06 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): auc/_mean=0.9999 | auc/class_0=0.9999 | loss=0.0009\n",
      "16/300 * Epoch 16 (valid): auc/_mean=0.8514 | auc/class_0=0.8514 | es_auc/_mean=0.8605 | es_auc/class_0=0.8605 | es_loss=0.0940 | it_auc/_mean=0.8227 | it_auc/class_0=0.8227 | it_loss=0.1165 | loss=0.0950 | tr_auc/_mean=0.8541 | tr_auc/class_0=0.8541 | tr_loss=0.0780\n",
      "16/300 * Epoch 16 (valid_es): auc/_mean=0.8605 | auc/class_0=0.8605 | loss=0.0940\n",
      "16/300 * Epoch 16 (valid_it): auc/_mean=0.8227 | auc/class_0=0.8227 | loss=0.1165\n",
      "16/300 * Epoch 16 (valid_tr): auc/_mean=0.8541 | auc/class_0=0.8541 | loss=0.0780\n",
      "17/300 * Epoch (train):  51% 2741/5345 [11:04<10:30,  4.13it/s, loss=5.202e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "17/300 * Epoch (train):  95% 5055/5345 [20:25<01:10,  4.12it/s, loss=3.864e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "17/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=2.367e-06]\n",
      "17/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.04it/s, loss=0.036]\n",
      "17/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.064]\n",
      "17/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.82it/s, loss=0.119]\n",
      "17/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.10it/s, loss=0.075]\n",
      "[2020-05-02 01:30:00,187] \n",
      "17/300 * Epoch 17 (_base): lr=6.250e-07 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): auc/_mean=0.9999 | auc/class_0=0.9999 | loss=0.0008\n",
      "17/300 * Epoch 17 (valid): auc/_mean=0.8597 | auc/class_0=0.8597 | es_auc/_mean=0.8640 | es_auc/class_0=0.8640 | es_loss=0.0949 | it_auc/_mean=0.8272 | it_auc/class_0=0.8272 | it_loss=0.1154 | loss=0.0934 | tr_auc/_mean=0.8750 | tr_auc/class_0=0.8750 | tr_loss=0.0738\n",
      "17/300 * Epoch 17 (valid_es): auc/_mean=0.8640 | auc/class_0=0.8640 | loss=0.0949\n",
      "17/300 * Epoch 17 (valid_it): auc/_mean=0.8272 | auc/class_0=0.8272 | loss=0.1154\n",
      "17/300 * Epoch 17 (valid_tr): auc/_mean=0.8750 | auc/class_0=0.8750 | loss=0.0738\n",
      "18/300 * Epoch (train):  70% 3730/5345 [15:03<06:32,  4.12it/s, loss=1.094e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "18/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=6.617e-06]\n",
      "18/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.95it/s, loss=0.041]\n",
      "18/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.75it/s, loss=0.065]\n",
      "18/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.86it/s, loss=0.130]\n",
      "18/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.98it/s, loss=0.077]\n",
      "[2020-05-02 01:52:21,408] \n",
      "18/300 * Epoch 18 (_base): lr=6.250e-07 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): auc/_mean=0.9999 | auc/class_0=0.9999 | loss=0.0007\n",
      "18/300 * Epoch 18 (valid): auc/_mean=0.8571 | auc/class_0=0.8571 | es_auc/_mean=0.8632 | es_auc/class_0=0.8632 | es_loss=0.0964 | it_auc/_mean=0.8226 | it_auc/class_0=0.8226 | it_loss=0.1213 | loss=0.0968 | tr_auc/_mean=0.8739 | tr_auc/class_0=0.8739 | tr_loss=0.0766\n",
      "18/300 * Epoch 18 (valid_es): auc/_mean=0.8632 | auc/class_0=0.8632 | loss=0.0964\n",
      "18/300 * Epoch 18 (valid_it): auc/_mean=0.8226 | auc/class_0=0.8226 | loss=0.1213\n",
      "18/300 * Epoch 18 (valid_tr): auc/_mean=0.8739 | auc/class_0=0.8739 | loss=0.0766\n",
      "19/300 * Epoch (train):   8% 412/5345 [01:39<19:51,  4.14it/s, loss=3.126e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "19/300 * Epoch (train):   8% 419/5345 [01:41<19:44,  4.16it/s, loss=1.662e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "19/300 * Epoch (train):  21% 1109/5345 [04:28<17:05,  4.13it/s, loss=3.856e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/300 * Epoch (train):  99% 5317/5345 [21:27<00:06,  4.12it/s, loss=1.192e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "19/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=4.423e-06]\n",
      "19/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.04it/s, loss=0.039]\n",
      "19/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.74it/s, loss=0.066]\n",
      "19/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.132]\n",
      "19/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.05it/s, loss=0.078]\n",
      "[2020-05-02 02:14:41,841] \n",
      "19/300 * Epoch 19 (_base): lr=6.250e-07 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): auc/_mean=0.9999 | auc/class_0=0.9999 | loss=0.0006\n",
      "19/300 * Epoch 19 (valid): auc/_mean=0.8624 | auc/class_0=0.8624 | es_auc/_mean=0.8641 | es_auc/class_0=0.8641 | es_loss=0.0960 | it_auc/_mean=0.8264 | it_auc/class_0=0.8264 | it_loss=0.1199 | loss=0.0948 | tr_auc/_mean=0.8848 | tr_auc/class_0=0.8848 | tr_loss=0.0728\n",
      "19/300 * Epoch 19 (valid_es): auc/_mean=0.8641 | auc/class_0=0.8641 | loss=0.0960\n",
      "19/300 * Epoch 19 (valid_it): auc/_mean=0.8264 | auc/class_0=0.8264 | loss=0.1199\n",
      "19/300 * Epoch 19 (valid_tr): auc/_mean=0.8848 | auc/class_0=0.8848 | loss=0.0728\n",
      "20/300 * Epoch (train):  55% 2949/5345 [11:53<09:41,  4.12it/s, loss=6.487e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "20/300 * Epoch (train):  57% 3045/5345 [12:16<09:16,  4.13it/s, loss=1.454e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "20/300 * Epoch (train):  82% 4360/5345 [17:34<03:58,  4.14it/s, loss=3.768e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "20/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=5.647e-06]\n",
      "20/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.06it/s, loss=0.040]\n",
      "20/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.88it/s, loss=0.065]\n",
      "20/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.61it/s, loss=0.136]\n",
      "20/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.05it/s, loss=0.081]\n",
      "[2020-05-02 02:37:00,538] \n",
      "20/300 * Epoch 20 (_base): lr=6.250e-07 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): auc/_mean=0.9999 | auc/class_0=0.9999 | loss=0.0006\n",
      "20/300 * Epoch 20 (valid): auc/_mean=0.8559 | auc/class_0=0.8559 | es_auc/_mean=0.8623 | es_auc/class_0=0.8623 | es_loss=0.0987 | it_auc/_mean=0.8257 | it_auc/class_0=0.8257 | it_loss=0.1225 | loss=0.0982 | tr_auc/_mean=0.8645 | tr_auc/class_0=0.8645 | tr_loss=0.0776\n",
      "20/300 * Epoch 20 (valid_es): auc/_mean=0.8623 | auc/class_0=0.8623 | loss=0.0987\n",
      "20/300 * Epoch 20 (valid_it): auc/_mean=0.8257 | auc/class_0=0.8257 | loss=0.1225\n",
      "20/300 * Epoch 20 (valid_tr): auc/_mean=0.8645 | auc/class_0=0.8645 | loss=0.0776\n",
      "21/300 * Epoch (train):  71% 3813/5345 [15:23<06:10,  4.13it/s, loss=1.781e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "21/300 * Epoch (train):  84% 4508/5345 [18:10<03:22,  4.13it/s, loss=4.485e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "21/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=2.821e-06]\n",
      "21/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.06it/s, loss=0.041]\n",
      "21/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.80it/s, loss=0.069]\n",
      "21/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.91it/s, loss=0.143]\n",
      "21/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.03it/s, loss=0.081]\n",
      "[2020-05-02 02:59:19,430] \n",
      "21/300 * Epoch 21 (_base): lr=6.250e-07 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0005\n",
      "21/300 * Epoch 21 (valid): auc/_mean=0.8530 | auc/class_0=0.8530 | es_auc/_mean=0.8612 | es_auc/class_0=0.8612 | es_loss=0.1003 | it_auc/_mean=0.8226 | it_auc/class_0=0.8226 | it_loss=0.1250 | loss=0.0995 | tr_auc/_mean=0.8581 | tr_auc/class_0=0.8581 | tr_loss=0.0775\n",
      "21/300 * Epoch 21 (valid_es): auc/_mean=0.8612 | auc/class_0=0.8612 | loss=0.1003\n",
      "21/300 * Epoch 21 (valid_it): auc/_mean=0.8226 | auc/class_0=0.8226 | loss=0.1250\n",
      "21/300 * Epoch 21 (valid_tr): auc/_mean=0.8581 | auc/class_0=0.8581 | loss=0.0775\n",
      "22/300 * Epoch (train):  89% 4735/5345 [19:06<02:27,  4.12it/s, loss=1.348e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "22/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=3.650e-06]\n",
      "22/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.05it/s, loss=0.039]\n",
      "22/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.86it/s, loss=0.072]\n",
      "22/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.73it/s, loss=0.137]\n",
      "22/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.06it/s, loss=0.079]\n",
      "[2020-05-02 03:21:39,267] \n",
      "22/300 * Epoch 22 (_base): lr=6.250e-07 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0005\n",
      "22/300 * Epoch 22 (valid): auc/_mean=0.8543 | auc/class_0=0.8543 | es_auc/_mean=0.8622 | es_auc/class_0=0.8622 | es_loss=0.0977 | it_auc/_mean=0.8247 | it_auc/class_0=0.8247 | it_loss=0.1204 | loss=0.0961 | tr_auc/_mean=0.8585 | tr_auc/class_0=0.8585 | tr_loss=0.0745\n",
      "22/300 * Epoch 22 (valid_es): auc/_mean=0.8622 | auc/class_0=0.8622 | loss=0.0977\n",
      "22/300 * Epoch 22 (valid_it): auc/_mean=0.8247 | auc/class_0=0.8247 | loss=0.1204\n",
      "22/300 * Epoch 22 (valid_tr): auc/_mean=0.8585 | auc/class_0=0.8585 | loss=0.0745\n",
      "23/300 * Epoch (train):  82% 4373/5345 [17:39<03:55,  4.12it/s, loss=6.984e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "23/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=1.387e-06]\n",
      "23/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.02it/s, loss=0.039]\n",
      "23/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.79it/s, loss=0.076]\n",
      "23/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.84it/s, loss=0.143]\n",
      "23/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.03it/s, loss=0.080]\n",
      "[2020-05-02 03:43:59,719] \n",
      "23/300 * Epoch 23 (_base): lr=1.563e-07 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0005\n",
      "23/300 * Epoch 23 (valid): auc/_mean=0.8465 | auc/class_0=0.8465 | es_auc/_mean=0.8595 | es_auc/class_0=0.8595 | es_loss=0.1015 | it_auc/_mean=0.8194 | it_auc/class_0=0.8194 | it_loss=0.1256 | loss=0.0997 | tr_auc/_mean=0.8406 | tr_auc/class_0=0.8406 | tr_loss=0.0767\n",
      "23/300 * Epoch 23 (valid_es): auc/_mean=0.8595 | auc/class_0=0.8595 | loss=0.1015\n",
      "23/300 * Epoch 23 (valid_it): auc/_mean=0.8194 | auc/class_0=0.8194 | loss=0.1256\n",
      "23/300 * Epoch 23 (valid_tr): auc/_mean=0.8406 | auc/class_0=0.8406 | loss=0.0767\n",
      "24/300 * Epoch (train):  37% 1993/5345 [08:02<13:31,  4.13it/s, loss=2.224e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "24/300 * Epoch (train):  88% 4693/5345 [18:56<02:37,  4.13it/s, loss=6.393e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "24/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=1.799e-06]\n",
      "24/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.03it/s, loss=0.039]\n",
      "24/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.078]\n",
      "24/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.76it/s, loss=0.142]\n",
      "24/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.06it/s, loss=0.080]    \n",
      "[2020-05-02 04:06:20,297] \n",
      "24/300 * Epoch 24 (_base): lr=1.563e-07 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "24/300 * Epoch 24 (valid): auc/_mean=0.8503 | auc/class_0=0.8503 | es_auc/_mean=0.8615 | es_auc/class_0=0.8615 | es_loss=0.1012 | it_auc/_mean=0.8215 | it_auc/class_0=0.8215 | it_loss=0.1249 | loss=0.0988 | tr_auc/_mean=0.8499 | tr_auc/class_0=0.8499 | tr_loss=0.0751\n",
      "24/300 * Epoch 24 (valid_es): auc/_mean=0.8615 | auc/class_0=0.8615 | loss=0.1012\n",
      "24/300 * Epoch 24 (valid_it): auc/_mean=0.8215 | auc/class_0=0.8215 | loss=0.1249\n",
      "24/300 * Epoch 24 (valid_tr): auc/_mean=0.8499 | auc/class_0=0.8499 | loss=0.0751\n",
      "25/300 * Epoch (train):   0% 6/5345 [00:01<27:04,  3.29it/s, loss=1.585e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "25/300 * Epoch (train): 100% 5335/5345 [21:32<00:02,  4.12it/s, loss=6.411e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=4.586e-06]\n",
      "25/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.01it/s, loss=0.040]\n",
      "25/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.77it/s, loss=0.079]\n",
      "25/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.68it/s, loss=0.145]\n",
      "25/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.08it/s, loss=0.080]\n",
      "[2020-05-02 04:28:40,622] \n",
      "25/300 * Epoch 25 (_base): lr=1.563e-07 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "25/300 * Epoch 25 (valid): auc/_mean=0.8497 | auc/class_0=0.8497 | es_auc/_mean=0.8613 | es_auc/class_0=0.8613 | es_loss=0.1018 | it_auc/_mean=0.8212 | it_auc/class_0=0.8212 | it_loss=0.1260 | loss=0.0997 | tr_auc/_mean=0.8482 | tr_auc/class_0=0.8482 | tr_loss=0.0760\n",
      "25/300 * Epoch 25 (valid_es): auc/_mean=0.8613 | auc/class_0=0.8613 | loss=0.1018\n",
      "25/300 * Epoch 25 (valid_it): auc/_mean=0.8212 | auc/class_0=0.8212 | loss=0.1260\n",
      "25/300 * Epoch 25 (valid_tr): auc/_mean=0.8482 | auc/class_0=0.8482 | loss=0.0760\n",
      "26/300 * Epoch (train):  76% 4040/5345 [16:17<05:15,  4.13it/s, loss=4.560e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "26/300 * Epoch (train):  79% 4233/5345 [17:04<04:29,  4.13it/s, loss=1.082e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "26/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=3.294e-06]\n",
      "26/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.02it/s, loss=0.040]\n",
      "26/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.83it/s, loss=0.076]\n",
      "26/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.79it/s, loss=0.146]\n",
      "26/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.09it/s, loss=0.081]\n",
      "[2020-05-02 04:51:00,377] \n",
      "26/300 * Epoch 26 (_base): lr=1.563e-07 | momentum=0.9000\n",
      "26/300 * Epoch 26 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "26/300 * Epoch 26 (valid): auc/_mean=0.8461 | auc/class_0=0.8461 | es_auc/_mean=0.8602 | es_auc/class_0=0.8602 | es_loss=0.1017 | it_auc/_mean=0.8189 | it_auc/class_0=0.8189 | it_loss=0.1269 | loss=0.1005 | tr_auc/_mean=0.8391 | tr_auc/class_0=0.8391 | tr_loss=0.0775\n",
      "26/300 * Epoch 26 (valid_es): auc/_mean=0.8602 | auc/class_0=0.8602 | loss=0.1017\n",
      "26/300 * Epoch 26 (valid_it): auc/_mean=0.8189 | auc/class_0=0.8189 | loss=0.1269\n",
      "26/300 * Epoch 26 (valid_tr): auc/_mean=0.8391 | auc/class_0=0.8391 | loss=0.0775\n",
      "27/300 * Epoch (train):  48% 2554/5345 [10:17<11:16,  4.13it/s, loss=2.425e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "27/300 * Epoch (train):  98% 5229/5345 [21:06<00:28,  4.11it/s, loss=2.654e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "27/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=5.463e-06]\n",
      "27/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.03it/s, loss=0.041]\n",
      "27/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.84it/s, loss=0.075]\n",
      "27/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.81it/s, loss=0.149]\n",
      "27/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.98it/s, loss=0.081]\n",
      "[2020-05-02 05:13:20,379] \n",
      "27/300 * Epoch 27 (_base): lr=1.563e-07 | momentum=0.9000\n",
      "27/300 * Epoch 27 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "27/300 * Epoch 27 (valid): auc/_mean=0.8442 | auc/class_0=0.8442 | es_auc/_mean=0.8596 | es_auc/class_0=0.8596 | es_loss=0.1026 | it_auc/_mean=0.8172 | it_auc/class_0=0.8172 | it_loss=0.1291 | loss=0.1021 | tr_auc/_mean=0.8353 | tr_auc/class_0=0.8353 | tr_loss=0.0791\n",
      "27/300 * Epoch 27 (valid_es): auc/_mean=0.8596 | auc/class_0=0.8596 | loss=0.1026\n",
      "27/300 * Epoch 27 (valid_it): auc/_mean=0.8172 | auc/class_0=0.8172 | loss=0.1291\n",
      "27/300 * Epoch 27 (valid_tr): auc/_mean=0.8353 | auc/class_0=0.8353 | loss=0.0791\n",
      "28/300 * Epoch (train):  39% 2060/5345 [08:18<13:16,  4.12it/s, loss=2.770e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "28/300 * Epoch (train):  83% 4411/5345 [17:48<03:46,  4.12it/s, loss=1.415e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "28/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=2.103e-06]\n",
      "28/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.99it/s, loss=0.041]\n",
      "28/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.90it/s, loss=0.078]\n",
      "28/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.84it/s, loss=0.148]\n",
      "28/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.081]\n",
      "[2020-05-02 05:35:41,417] \n",
      "28/300 * Epoch 28 (_base): lr=1.563e-07 | momentum=0.9000\n",
      "28/300 * Epoch 28 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "28/300 * Epoch 28 (valid): auc/_mean=0.8423 | auc/class_0=0.8423 | es_auc/_mean=0.8591 | es_auc/class_0=0.8591 | es_loss=0.1033 | it_auc/_mean=0.8164 | it_auc/class_0=0.8164 | it_loss=0.1294 | loss=0.1025 | tr_auc/_mean=0.8298 | tr_auc/class_0=0.8298 | tr_loss=0.0794\n",
      "28/300 * Epoch 28 (valid_es): auc/_mean=0.8591 | auc/class_0=0.8591 | loss=0.1033\n",
      "28/300 * Epoch 28 (valid_it): auc/_mean=0.8164 | auc/class_0=0.8164 | loss=0.1294\n",
      "28/300 * Epoch 28 (valid_tr): auc/_mean=0.8298 | auc/class_0=0.8298 | loss=0.0794\n",
      "29/300 * Epoch (train):  55% 2921/5345 [11:47<09:47,  4.13it/s, loss=8.594e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "29/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=7.593e-06]\n",
      "29/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.03it/s, loss=0.041]\n",
      "29/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.90it/s, loss=0.081]\n",
      "29/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.86it/s, loss=0.147]\n",
      "29/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.11it/s, loss=0.081]\n",
      "[2020-05-02 05:58:00,977] \n",
      "29/300 * Epoch 29 (_base): lr=3.906e-08 | momentum=0.9000\n",
      "29/300 * Epoch 29 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "29/300 * Epoch 29 (valid): auc/_mean=0.8434 | auc/class_0=0.8434 | es_auc/_mean=0.8590 | es_auc/class_0=0.8590 | es_loss=0.1032 | it_auc/_mean=0.8174 | it_auc/class_0=0.8174 | it_loss=0.1287 | loss=0.1022 | tr_auc/_mean=0.8320 | tr_auc/class_0=0.8320 | tr_loss=0.0791\n",
      "29/300 * Epoch 29 (valid_es): auc/_mean=0.8590 | auc/class_0=0.8590 | loss=0.1032\n",
      "29/300 * Epoch 29 (valid_it): auc/_mean=0.8174 | auc/class_0=0.8174 | loss=0.1287\n",
      "29/300 * Epoch 29 (valid_tr): auc/_mean=0.8320 | auc/class_0=0.8320 | loss=0.0791\n",
      "30/300 * Epoch (train):  17% 893/5345 [03:36<17:58,  4.13it/s, loss=9.387e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "30/300 * Epoch (train):  44% 2349/5345 [09:28<12:04,  4.13it/s, loss=6.909e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "30/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=1.666e-06]\n",
      "30/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.05it/s, loss=0.041]\n",
      "30/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.80it/s, loss=0.080]\n",
      "30/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.67it/s, loss=0.145]\n",
      "30/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.07it/s, loss=0.082]\n",
      "[2020-05-02 06:20:20,925] \n",
      "30/300 * Epoch 30 (_base): lr=3.906e-08 | momentum=0.9000\n",
      "30/300 * Epoch 30 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "30/300 * Epoch 30 (valid): auc/_mean=0.8409 | auc/class_0=0.8409 | es_auc/_mean=0.8582 | es_auc/class_0=0.8582 | es_loss=0.1031 | it_auc/_mean=0.8151 | it_auc/class_0=0.8151 | it_loss=0.1296 | loss=0.1030 | tr_auc/_mean=0.8273 | tr_auc/class_0=0.8273 | tr_loss=0.0809\n",
      "30/300 * Epoch 30 (valid_es): auc/_mean=0.8582 | auc/class_0=0.8582 | loss=0.1031\n",
      "30/300 * Epoch 30 (valid_it): auc/_mean=0.8151 | auc/class_0=0.8151 | loss=0.1296\n",
      "30/300 * Epoch 30 (valid_tr): auc/_mean=0.8273 | auc/class_0=0.8273 | loss=0.0809\n",
      "31/300 * Epoch (train):  25% 1314/5345 [05:18<16:17,  4.13it/s, loss=8.118e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "31/300 * Epoch (train):  29% 1528/5345 [06:10<15:23,  4.13it/s, loss=0.001]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "31/300 * Epoch (train):  98% 5230/5345 [21:06<00:27,  4.13it/s, loss=2.728e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=6.127e-05]\n",
      "31/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.03it/s, loss=0.041]\n",
      "31/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.81it/s, loss=0.081]\n",
      "31/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.82it/s, loss=0.147]\n",
      "31/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.04it/s, loss=0.081]\n",
      "[2020-05-02 06:42:41,885] \n",
      "31/300 * Epoch 31 (_base): lr=3.906e-08 | momentum=0.9000\n",
      "31/300 * Epoch 31 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "31/300 * Epoch 31 (valid): auc/_mean=0.8433 | auc/class_0=0.8433 | es_auc/_mean=0.8588 | es_auc/class_0=0.8588 | es_loss=0.1034 | it_auc/_mean=0.8166 | it_auc/class_0=0.8166 | it_loss=0.1293 | loss=0.1025 | tr_auc/_mean=0.8335 | tr_auc/class_0=0.8335 | tr_loss=0.0792\n",
      "31/300 * Epoch 31 (valid_es): auc/_mean=0.8588 | auc/class_0=0.8588 | loss=0.1034\n",
      "31/300 * Epoch 31 (valid_it): auc/_mean=0.8166 | auc/class_0=0.8166 | loss=0.1293\n",
      "31/300 * Epoch 31 (valid_tr): auc/_mean=0.8335 | auc/class_0=0.8335 | loss=0.0792\n",
      "32/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=5.936e-06]\n",
      "32/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.01it/s, loss=0.041]\n",
      "32/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.86it/s, loss=0.081]\n",
      "32/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.83it/s, loss=0.147]\n",
      "32/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.06it/s, loss=0.082]\n",
      "[2020-05-02 07:05:02,512] \n",
      "32/300 * Epoch 32 (_base): lr=3.906e-08 | momentum=0.9000\n",
      "32/300 * Epoch 32 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "32/300 * Epoch 32 (valid): auc/_mean=0.8426 | auc/class_0=0.8426 | es_auc/_mean=0.8590 | es_auc/class_0=0.8590 | es_loss=0.1033 | it_auc/_mean=0.8162 | it_auc/class_0=0.8162 | it_loss=0.1295 | loss=0.1026 | tr_auc/_mean=0.8313 | tr_auc/class_0=0.8313 | tr_loss=0.0795\n",
      "32/300 * Epoch 32 (valid_es): auc/_mean=0.8590 | auc/class_0=0.8590 | loss=0.1033\n",
      "32/300 * Epoch 32 (valid_it): auc/_mean=0.8162 | auc/class_0=0.8162 | loss=0.1295\n",
      "32/300 * Epoch 32 (valid_tr): auc/_mean=0.8313 | auc/class_0=0.8313 | loss=0.0795\n",
      "33/300 * Epoch (train):   8% 440/5345 [01:46<19:48,  4.13it/s, loss=5.059e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "33/300 * Epoch (train):  64% 3430/5345 [13:50<07:43,  4.13it/s, loss=1.242e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "33/300 * Epoch (train):  79% 4197/5345 [16:56<04:39,  4.11it/s, loss=4.627e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "33/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=5.394e-06]\n",
      "33/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.00it/s, loss=0.041]\n",
      "33/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.081]\n",
      "33/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.69it/s, loss=0.147]\n",
      "33/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.082]\n",
      "[2020-05-02 07:27:23,389] \n",
      "33/300 * Epoch 33 (_base): lr=3.906e-08 | momentum=0.9000\n",
      "33/300 * Epoch 33 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "33/300 * Epoch 33 (valid): auc/_mean=0.8422 | auc/class_0=0.8422 | es_auc/_mean=0.8590 | es_auc/class_0=0.8590 | es_loss=0.1034 | it_auc/_mean=0.8159 | it_auc/class_0=0.8159 | it_loss=0.1297 | loss=0.1027 | tr_auc/_mean=0.8305 | tr_auc/class_0=0.8305 | tr_loss=0.0797\n",
      "33/300 * Epoch 33 (valid_es): auc/_mean=0.8590 | auc/class_0=0.8590 | loss=0.1034\n",
      "33/300 * Epoch 33 (valid_it): auc/_mean=0.8159 | auc/class_0=0.8159 | loss=0.1297\n",
      "33/300 * Epoch 33 (valid_tr): auc/_mean=0.8305 | auc/class_0=0.8305 | loss=0.0797\n",
      "34/300 * Epoch (train):   5% 293/5345 [01:11<20:20,  4.14it/s, loss=2.137e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "34/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=2.119e-06]\n",
      "34/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.04it/s, loss=0.041]\n",
      "34/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.76it/s, loss=0.081]\n",
      "34/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.147]\n",
      "34/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.02it/s, loss=0.082]\n",
      "[2020-05-02 07:49:43,281] \n",
      "34/300 * Epoch 34 (_base): lr=3.906e-08 | momentum=0.9000\n",
      "34/300 * Epoch 34 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "34/300 * Epoch 34 (valid): auc/_mean=0.8420 | auc/class_0=0.8420 | es_auc/_mean=0.8590 | es_auc/class_0=0.8590 | es_loss=0.1034 | it_auc/_mean=0.8159 | it_auc/class_0=0.8159 | it_loss=0.1298 | loss=0.1028 | tr_auc/_mean=0.8297 | tr_auc/class_0=0.8297 | tr_loss=0.0797\n",
      "34/300 * Epoch 34 (valid_es): auc/_mean=0.8590 | auc/class_0=0.8590 | loss=0.1034\n",
      "34/300 * Epoch 34 (valid_it): auc/_mean=0.8159 | auc/class_0=0.8159 | loss=0.1298\n",
      "34/300 * Epoch 34 (valid_tr): auc/_mean=0.8297 | auc/class_0=0.8297 | loss=0.0797\n",
      "35/300 * Epoch (train):  22% 1155/5345 [04:39<16:54,  4.13it/s, loss=6.731e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "35/300 * Epoch (train):  26% 1380/5345 [05:34<15:59,  4.13it/s, loss=1.459e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "35/300 * Epoch (train):  49% 2627/5345 [10:35<10:53,  4.16it/s, loss=1.675e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "35/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=2.213e-06]\n",
      "35/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.97it/s, loss=0.041]\n",
      "35/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.080]\n",
      "35/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.84it/s, loss=0.148]\n",
      "35/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.93it/s, loss=0.082]\n",
      "[2020-05-02 08:12:02,378] \n",
      "35/300 * Epoch 35 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "35/300 * Epoch 35 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "35/300 * Epoch 35 (valid): auc/_mean=0.8406 | auc/class_0=0.8406 | es_auc/_mean=0.8585 | es_auc/class_0=0.8585 | es_loss=0.1035 | it_auc/_mean=0.8145 | it_auc/class_0=0.8145 | it_loss=0.1303 | loss=0.1032 | tr_auc/_mean=0.8270 | tr_auc/class_0=0.8270 | tr_loss=0.0805\n",
      "35/300 * Epoch 35 (valid_es): auc/_mean=0.8585 | auc/class_0=0.8585 | loss=0.1035\n",
      "35/300 * Epoch 35 (valid_it): auc/_mean=0.8145 | auc/class_0=0.8145 | loss=0.1303\n",
      "35/300 * Epoch 35 (valid_tr): auc/_mean=0.8270 | auc/class_0=0.8270 | loss=0.0805\n",
      "36/300 * Epoch (train):   1% 27/5345 [00:06<21:22,  4.15it/s, loss=9.675e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "36/300 * Epoch (train):  35% 1849/5345 [07:27<14:05,  4.13it/s, loss=2.990e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "36/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=4.272e-06]\n",
      "36/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.03it/s, loss=0.041]\n",
      "36/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.83it/s, loss=0.080]\n",
      "36/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.148]\n",
      "36/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.01it/s, loss=0.082]\n",
      "[2020-05-02 08:34:21,735] \n",
      "36/300 * Epoch 36 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "36/300 * Epoch 36 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "36/300 * Epoch 36 (valid): auc/_mean=0.8404 | auc/class_0=0.8404 | es_auc/_mean=0.8584 | es_auc/class_0=0.8584 | es_loss=0.1035 | it_auc/_mean=0.8145 | it_auc/class_0=0.8145 | it_loss=0.1303 | loss=0.1032 | tr_auc/_mean=0.8268 | tr_auc/class_0=0.8268 | tr_loss=0.0805\n",
      "36/300 * Epoch 36 (valid_es): auc/_mean=0.8584 | auc/class_0=0.8584 | loss=0.1035\n",
      "36/300 * Epoch 36 (valid_it): auc/_mean=0.8145 | auc/class_0=0.8145 | loss=0.1303\n",
      "36/300 * Epoch 36 (valid_tr): auc/_mean=0.8268 | auc/class_0=0.8268 | loss=0.0805\n",
      "37/300 * Epoch (train):  38% 2050/5345 [08:16<13:17,  4.13it/s, loss=0.007]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "37/300 * Epoch (train):  81% 4320/5345 [17:25<04:08,  4.13it/s, loss=3.586e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "37/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=2.906e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.00it/s, loss=0.041]\n",
      "37/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.81it/s, loss=0.080]\n",
      "37/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.73it/s, loss=0.148]\n",
      "37/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.96it/s, loss=0.082]\n",
      "[2020-05-02 08:56:41,662] \n",
      "37/300 * Epoch 37 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "37/300 * Epoch 37 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "37/300 * Epoch 37 (valid): auc/_mean=0.8403 | auc/class_0=0.8403 | es_auc/_mean=0.8584 | es_auc/class_0=0.8584 | es_loss=0.1034 | it_auc/_mean=0.8144 | it_auc/class_0=0.8144 | it_loss=0.1302 | loss=0.1032 | tr_auc/_mean=0.8264 | tr_auc/class_0=0.8264 | tr_loss=0.0805\n",
      "37/300 * Epoch 37 (valid_es): auc/_mean=0.8584 | auc/class_0=0.8584 | loss=0.1034\n",
      "37/300 * Epoch 37 (valid_it): auc/_mean=0.8144 | auc/class_0=0.8144 | loss=0.1302\n",
      "37/300 * Epoch 37 (valid_tr): auc/_mean=0.8264 | auc/class_0=0.8264 | loss=0.0805\n",
      "38/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=2.290e-06]\n",
      "38/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.03it/s, loss=0.041]\n",
      "38/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.70it/s, loss=0.080]\n",
      "38/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.85it/s, loss=0.147]\n",
      "38/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.00it/s, loss=0.082]\n",
      "[2020-05-02 09:19:02,122] \n",
      "38/300 * Epoch 38 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "38/300 * Epoch 38 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "38/300 * Epoch 38 (valid): auc/_mean=0.8400 | auc/class_0=0.8400 | es_auc/_mean=0.8583 | es_auc/class_0=0.8583 | es_loss=0.1032 | it_auc/_mean=0.8142 | it_auc/class_0=0.8142 | it_loss=0.1300 | loss=0.1031 | tr_auc/_mean=0.8257 | tr_auc/class_0=0.8257 | tr_loss=0.0806\n",
      "38/300 * Epoch 38 (valid_es): auc/_mean=0.8583 | auc/class_0=0.8583 | loss=0.1032\n",
      "38/300 * Epoch 38 (valid_it): auc/_mean=0.8142 | auc/class_0=0.8142 | loss=0.1300\n",
      "38/300 * Epoch 38 (valid_tr): auc/_mean=0.8257 | auc/class_0=0.8257 | loss=0.0806\n",
      "39/300 * Epoch (train):   7% 371/5345 [01:30<20:04,  4.13it/s, loss=2.651e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "39/300 * Epoch (train):  12% 642/5345 [02:35<18:58,  4.13it/s, loss=9.249e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "39/300 * Epoch (train):  62% 3317/5345 [13:22<08:12,  4.12it/s, loss=0.002]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "39/300 * Epoch (train):  70% 3768/5345 [15:11<06:21,  4.13it/s, loss=1.023e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "39/300 * Epoch (train): 100% 5345/5345 [21:33<00:00,  4.13it/s, loss=3.446e-06]\n",
      "39/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.05it/s, loss=0.041]\n",
      "39/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.63it/s, loss=0.079]\n",
      "39/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.147]\n",
      "39/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.04it/s, loss=0.082]\n",
      "[2020-05-02 09:41:21,561] \n",
      "39/300 * Epoch 39 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "39/300 * Epoch 39 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "39/300 * Epoch 39 (valid): auc/_mean=0.8402 | auc/class_0=0.8402 | es_auc/_mean=0.8583 | es_auc/class_0=0.8583 | es_loss=0.1032 | it_auc/_mean=0.8145 | it_auc/class_0=0.8145 | it_loss=0.1299 | loss=0.1030 | tr_auc/_mean=0.8261 | tr_auc/class_0=0.8261 | tr_loss=0.0803\n",
      "39/300 * Epoch 39 (valid_es): auc/_mean=0.8583 | auc/class_0=0.8583 | loss=0.1032\n",
      "39/300 * Epoch 39 (valid_it): auc/_mean=0.8145 | auc/class_0=0.8145 | loss=0.1299\n",
      "39/300 * Epoch 39 (valid_tr): auc/_mean=0.8261 | auc/class_0=0.8261 | loss=0.0803\n",
      "40/300 * Epoch (train):  54% 2880/5345 [11:37<09:55,  4.14it/s, loss=1.911e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "40/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=3.724e-06]\n",
      "40/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.99it/s, loss=0.041]\n",
      "40/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.87it/s, loss=0.079]\n",
      "40/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.84it/s, loss=0.147]\n",
      "40/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.06it/s, loss=0.082]\n",
      "[2020-05-02 10:03:41,798] \n",
      "40/300 * Epoch 40 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "40/300 * Epoch 40 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "40/300 * Epoch 40 (valid): auc/_mean=0.8397 | auc/class_0=0.8397 | es_auc/_mean=0.8581 | es_auc/class_0=0.8581 | es_loss=0.1031 | it_auc/_mean=0.8140 | it_auc/class_0=0.8140 | it_loss=0.1299 | loss=0.1030 | tr_auc/_mean=0.8252 | tr_auc/class_0=0.8252 | tr_loss=0.0806\n",
      "40/300 * Epoch 40 (valid_es): auc/_mean=0.8581 | auc/class_0=0.8581 | loss=0.1031\n",
      "40/300 * Epoch 40 (valid_it): auc/_mean=0.8140 | auc/class_0=0.8140 | loss=0.1299\n",
      "40/300 * Epoch 40 (valid_tr): auc/_mean=0.8252 | auc/class_0=0.8252 | loss=0.0806\n",
      "41/300 * Epoch (train):   0% 4/5345 [00:01<33:37,  2.65it/s, loss=0.005]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "41/300 * Epoch (train):  45% 2430/5345 [09:48<11:47,  4.12it/s, loss=3.644e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "41/300 * Epoch (train):  71% 3788/5345 [15:16<06:17,  4.13it/s, loss=0.008]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "41/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=1.123e-06]\n",
      "41/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.04it/s, loss=0.041]\n",
      "41/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.65it/s, loss=0.080]\n",
      "41/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.77it/s, loss=0.147]\n",
      "41/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.09it/s, loss=0.081]\n",
      "[2020-05-02 10:26:01,607] \n",
      "41/300 * Epoch 41 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "41/300 * Epoch 41 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "41/300 * Epoch 41 (valid): auc/_mean=0.8402 | auc/class_0=0.8402 | es_auc/_mean=0.8583 | es_auc/class_0=0.8583 | es_loss=0.1031 | it_auc/_mean=0.8143 | it_auc/class_0=0.8143 | it_loss=0.1298 | loss=0.1029 | tr_auc/_mean=0.8263 | tr_auc/class_0=0.8263 | tr_loss=0.0803\n",
      "41/300 * Epoch 41 (valid_es): auc/_mean=0.8583 | auc/class_0=0.8583 | loss=0.1031\n",
      "41/300 * Epoch 41 (valid_it): auc/_mean=0.8143 | auc/class_0=0.8143 | loss=0.1298\n",
      "41/300 * Epoch 41 (valid_tr): auc/_mean=0.8263 | auc/class_0=0.8263 | loss=0.0803\n",
      "42/300 * Epoch (train):  26% 1383/5345 [05:35<16:01,  4.12it/s, loss=0.003]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "42/300 * Epoch (train): 100% 5345/5345 [21:34<00:00,  4.13it/s, loss=3.786e-05]\n",
      "42/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.01it/s, loss=0.041]\n",
      "42/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.79it/s, loss=0.079]\n",
      "42/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.79it/s, loss=0.146]\n",
      "42/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.96it/s, loss=0.081]\n",
      "[2020-05-02 10:48:21,349] \n",
      "42/300 * Epoch 42 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "42/300 * Epoch 42 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "42/300 * Epoch 42 (valid): auc/_mean=0.8402 | auc/class_0=0.8402 | es_auc/_mean=0.8584 | es_auc/class_0=0.8584 | es_loss=0.1029 | it_auc/_mean=0.8143 | it_auc/class_0=0.8143 | it_loss=0.1296 | loss=0.1028 | tr_auc/_mean=0.8258 | tr_auc/class_0=0.8258 | tr_loss=0.0803\n",
      "42/300 * Epoch 42 (valid_es): auc/_mean=0.8584 | auc/class_0=0.8584 | loss=0.1029\n",
      "42/300 * Epoch 42 (valid_it): auc/_mean=0.8143 | auc/class_0=0.8143 | loss=0.1296\n",
      "42/300 * Epoch 42 (valid_tr): auc/_mean=0.8258 | auc/class_0=0.8258 | loss=0.0803\n",
      "43/300 * Epoch (train):   8% 431/5345 [01:44<19:51,  4.12it/s, loss=3.347e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "43/300 * Epoch (train):  35% 1851/5345 [07:28<14:08,  4.12it/s, loss=7.320e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "43/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=6.841e-06]\n",
      "43/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.01it/s, loss=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.83it/s, loss=0.079]\n",
      "43/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.76it/s, loss=0.146]\n",
      "43/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.01it/s, loss=0.081]\n",
      "[2020-05-02 11:10:43,271] \n",
      "43/300 * Epoch 43 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "43/300 * Epoch 43 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "43/300 * Epoch 43 (valid): auc/_mean=0.8403 | auc/class_0=0.8403 | es_auc/_mean=0.8584 | es_auc/class_0=0.8584 | es_loss=0.1028 | it_auc/_mean=0.8145 | it_auc/class_0=0.8145 | it_loss=0.1294 | loss=0.1027 | tr_auc/_mean=0.8263 | tr_auc/class_0=0.8263 | tr_loss=0.0802\n",
      "43/300 * Epoch 43 (valid_es): auc/_mean=0.8584 | auc/class_0=0.8584 | loss=0.1028\n",
      "43/300 * Epoch 43 (valid_it): auc/_mean=0.8145 | auc/class_0=0.8145 | loss=0.1294\n",
      "43/300 * Epoch 43 (valid_tr): auc/_mean=0.8263 | auc/class_0=0.8263 | loss=0.0802\n",
      "44/300 * Epoch (train):  20% 1073/5345 [04:19<17:15,  4.12it/s, loss=1.171e-04]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "44/300 * Epoch (train):  70% 3736/5345 [15:05<06:30,  4.12it/s, loss=9.829e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "44/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=1.029e-05]\n",
      "44/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.01it/s, loss=0.041]\n",
      "44/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.80it/s, loss=0.079]\n",
      "44/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.83it/s, loss=0.146]\n",
      "44/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.97it/s, loss=0.081]\n",
      "[2020-05-02 11:33:04,336] \n",
      "44/300 * Epoch 44 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "44/300 * Epoch 44 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0004\n",
      "44/300 * Epoch 44 (valid): auc/_mean=0.8400 | auc/class_0=0.8400 | es_auc/_mean=0.8584 | es_auc/class_0=0.8584 | es_loss=0.1027 | it_auc/_mean=0.8142 | it_auc/class_0=0.8142 | it_loss=0.1295 | loss=0.1027 | tr_auc/_mean=0.8257 | tr_auc/class_0=0.8257 | tr_loss=0.0803\n",
      "44/300 * Epoch 44 (valid_es): auc/_mean=0.8584 | auc/class_0=0.8584 | loss=0.1027\n",
      "44/300 * Epoch 44 (valid_it): auc/_mean=0.8142 | auc/class_0=0.8142 | loss=0.1295\n",
      "44/300 * Epoch 44 (valid_tr): auc/_mean=0.8257 | auc/class_0=0.8257 | loss=0.0803\n",
      "45/300 * Epoch (train):  49% 2622/5345 [10:35<10:58,  4.13it/s, loss=4.158e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "45/300 * Epoch (train):  53% 2840/5345 [11:28<10:07,  4.12it/s, loss=8.019e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "45/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.12it/s, loss=3.171e-06]\n",
      "45/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 14.99it/s, loss=0.041]\n",
      "45/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.079]\n",
      "45/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.76it/s, loss=0.146]\n",
      "45/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 13.97it/s, loss=0.081]\n",
      "[2020-05-02 11:55:25,964] \n",
      "45/300 * Epoch 45 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "45/300 * Epoch 45 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "45/300 * Epoch 45 (valid): auc/_mean=0.8399 | auc/class_0=0.8399 | es_auc/_mean=0.8584 | es_auc/class_0=0.8584 | es_loss=0.1028 | it_auc/_mean=0.8143 | it_auc/class_0=0.8143 | it_loss=0.1294 | loss=0.1026 | tr_auc/_mean=0.8257 | tr_auc/class_0=0.8257 | tr_loss=0.0802\n",
      "45/300 * Epoch 45 (valid_es): auc/_mean=0.8584 | auc/class_0=0.8584 | loss=0.1028\n",
      "45/300 * Epoch 45 (valid_it): auc/_mean=0.8143 | auc/class_0=0.8143 | loss=0.1294\n",
      "45/300 * Epoch 45 (valid_tr): auc/_mean=0.8257 | auc/class_0=0.8257 | loss=0.0802\n",
      "46/300 * Epoch (train):  29% 1566/5345 [06:19<15:14,  4.13it/s, loss=4.880e-06]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "46/300 * Epoch (train):  48% 2553/5345 [10:18<11:17,  4.12it/s, loss=1.974e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "46/300 * Epoch (train):  72% 3846/5345 [15:32<06:03,  4.12it/s, loss=1.104e-05]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "46/300 * Epoch (train): 100% 5345/5345 [21:35<00:00,  4.13it/s, loss=1.233e-06]\n",
      "46/300 * Epoch (valid): 100% 160/160 [00:10<00:00, 15.01it/s, loss=0.041]\n",
      "46/300 * Epoch (valid_es): 100% 50/50 [00:03<00:00, 13.78it/s, loss=0.079]\n",
      "46/300 * Epoch (valid_it): 100% 50/50 [00:03<00:00, 13.75it/s, loss=0.146]\n",
      "46/300 * Epoch (valid_tr): 100% 60/60 [00:04<00:00, 14.03it/s, loss=0.081]\n",
      "[2020-05-02 12:17:47,025] \n",
      "46/300 * Epoch 46 (_base): lr=9.766e-09 | momentum=0.9000\n",
      "46/300 * Epoch 46 (train): auc/_mean=1.0000 | auc/class_0=1.0000 | loss=0.0003\n",
      "46/300 * Epoch 46 (valid): auc/_mean=0.8399 | auc/class_0=0.8399 | es_auc/_mean=0.8583 | es_auc/class_0=0.8583 | es_loss=0.1028 | it_auc/_mean=0.8142 | it_auc/class_0=0.8142 | it_loss=0.1293 | loss=0.1026 | tr_auc/_mean=0.8253 | tr_auc/class_0=0.8253 | tr_loss=0.0801\n",
      "46/300 * Epoch 46 (valid_es): auc/_mean=0.8583 | auc/class_0=0.8583 | loss=0.1028\n",
      "46/300 * Epoch 46 (valid_it): auc/_mean=0.8142 | auc/class_0=0.8142 | loss=0.1293\n",
      "46/300 * Epoch 46 (valid_tr): auc/_mean=0.8253 | auc/class_0=0.8253 | loss=0.0801\n",
      "47/300 * Epoch (train):  26% 1377/5345 [05:34<16:19,  4.05it/s, loss=4.681e-05]"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = './checkpoints/from_v4.pth'\n",
    "project = \"jigsaw_v9_xlm_roberta_base_fp02\"\n",
    "num_epochs = 300\n",
    "\n",
    "group = datetime.now().strftime(\"%m_%d_%Y__%H_%M_%S\")\n",
    "\n",
    "    \n",
    "if SERVER:\n",
    "    group = f'{group}_server'\n",
    "    \n",
    "if STRIDE > 1:\n",
    "    group = f'{group}_str{STRIDE}'\n",
    "\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "lr = 1e-5#0.0001\n",
    "group += f'_lr{lr}_dr0.2_base_toofp16'\n",
    "\n",
    "group = group.replace('.', '')\n",
    "\n",
    "runner = SupervisedRunner(input_key=('features'), input_target_key=('targets'), output_key=('logits'))\n",
    "\n",
    "experiment = 'simple'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "logdir = f\"{LOG_PATH}/{project}/{group}/{experiment}\"\n",
    "\n",
    "model = QuestModel(2)\n",
    "#     checkpoint = torch.load(CHECKPOINT)#, map_location=device)   \n",
    "\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     del checkpoint\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "loaders = get_loaders(to_balance=True)\n",
    "\n",
    "\n",
    "t_total = len(loaders['train'])//gradient_accumulation_steps*num_epochs\n",
    "warmup_proportion = 0.01\n",
    "num_warmup_steps = t_total * warmup_proportion\n",
    "\n",
    "#     criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(alpha=0.2, gamma=1.5, logits=True, reduce=True)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "#     criterion = torch.nn.BCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr = lr)\n",
    "#    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.25)\n",
    "print(f'----------------Experiment: {experiment}')\n",
    "\n",
    "runner.train(\n",
    "    fp16=dict(opt_level=\"O2\") ,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=True,\n",
    "    distributed=False if is_jupyter() else True,\n",
    "    callbacks=[\n",
    "        AlchemyLogger(\n",
    "                token=token, # your Alchemy token\n",
    "                project=project,\n",
    "                experiment=experiment,\n",
    "                group=group,\n",
    "            ),\n",
    "        MyAUCCallback()\n",
    "#             AUCCallback(input_key = 'targets',\n",
    "#                                 output_key = 'logits',\n",
    "#                                 prefix = 'auc',\n",
    "#                                 class_names = None,\n",
    "#                                 num_classes = 2,\n",
    "#                                 activation = 'Sigmoid',)\n",
    "    ],\n",
    "    main_metric='auc/_mean',\n",
    "    minimize_metric=False,\n",
    "    \n",
    "    #fp16={\"opt_level\": \"O1\"}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBertTokenizer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apex import amp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jig_env",
   "language": "python",
   "name": "jig_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "086421f7eec44c769f08f5f68fafafdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e7c81c0da784e04b530236bad005c33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18b951cd8c1447eaa1e12f972ac37d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  9%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e743ecd26cd4877a539f9bbbd23d114",
       "max": 308,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e34fafda1e234d9c981322beff1068e7",
       "value": 29
      }
     },
     "35645b239e914aee807cfdc234fc5b75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfdee9b109bc4176a0bc3a26ae38f7a3",
       "placeholder": "​",
       "style": "IPY_MODEL_086421f7eec44c769f08f5f68fafafdc",
       "value": " 29/308 [7:12:46&lt;66:18:40, 855.63s/it]"
      }
     },
     "554271f3ed5d48efa844608a0b72fdac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "685ecca481e3463d83a2465f15f7b33f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80ae0d356c3e4b1bbe511c5f5a2694b5",
       "max": 4059,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a34804b28be74d7c9972a0a13410ba77",
       "value": 4059
      }
     },
     "7f49d7d685554687bc2d131959058cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80ae0d356c3e4b1bbe511c5f5a2694b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "840e74b11eb44a58b1ed0433e924dc82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e743ecd26cd4877a539f9bbbd23d114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a34804b28be74d7c9972a0a13410ba77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a61c8f56dbd74e29a155fad0d7095f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_18b951cd8c1447eaa1e12f972ac37d42",
        "IPY_MODEL_35645b239e914aee807cfdc234fc5b75"
       ],
       "layout": "IPY_MODEL_7f49d7d685554687bc2d131959058cb3"
      }
     },
     "c9ab84b07a32426282543b5ff054ddec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_840e74b11eb44a58b1ed0433e924dc82",
       "placeholder": "​",
       "style": "IPY_MODEL_554271f3ed5d48efa844608a0b72fdac",
       "value": " 4059/4059 [14:53&lt;00:00,  4.54it/s]"
      }
     },
     "dfdee9b109bc4176a0bc3a26ae38f7a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e34fafda1e234d9c981322beff1068e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fd692cff30e343aa8afa007a05d66acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_685ecca481e3463d83a2465f15f7b33f",
        "IPY_MODEL_c9ab84b07a32426282543b5ff054ddec"
       ],
       "layout": "IPY_MODEL_0e7c81c0da784e04b530236bad005c33"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
