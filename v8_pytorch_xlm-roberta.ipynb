{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch BERT baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, I convert https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic into pytorch version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please upvote the kernel if you find it helpful**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install HuggingFace transformers & sacremoses dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are not allowed to use internet I've created required datasets and commands to setup Hugging Face Transformers setup in offline mode. You can find the required github codebases in the datasets.\n",
    "\n",
    "* sacremoses dependency - https://www.kaggle.com/axel81/sacremoses\n",
    "* transformers - https://www.kaggle.com/axel81/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# !pip install ./sacremoses/sacremoses-master/\n",
    "# !pip install ./transformers/transformers-master/\n",
    "STRIDE = 1\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        ipy_str = str(type(get_ipython()))\n",
    "        if 'zmqshell' in ipy_str:\n",
    "            return True\n",
    "        \n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports\n",
    "\n",
    "I've added imports that will be used in training too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from random import shuffle as shfl\n",
    "from auc import MyAUCCallback\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max.columns', 500)\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-10.1/lib64'\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from shutil import copyfile\n",
    "from catalyst.dl import SupervisedRunner, AlchemyLogger, CriterionCallback\n",
    "from catalyst.dl.callbacks.metrics import AUCCallback\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler,Dataset\n",
    "batch_size = 6\n",
    "token = \"d1dd16f08d518293bcbeddd313b49aa4\"\n",
    "DATA_DIR = '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on desktop\n"
     ]
    }
   ],
   "source": [
    "if os.uname()[1] == 'kb-Z370P-D3':\n",
    "    # desktop\n",
    "    LOG_PATH = '/media/ssd/logs/jigsaw'\n",
    "    SERVER = False\n",
    "    print('Working on desktop')\n",
    "elif os.uname()[1] == 'kb-server':\n",
    "    # server\n",
    "    LOG_PATH = '/home/kb/logs/jigsaw'\n",
    "    SERVER = True\n",
    "    print('Working on server')\n",
    "else:\n",
    "    raise Exception('which hostname???')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\[\n",
      "\n",
      "<>:5: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\d\n",
      "\n",
      "<>:6: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\(\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text = text.fillna(\"fillna\")#.str.lower()\n",
    "    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\(http://.*?\\s\\(http://.*\\)\",'',str(x)))\n",
    "    return text\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"havent\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"thats\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"theres\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"theyre\":  \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"}\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = tokenizer.tokenize(x)\n",
    "    return x\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x).replace(\"\\n\",\"\")\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def clean_data(df, columns: list):\n",
    "    for col in columns:\n",
    "        pass\n",
    "        df[col] = df[col].apply(lambda x: clean_numbers(x))\n",
    "        df[col] = clean(df[col])\n",
    "        df[col] = df[col].apply(lambda x: clean_text(x)) \n",
    "        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n",
    "# #         df[col] = df[col].apply(lambda x: handle_contractions(x))  \n",
    "#         df[col] = df[col].apply(lambda x: fix_quote(x))   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D ' aww !  He matches this background colour I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man ,  I ' m really not trying to edit war...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"  More I can ' t make any real suggestions o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You ,  sir ,  are my hero .  Any chance you re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation Why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  D ' aww !  He matches this background colour I...      0   \n",
       "2  000113f07ec002fd  Hey man ,  I ' m really not trying to edit war...      0   \n",
       "3  0001b41b1c6bb37e   \"  More I can ' t make any real suggestions o...      0   \n",
       "4  0001d958c54c6e35  You ,  sir ,  are my hero .  Any chance you re...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_toxic = pd.read_csv(DATA_DIR+'jigsaw-toxic-comment-train.csv')\n",
    "df_train_toxic = clean_data(df_train_toxic, ['comment_text'])\n",
    "df_train_toxic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:47.601894+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:48.488476+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                       comment_text     toxic  \\\n",
       "0  59848  This is so cool. It's like, 'would you want yo...  0.000000   \n",
       "1  59849  Thank you!! This would make my life a lot less...  0.000000   \n",
       "2  59852  This is such an urgent design problem; kudos t...  0.000000   \n",
       "3  59855  Is this something I'll be able to install on m...  0.000000   \n",
       "4  59856               haha you guys are a bunch of losers.  0.893617   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   bisexual  black  buddhist  christian  female  heterosexual  hindu  \\\n",
       "0       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "1       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "2       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "3       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "4       0.0    0.0       0.0        0.0     0.0           0.0    0.0   \n",
       "\n",
       "   homosexual_gay_or_lesbian  intellectual_or_learning_disability  jewish  \\\n",
       "0                        NaN                                  NaN     NaN   \n",
       "1                        NaN                                  NaN     NaN   \n",
       "2                        NaN                                  NaN     NaN   \n",
       "3                        NaN                                  NaN     NaN   \n",
       "4                        0.0                                 0.25     0.0   \n",
       "\n",
       "   latino  male  muslim  other_disability  other_gender  \\\n",
       "0     NaN   NaN     NaN               NaN           NaN   \n",
       "1     NaN   NaN     NaN               NaN           NaN   \n",
       "2     NaN   NaN     NaN               NaN           NaN   \n",
       "3     NaN   NaN     NaN               NaN           NaN   \n",
       "4     0.0   0.0     0.0               0.0           0.0   \n",
       "\n",
       "   other_race_or_ethnicity  other_religion  other_sexual_orientation  \\\n",
       "0                      NaN             NaN                       NaN   \n",
       "1                      NaN             NaN                       NaN   \n",
       "2                      NaN             NaN                       NaN   \n",
       "3                      NaN             NaN                       NaN   \n",
       "4                      0.0             0.0                       0.0   \n",
       "\n",
       "   physical_disability  psychiatric_or_mental_illness  transgender  white  \\\n",
       "0                  NaN                            NaN          NaN    NaN   \n",
       "1                  NaN                            NaN          NaN    NaN   \n",
       "2                  NaN                            NaN          NaN    NaN   \n",
       "3                  NaN                            NaN          NaN    NaN   \n",
       "4                  0.0                            0.0          0.0    0.0   \n",
       "\n",
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        NaN        2006   \n",
       "1  2015-09-29 10:50:42.870083+00               2        NaN        2006   \n",
       "2  2015-09-29 10:50:45.222647+00               2        NaN        2006   \n",
       "3  2015-09-29 10:50:47.601894+00               2        NaN        2006   \n",
       "4  2015-09-29 10:50:48.488476+00               2        NaN        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bias = pd.read_csv(DATA_DIR + 'jigsaw-unintended-bias-train.csv')\n",
    "df_train_bias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66651.75, 25124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df_train_toxic[df_train_toxic['toxic']==1]),len(df_train_toxic[df_train_toxic['toxic']==0])\n",
    "# len(df_train_bias[df_train_bias['toxic']<0.1])/7,len(df_train_bias[df_train_bias['toxic']>0.80])\n",
    "# len(df_train_bias[df_train_bias['toxic']==1]),len(df_train_bias[df_train_bias['toxic']==0])\n",
    "len(df_train_bias[df_train_bias['toxic']==0])/20,len(df_train_bias[df_train_bias['toxic']>0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bias_pos = df_train_bias[df_train_bias['toxic']>0.8].reset_index(drop=True)\n",
    "df_train_bias_pos['toxic'] = 1\n",
    "df_train_bias_neg = shuffle(df_train_bias[df_train_bias['toxic']<0.1].reset_index(drop=True)).reset_index(drop=True).iloc[::20]\n",
    "df_train_bias_neg['toxic'] = 0\n",
    "df_train_bias =  df_train_bias_pos.append(df_train_bias_neg).reset_index(drop=True)\n",
    "df_train_bias = clean_data(df_train_bias, ['comment_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid = shuffle(pd.read_csv(DATA_DIR + 'validation.csv'))\n",
    "# df_valid = clean_data(df_valid, ['comment_text'])\n",
    "# df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>6291</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>The world ' s free encyclopedia aimed at disse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>Spider ,  you should shut up because you are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>7648</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>And an activist  ( but not peace )  is also a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>5950</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Jedistarlogo . gif license suspicion  #  # px ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2169</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>I apologize .  I ' m not being precious but in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id lang  toxic                                       comment_text\n",
       "6291  6291   tr      0  The world ' s free encyclopedia aimed at disse...\n",
       "2010  2010   it      0  Spider ,  you should shut up because you are a...\n",
       "7648  7648   it      0  And an activist  ( but not peace )  is also a ...\n",
       "5950  5950   tr      0  Jedistarlogo . gif license suspicion  #  # px ...\n",
       "2169  2169   it      0  I apologize .  I ' m not being precious but in..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_en = shuffle(pd.read_csv(DATA_DIR + 'validation_en.csv'))\n",
    "df_valid_en = df_valid_en.drop(['comment_text'],axis=1).rename(columns={'comment_text_en':'comment_text'})\n",
    "df_valid_en = clean_data(df_valid_en, ['comment_text'])\n",
    "df_valid_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">es</th>\n",
       "      <th>0</th>\n",
       "      <td>2078</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">it</th>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">tr</th>\n",
       "      <th>0</th>\n",
       "      <td>2680</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  comment_text\n",
       "lang toxic                    \n",
       "es   0      2078          2078\n",
       "     1       422           422\n",
       "it   0      2012          2012\n",
       "     1       488           488\n",
       "tr   0      2680          2680\n",
       "     1       320           320"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_en.groupby(['lang', 'toxic']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.groupby(['lang']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  toxic\n",
       "0   0    0.5\n",
       "1   1    0.5\n",
       "2   2    0.5\n",
       "3   3    0.5\n",
       "4   4    0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'toxic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/kb/jig_env/lib/python3.7/site-packages/torchvision/_C.so'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import time\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "#import torch.utils.data as data\n",
    "from torchvision import datasets, models, transforms\n",
    "from transformers import *\n",
    "import random\n",
    "from math import floor, ceil\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "MAX_LEN = 512\n",
    "SEP_TOKEN_ID = 102\n",
    "\n",
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train_mode=True, labeled=True):\n",
    "        \n",
    "            \n",
    "        self.df = df\n",
    "        if train_mode:\n",
    "            self.labels = df.toxic.values\n",
    "            self.toxic_inds = np.where(self.labels==1)[0]\n",
    "            self.normal_inds = np.where(self.labels==0)[0]            \n",
    "            \n",
    "            \n",
    "            print(f'Here is {len(self.labels)} samples, {len(self.toxic_inds)} samples and {len(self.normal_inds)} samples')\n",
    "            print(f'Class balance is {len(self.toxic_inds)/len(self.labels):.2f}')\n",
    "            \n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "#         self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased',\n",
    "#                                                                 do_lower_case=False,\n",
    "#                                                                 do_basic_tokenize=True,\n",
    "#                                                                 never_split=None,\n",
    "#                                                                 unk_token='[UNK]',\n",
    "#                                                                 sep_token='[SEP]',\n",
    "#                                                                 pad_token='[PAD]',\n",
    "#                                                                 cls_token='[CLS]',\n",
    "#                                                                 mask_token='[MASK]',\n",
    "#                                                                 tokenize_chinese_chars=True,)\n",
    "        #distil\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        token_ids = self.get_token_ids(row)\n",
    "        \n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return {'features': token_ids, 'targets': labels}\n",
    "\n",
    "        else:\n",
    "            return {'features': token_ids}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def trim_input(self, text, max_sequence_length=MAX_LEN):\n",
    "        t = self.tokenizer.tokenize(text)\n",
    "        t_len = len(t)\n",
    "\n",
    "        if t_len + 2 > max_sequence_length:\n",
    "\n",
    "            t_new_len = int(max_sequence_length) - 2\n",
    "\n",
    "            t = t[:t_new_len]\n",
    "\n",
    "        return t\n",
    "        \n",
    "    def get_token_ids(self, row):\n",
    "        token_ids = self.tokenizer.encode(row.comment_text, max_length=MAX_LEN)\n",
    "#         print(token_ids)\n",
    "#         print(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            ids = torch.tensor(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "        else:\n",
    "            ids = torch.tensor(token_ids[:MAX_LEN])\n",
    "#         print(ids.shape)\n",
    "        \n",
    "#         t_tokens = self.trim_input(row.comment_text)\n",
    "\n",
    "# #         tokens = ['[CLS]'] + t_tokens  + ['[SEP]']+ t_tokens[-1::-1]+ ['[SEP]']\n",
    "#         tokens = ['[CLS]'] + t_tokens  + ['[SEP]']\n",
    "#         token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "#         if len(token_ids) < MAX_LEN:\n",
    "#             token_ids += [0] * (MAX_LEN - len(token_ids))\n",
    "            \n",
    "#         ids = torch.tensor(token_ids)\n",
    "#         print(ids.shape, torch.tensor(token_ids).shape)\n",
    "#         print(torch.tensor(token_ids))\n",
    "#         print(len(ids))\n",
    "        return ids\n",
    "\n",
    "    def get_label(self, row):\n",
    "#         label = torch.tensor(row[target_column].astype(np.long))\n",
    "        label = np.round(row[target_column])\n",
    "        return torch.tensor([1-label, label]).float()\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "\n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[1] for x in batch])\n",
    "            return {'features': token_ids, 'targets': labels}\n",
    "        else:\n",
    "            return {'features': token_ids}\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(QuestModel, self).__init__()\n",
    "        self.model_name = 'QuestModel'\n",
    "        \n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base', \n",
    "                                                          output_hidden_states=False, \n",
    "                                                          output_attentions=False)\n",
    "#         self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-large', \n",
    "#                                                           output_hidden_states=False, \n",
    "#                                                           output_attentions=False)\n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "    \n",
    "        self.fc = nn.Linear(768, n_classes)\n",
    "#         self.fc = nn.Linear(1024, n_classes)\n",
    "\n",
    "    def forward(self, ids):\n",
    "#         attention_mask = (ids > 0)\n",
    "#         print(ids.shape)\n",
    "        layers = self.bert_model(input_ids=ids)#, attention_mask=attention_mask)\n",
    "#         print(layers[0].shape)\n",
    "#         out = F.dropout(layers[0][:, 0, :], p=0.2, training=self.training)\n",
    "#         print(layers[0].shape)\n",
    "#         print([l.shape for l in layers])\n",
    "#         out = F.dropout(layers[-1][:, 0, :], p=0.35, training=self.training)\n",
    "        out = F.dropout(layers[0][:, 0, :], p=0.35, training=self.training)\n",
    "        logit = self.fc(out)#.unsqueeze(1)\n",
    "        return logit #, 'for_auc': logit[:, 1]}#[:,1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, dataset):\n",
    "       \n",
    "        self.toxic_inds = dataset.toxic_inds.copy()\n",
    "        self.normal_inds = dataset.normal_inds.copy()\n",
    "        \n",
    "        self.num_samples = 2*min(len(self.toxic_inds), len(self.normal_inds))\n",
    "        \n",
    "        shfl(self.toxic_inds)\n",
    "        shfl(self.normal_inds)\n",
    "        \n",
    "        self.inds = []\n",
    "        for i in range(min(len(self.toxic_inds), len(self.normal_inds))):\n",
    "            self.inds.append(self.normal_inds[i%len(self.normal_inds)])\n",
    "            self.inds.append(self.toxic_inds[i%len(self.toxic_inds)])\n",
    "\n",
    "    def __iter__(self):\n",
    "        #print ('\\tcalling Sampler:__iter__')\n",
    "        return iter(self.inds)\n",
    "\n",
    "    def __len__(self):\n",
    "        #print ('\\tcalling Sampler:__len__')\n",
    "        return self.num_samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "\n",
    "        # define custom callback\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        if self.callback_get_label:\n",
    "            return self.callback_get_label(dataset, idx)\n",
    "        else:\n",
    "            dataset.labels[idx]\n",
    "#             raise NotImplementedError\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'bias': df_train_bias,\n",
    "    'toxic': df_train_toxic,\n",
    "    'valid': df_valid_en,\n",
    "#     'valid2': df_test\n",
    "}\n",
    "def get_loaders(train_pt='bias', valid_pt='valid', test_pt=None, to_balance=True, shuffle_before=True):\n",
    "    if SERVER:\n",
    "        workers=1\n",
    "    else:\n",
    "        workers = 6\n",
    "    \n",
    "    if isinstance(train_pt, list):\n",
    "        df_train = dataframes[train_pt[0]][['comment_text', 'toxic']]\n",
    "        for pt in train_pt[1:]:\n",
    "            df_train = df_train.append(dataframes[pt][['comment_text', 'toxic']]).reset_index(drop=True)\n",
    "    else:\n",
    "        df_train = dataframes[train_pt][['comment_text', 'toxic']]\n",
    "    \n",
    "    if shuffle_before:\n",
    "        df_train = shuffle(df_train).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "#     train_dataset = QuestDataset(df_train.iloc[::STRIDE], train_mode=True)\n",
    "    \n",
    "    if STRIDE == 1:\n",
    "        train_dataset = QuestDataset(df_train.iloc[::STRIDE], train_mode=True)\n",
    "    elif STRIDE<=10:\n",
    "        df_train_pos = df_train[df_train[target_column]==1].reset_index(drop=True)\n",
    "        df_train_neg = df_train[df_train[target_column]==0].reset_index(drop=True).iloc[::STRIDE]\n",
    "        train_dataset = QuestDataset(df_train_pos.append(df_train_neg).reset_index(drop=True), train_mode=True)\n",
    "    else:\n",
    "        df_train_pos = df_train[df_train[target_column]==1].reset_index(drop=True).iloc[::int(STRIDE/10)]\n",
    "        df_train_neg = df_train[df_train[target_column]==0].reset_index(drop=True).iloc[::STRIDE]\n",
    "        train_dataset = QuestDataset(df_train_pos.append(df_train_neg).reset_index(drop=True), train_mode=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    valid_dataset = QuestDataset(dataframes[valid_pt], train_mode=False)\n",
    "    if test_pt != None:\n",
    "        test_dataset = QuestDataset(dataframes[test_pt].iloc[::STRIDE], train_mode=False)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        num_workers=workers,\n",
    "        sampler=BalancedSampler(train_dataset) if to_balance else None,#ImbalancedDatasetSampler(train_dataset) if to_balance else None,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        num_workers=workers,\n",
    "        batch_size=batch_size,\n",
    "    )    \n",
    "    if test_pt != None:\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            num_workers=workers,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "       \n",
    "    loaders = {}\n",
    "    loaders['train'] = train_loader\n",
    "    \n",
    "    loaders['valid'] = valid_loader\n",
    "    \n",
    "    if test_pt != None:\n",
    "        loaders['valid2'] = test_loader\n",
    "    \n",
    "    for i in ['es', 'it', 'tr']:\n",
    "        df = dataframes[valid_pt]\n",
    "        df = df[df['lang']==i]\n",
    "\n",
    "        loaders['valid_'+ i] = DataLoader(\n",
    "            QuestDataset(df, train_mode=False),\n",
    "            num_workers=workers,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is 315403 samples, 46508 samples and 268895 samples\n",
      "Class balance is 0.15\n",
      "----------------Experiment: learn_both\n",
      "1/300 * Epoch (train):   0% 1/15503 [00:00<2:25:05,  1.78it/s, loss=0.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 * Epoch (train):  46% 7193/15503 [30:14<34:45,  3.99it/s, loss=0.085]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connection.py\", line 157, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: [Errno 110] Connection timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connection.py\", line 300, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7ff5016f50d0>: Failed to establish a new connection: [Errno 110] Connection timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='log.alchemy.host', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7ff5016f50d0>: Failed to establish a new connection: [Errno 110] Connection timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kb/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/kb/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/alchemy/logger.py\", line 78, in _run_worker\n",
      "    requests.post(self._url, json=batch, headers=headers)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/requests/api.py\", line 116, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/kb/jig_env/lib/python3.7/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='log.alchemy.host', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7ff5016f50d0>: Failed to establish a new connection: [Errno 110] Connection timed out'))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 * Epoch (train): 100% 15503/15503 [1:05:01<00:00,  3.97it/s, loss=0.052]\n",
      "1/300 * Epoch (valid): 100% 1334/1334 [01:37<00:00, 13.63it/s, loss=0.025]\n",
      "1/300 * Epoch (valid_es): 100% 417/417 [00:30<00:00, 13.51it/s, loss=0.041]\n",
      "1/300 * Epoch (valid_it): 100% 417/417 [00:30<00:00, 13.52it/s, loss=0.025]\n",
      "1/300 * Epoch (valid_tr): 100% 500/500 [00:36<00:00, 13.54it/s, loss=0.025]\n",
      "[2020-04-27 01:14:38,451] \n",
      "1/300 * Epoch 1 (_base): lr=6.450e-10 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): auc/_mean=0.5049 | auc/class_0=0.5049 | loss=0.0604\n",
      "1/300 * Epoch 1 (valid): auc/_mean=0.4635 | auc/class_0=0.4635 | es_auc/_mean=0.4730 | es_auc/class_0=0.4730 | es_loss=0.0356 | it_auc/_mean=0.4751 | it_auc/class_0=0.4751 | it_loss=0.0372 | loss=0.0346 | tr_auc/_mean=0.4889 | tr_auc/class_0=0.4889 | tr_loss=0.0316\n",
      "1/300 * Epoch 1 (valid_es): auc/_mean=0.4730 | auc/class_0=0.4730 | loss=0.0356\n",
      "1/300 * Epoch 1 (valid_it): auc/_mean=0.4751 | auc/class_0=0.4751 | loss=0.0372\n",
      "1/300 * Epoch 1 (valid_tr): auc/_mean=0.4889 | auc/class_0=0.4889 | loss=0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:224: UserWarning:\n",
      "\n",
      "To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/300 * Epoch (train): 100% 15503/15503 [1:05:02<00:00,  3.97it/s, loss=0.068]\n",
      "2/300 * Epoch (valid): 100% 1334/1334 [01:38<00:00, 13.58it/s, loss=0.025]\n",
      "2/300 * Epoch (valid_es): 100% 417/417 [00:30<00:00, 13.48it/s, loss=0.041]\n",
      "2/300 * Epoch (valid_it): 100% 417/417 [00:30<00:00, 13.48it/s, loss=0.025]\n",
      "2/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.51it/s, loss=0.025]\n",
      "[2020-04-27 02:23:30,595] \n",
      "2/300 * Epoch 2 (_base): lr=1.290e-09 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): auc/_mean=0.5045 | auc/class_0=0.5045 | loss=0.0604\n",
      "2/300 * Epoch 2 (valid): auc/_mean=0.4639 | auc/class_0=0.4639 | es_auc/_mean=0.4731 | es_auc/class_0=0.4731 | es_loss=0.0356 | it_auc/_mean=0.4754 | it_auc/class_0=0.4754 | it_loss=0.0373 | loss=0.0347 | tr_auc/_mean=0.4895 | tr_auc/class_0=0.4895 | tr_loss=0.0317\n",
      "2/300 * Epoch 2 (valid_es): auc/_mean=0.4731 | auc/class_0=0.4731 | loss=0.0356\n",
      "2/300 * Epoch 2 (valid_it): auc/_mean=0.4754 | auc/class_0=0.4754 | loss=0.0373\n",
      "2/300 * Epoch 2 (valid_tr): auc/_mean=0.4895 | auc/class_0=0.4895 | loss=0.0317\n",
      "3/300 * Epoch (train): 100% 15503/15503 [1:05:06<00:00,  3.97it/s, loss=0.057]\n",
      "3/300 * Epoch (valid): 100% 1334/1334 [01:38<00:00, 13.55it/s, loss=0.025]\n",
      "3/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.44it/s, loss=0.041]\n",
      "3/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.43it/s, loss=0.025]\n",
      "3/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.45it/s, loss=0.025]\n",
      "[2020-04-27 03:32:54,003] \n",
      "3/300 * Epoch 3 (_base): lr=1.935e-09 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): auc/_mean=0.5014 | auc/class_0=0.5014 | loss=0.0604\n",
      "3/300 * Epoch 3 (valid): auc/_mean=0.4650 | auc/class_0=0.4650 | es_auc/_mean=0.4736 | es_auc/class_0=0.4736 | es_loss=0.0357 | it_auc/_mean=0.4767 | it_auc/class_0=0.4767 | it_loss=0.0373 | loss=0.0348 | tr_auc/_mean=0.4916 | tr_auc/class_0=0.4916 | tr_loss=0.0318\n",
      "3/300 * Epoch 3 (valid_es): auc/_mean=0.4736 | auc/class_0=0.4736 | loss=0.0357\n",
      "3/300 * Epoch 3 (valid_it): auc/_mean=0.4767 | auc/class_0=0.4767 | loss=0.0373\n",
      "3/300 * Epoch 3 (valid_tr): auc/_mean=0.4916 | auc/class_0=0.4916 | loss=0.0318\n",
      "4/300 * Epoch (train): 100% 15503/15503 [1:05:12<00:00,  3.96it/s, loss=0.068]\n",
      "4/300 * Epoch (valid): 100% 1334/1334 [01:38<00:00, 13.54it/s, loss=0.026]\n",
      "4/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.42it/s, loss=0.041]\n",
      "4/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.41it/s, loss=0.026]\n",
      "4/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.45it/s, loss=0.026]\n",
      "[2020-04-27 04:42:22,699] \n",
      "4/300 * Epoch 4 (_base): lr=2.580e-09 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): auc/_mean=0.5056 | auc/class_0=0.5056 | loss=0.0598\n",
      "4/300 * Epoch 4 (valid): auc/_mean=0.4676 | auc/class_0=0.4676 | es_auc/_mean=0.4750 | es_auc/class_0=0.4750 | es_loss=0.0359 | it_auc/_mean=0.4791 | it_auc/class_0=0.4791 | it_loss=0.0375 | loss=0.0350 | tr_auc/_mean=0.4968 | tr_auc/class_0=0.4968 | tr_loss=0.0321\n",
      "4/300 * Epoch 4 (valid_es): auc/_mean=0.4750 | auc/class_0=0.4750 | loss=0.0359\n",
      "4/300 * Epoch 4 (valid_it): auc/_mean=0.4791 | auc/class_0=0.4791 | loss=0.0375\n",
      "4/300 * Epoch 4 (valid_tr): auc/_mean=0.4968 | auc/class_0=0.4968 | loss=0.0321\n",
      "5/300 * Epoch (train): 100% 15503/15503 [1:05:13<00:00,  3.96it/s, loss=0.050]\n",
      "5/300 * Epoch (valid): 100% 1334/1334 [01:38<00:00, 13.53it/s, loss=0.026]\n",
      "5/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.42it/s, loss=0.041]\n",
      "5/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.42it/s, loss=0.026]\n",
      "5/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.45it/s, loss=0.026]\n",
      "[2020-04-27 05:51:53,140] \n",
      "5/300 * Epoch 5 (_base): lr=3.225e-09 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): auc/_mean=0.5034 | auc/class_0=0.5034 | loss=0.0594\n",
      "5/300 * Epoch 5 (valid): auc/_mean=0.4715 | auc/class_0=0.4715 | es_auc/_mean=0.4790 | es_auc/class_0=0.4790 | es_loss=0.0361 | it_auc/_mean=0.4815 | it_auc/class_0=0.4815 | it_loss=0.0377 | loss=0.0352 | tr_auc/_mean=0.5033 | tr_auc/class_0=0.5033 | tr_loss=0.0325\n",
      "5/300 * Epoch 5 (valid_es): auc/_mean=0.4790 | auc/class_0=0.4790 | loss=0.0361\n",
      "5/300 * Epoch 5 (valid_it): auc/_mean=0.4815 | auc/class_0=0.4815 | loss=0.0377\n",
      "5/300 * Epoch 5 (valid_tr): auc/_mean=0.5033 | auc/class_0=0.5033 | loss=0.0325\n",
      "6/300 * Epoch (train): 100% 15503/15503 [1:05:27<00:00,  3.95it/s, loss=0.057]\n",
      "6/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.40it/s, loss=0.027]\n",
      "6/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.041]\n",
      "6/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.28it/s, loss=0.027]\n",
      "6/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.027]\n",
      "[2020-04-27 07:01:39,041] \n",
      "6/300 * Epoch 6 (_base): lr=3.870e-09 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): auc/_mean=0.5023 | auc/class_0=0.5023 | loss=0.0590\n",
      "6/300 * Epoch 6 (valid): auc/_mean=0.4753 | auc/class_0=0.4753 | es_auc/_mean=0.4829 | es_auc/class_0=0.4829 | es_loss=0.0365 | it_auc/_mean=0.4839 | it_auc/class_0=0.4839 | it_loss=0.0379 | loss=0.0356 | tr_auc/_mean=0.5093 | tr_auc/class_0=0.5093 | tr_loss=0.0329\n",
      "6/300 * Epoch 6 (valid_es): auc/_mean=0.4829 | auc/class_0=0.4829 | loss=0.0365\n",
      "6/300 * Epoch 6 (valid_it): auc/_mean=0.4839 | auc/class_0=0.4839 | loss=0.0379\n",
      "6/300 * Epoch 6 (valid_tr): auc/_mean=0.5093 | auc/class_0=0.5093 | loss=0.0329\n",
      "7/300 * Epoch (train): 100% 15503/15503 [1:05:47<00:00,  3.93it/s, loss=0.056]\n",
      "7/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.43it/s, loss=0.028]\n",
      "7/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.33it/s, loss=0.041]\n",
      "7/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.028]\n",
      "7/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.34it/s, loss=0.028]\n",
      "[2020-04-27 08:11:45,923] \n",
      "7/300 * Epoch 7 (_base): lr=4.515e-09 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): auc/_mean=0.5013 | auc/class_0=0.5013 | loss=0.0584\n",
      "7/300 * Epoch 7 (valid): auc/_mean=0.4790 | auc/class_0=0.4790 | es_auc/_mean=0.4865 | es_auc/class_0=0.4865 | es_loss=0.0368 | it_auc/_mean=0.4859 | it_auc/class_0=0.4859 | it_loss=0.0382 | loss=0.0360 | tr_auc/_mean=0.5148 | tr_auc/class_0=0.5148 | tr_loss=0.0334\n",
      "7/300 * Epoch 7 (valid_es): auc/_mean=0.4865 | auc/class_0=0.4865 | loss=0.0368\n",
      "7/300 * Epoch 7 (valid_it): auc/_mean=0.4859 | auc/class_0=0.4859 | loss=0.0382\n",
      "7/300 * Epoch 7 (valid_tr): auc/_mean=0.5148 | auc/class_0=0.5148 | loss=0.0334\n",
      "8/300 * Epoch (train): 100% 15503/15503 [1:05:39<00:00,  3.94it/s, loss=0.026]\n",
      "8/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.029]\n",
      "8/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.041]\n",
      "8/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.029]\n",
      "8/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.028]\n",
      "[2020-04-27 09:21:43,443] \n",
      "8/300 * Epoch 8 (_base): lr=5.160e-09 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): auc/_mean=0.5026 | auc/class_0=0.5026 | loss=0.0579\n",
      "8/300 * Epoch 8 (valid): auc/_mean=0.4828 | auc/class_0=0.4828 | es_auc/_mean=0.4897 | es_auc/class_0=0.4897 | es_loss=0.0372 | it_auc/_mean=0.4893 | it_auc/class_0=0.4893 | it_loss=0.0385 | loss=0.0363 | tr_auc/_mean=0.5185 | tr_auc/class_0=0.5185 | tr_loss=0.0339\n",
      "8/300 * Epoch 8 (valid_es): auc/_mean=0.4897 | auc/class_0=0.4897 | loss=0.0372\n",
      "8/300 * Epoch 8 (valid_it): auc/_mean=0.4893 | auc/class_0=0.4893 | loss=0.0385\n",
      "8/300 * Epoch 8 (valid_tr): auc/_mean=0.5185 | auc/class_0=0.5185 | loss=0.0339\n",
      "9/300 * Epoch (train): 100% 15503/15503 [1:05:43<00:00,  3.93it/s, loss=0.053]\n",
      "9/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.36it/s, loss=0.029]\n",
      "9/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.23it/s, loss=0.042]\n",
      "9/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.26it/s, loss=0.029]\n",
      "9/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.25it/s, loss=0.029]\n",
      "[2020-04-27 10:31:45,593] \n",
      "9/300 * Epoch 9 (_base): lr=5.805e-09 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): auc/_mean=0.5069 | auc/class_0=0.5069 | loss=0.0576\n",
      "9/300 * Epoch 9 (valid): auc/_mean=0.4864 | auc/class_0=0.4864 | es_auc/_mean=0.4942 | es_auc/class_0=0.4942 | es_loss=0.0375 | it_auc/_mean=0.4927 | it_auc/class_0=0.4927 | it_loss=0.0387 | loss=0.0367 | tr_auc/_mean=0.5199 | tr_auc/class_0=0.5199 | tr_loss=0.0344\n",
      "9/300 * Epoch 9 (valid_es): auc/_mean=0.4942 | auc/class_0=0.4942 | loss=0.0375\n",
      "9/300 * Epoch 9 (valid_it): auc/_mean=0.4927 | auc/class_0=0.4927 | loss=0.0387\n",
      "9/300 * Epoch 9 (valid_tr): auc/_mean=0.5199 | auc/class_0=0.5199 | loss=0.0344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/300 * Epoch (train): 100% 15503/15503 [1:05:44<00:00,  3.93it/s, loss=0.071]\n",
      "10/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.030]\n",
      "10/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.29it/s, loss=0.042]\n",
      "10/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.29it/s, loss=0.030]\n",
      "10/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.30it/s, loss=0.030]\n",
      "[2020-04-27 11:41:47,665] \n",
      "10/300 * Epoch 10 (_base): lr=6.450e-09 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): auc/_mean=0.5050 | auc/class_0=0.5050 | loss=0.0575\n",
      "10/300 * Epoch 10 (valid): auc/_mean=0.4907 | auc/class_0=0.4907 | es_auc/_mean=0.4979 | es_auc/class_0=0.4979 | es_loss=0.0378 | it_auc/_mean=0.4960 | it_auc/class_0=0.4960 | it_loss=0.0390 | loss=0.0371 | tr_auc/_mean=0.5237 | tr_auc/class_0=0.5237 | tr_loss=0.0348\n",
      "10/300 * Epoch 10 (valid_es): auc/_mean=0.4979 | auc/class_0=0.4979 | loss=0.0378\n",
      "10/300 * Epoch 10 (valid_it): auc/_mean=0.4960 | auc/class_0=0.4960 | loss=0.0390\n",
      "10/300 * Epoch 10 (valid_tr): auc/_mean=0.5237 | auc/class_0=0.5237 | loss=0.0348\n",
      "11/300 * Epoch (train): 100% 15503/15503 [1:06:00<00:00,  3.91it/s, loss=0.063]\n",
      "11/300 * Epoch (valid): 100% 1334/1334 [01:40<00:00, 13.22it/s, loss=0.031]\n",
      "11/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.11it/s, loss=0.042]\n",
      "11/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.13it/s, loss=0.031]\n",
      "11/300 * Epoch (valid_tr): 100% 500/500 [00:38<00:00, 13.13it/s, loss=0.030]\n",
      "[2020-04-27 12:52:10,793] \n",
      "11/300 * Epoch 11 (_base): lr=7.095e-09 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): auc/_mean=0.5052 | auc/class_0=0.5052 | loss=0.0573\n",
      "11/300 * Epoch 11 (valid): auc/_mean=0.4935 | auc/class_0=0.4935 | es_auc/_mean=0.5014 | es_auc/class_0=0.5014 | es_loss=0.0381 | it_auc/_mean=0.4976 | it_auc/class_0=0.4976 | it_loss=0.0392 | loss=0.0374 | tr_auc/_mean=0.5249 | tr_auc/class_0=0.5249 | tr_loss=0.0352\n",
      "11/300 * Epoch 11 (valid_es): auc/_mean=0.5014 | auc/class_0=0.5014 | loss=0.0381\n",
      "11/300 * Epoch 11 (valid_it): auc/_mean=0.4976 | auc/class_0=0.4976 | loss=0.0392\n",
      "11/300 * Epoch 11 (valid_tr): auc/_mean=0.5249 | auc/class_0=0.5249 | loss=0.0352\n",
      "12/300 * Epoch (train): 100% 15503/15503 [1:05:50<00:00,  3.92it/s, loss=0.068]\n",
      "12/300 * Epoch (valid): 100% 1334/1334 [01:40<00:00, 13.31it/s, loss=0.031]\n",
      "12/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.20it/s, loss=0.042]\n",
      "12/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.21it/s, loss=0.031]\n",
      "12/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.19it/s, loss=0.031]\n",
      "[2020-04-27 14:02:20,972] \n",
      "12/300 * Epoch 12 (_base): lr=7.740e-09 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): auc/_mean=0.5067 | auc/class_0=0.5067 | loss=0.0571\n",
      "12/300 * Epoch 12 (valid): auc/_mean=0.4975 | auc/class_0=0.4975 | es_auc/_mean=0.5081 | es_auc/class_0=0.5081 | es_loss=0.0384 | it_auc/_mean=0.4997 | it_auc/class_0=0.4997 | it_loss=0.0395 | loss=0.0377 | tr_auc/_mean=0.5196 | tr_auc/class_0=0.5196 | tr_loss=0.0356\n",
      "12/300 * Epoch 12 (valid_es): auc/_mean=0.5081 | auc/class_0=0.5081 | loss=0.0384\n",
      "12/300 * Epoch 12 (valid_it): auc/_mean=0.4997 | auc/class_0=0.4997 | loss=0.0395\n",
      "12/300 * Epoch 12 (valid_tr): auc/_mean=0.5196 | auc/class_0=0.5196 | loss=0.0356\n",
      "13/300 * Epoch (train): 100% 15503/15503 [1:05:50<00:00,  3.92it/s, loss=0.056]\n",
      "13/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.37it/s, loss=0.032]\n",
      "13/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.26it/s, loss=0.043]\n",
      "13/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.27it/s, loss=0.032]\n",
      "13/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.28it/s, loss=0.032]\n",
      "[2020-04-27 15:12:31,855] \n",
      "13/300 * Epoch 13 (_base): lr=8.385e-09 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): auc/_mean=0.5088 | auc/class_0=0.5088 | loss=0.0568\n",
      "13/300 * Epoch 13 (valid): auc/_mean=0.5078 | auc/class_0=0.5078 | es_auc/_mean=0.5241 | es_auc/class_0=0.5241 | es_loss=0.0390 | it_auc/_mean=0.5121 | it_auc/class_0=0.5121 | it_loss=0.0400 | loss=0.0383 | tr_auc/_mean=0.4807 | tr_auc/class_0=0.4807 | tr_loss=0.0362\n",
      "13/300 * Epoch 13 (valid_es): auc/_mean=0.5241 | auc/class_0=0.5241 | loss=0.0390\n",
      "13/300 * Epoch 13 (valid_it): auc/_mean=0.5121 | auc/class_0=0.5121 | loss=0.0400\n",
      "13/300 * Epoch 13 (valid_tr): auc/_mean=0.4807 | auc/class_0=0.4807 | loss=0.0362\n",
      "14/300 * Epoch (train): 100% 15503/15503 [1:05:46<00:00,  3.93it/s, loss=0.082]\n",
      "14/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.35it/s, loss=0.036]\n",
      "14/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.22it/s, loss=0.046]\n",
      "14/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.24it/s, loss=0.037]\n",
      "14/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.24it/s, loss=0.035]\n",
      "[2020-04-27 16:22:38,360] \n",
      "14/300 * Epoch 14 (_base): lr=9.031e-09 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): auc/_mean=0.5190 | auc/class_0=0.5190 | loss=0.0560\n",
      "14/300 * Epoch 14 (valid): auc/_mean=0.5336 | auc/class_0=0.5336 | es_auc/_mean=0.5399 | es_auc/class_0=0.5399 | es_loss=0.0414 | it_auc/_mean=0.5292 | it_auc/class_0=0.5292 | it_loss=0.0418 | loss=0.0403 | tr_auc/_mean=0.5035 | tr_auc/class_0=0.5035 | tr_loss=0.0381\n",
      "14/300 * Epoch 14 (valid_es): auc/_mean=0.5399 | auc/class_0=0.5399 | loss=0.0414\n",
      "14/300 * Epoch 14 (valid_it): auc/_mean=0.5292 | auc/class_0=0.5292 | loss=0.0418\n",
      "14/300 * Epoch 14 (valid_tr): auc/_mean=0.5035 | auc/class_0=0.5035 | loss=0.0381\n",
      "15/300 * Epoch (train): 100% 15503/15503 [1:05:46<00:00,  3.93it/s, loss=0.053]\n",
      "15/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.38it/s, loss=0.038]\n",
      "15/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.27it/s, loss=0.045]\n",
      "15/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.26it/s, loss=0.038]\n",
      "15/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.28it/s, loss=0.036]\n",
      "[2020-04-27 17:32:43,865] \n",
      "15/300 * Epoch 15 (_base): lr=9.676e-09 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): auc/_mean=0.5294 | auc/class_0=0.5294 | loss=0.0553\n",
      "15/300 * Epoch 15 (valid): auc/_mean=0.5307 | auc/class_0=0.5307 | es_auc/_mean=0.5413 | es_auc/class_0=0.5413 | es_loss=0.0409 | it_auc/_mean=0.5349 | it_auc/class_0=0.5349 | it_loss=0.0415 | loss=0.0400 | tr_auc/_mean=0.4932 | tr_auc/class_0=0.4932 | tr_loss=0.0381\n",
      "15/300 * Epoch 15 (valid_es): auc/_mean=0.5413 | auc/class_0=0.5413 | loss=0.0409\n",
      "15/300 * Epoch 15 (valid_it): auc/_mean=0.5349 | auc/class_0=0.5349 | loss=0.0415\n",
      "15/300 * Epoch 15 (valid_tr): auc/_mean=0.4932 | auc/class_0=0.4932 | loss=0.0381\n",
      "16/300 * Epoch (train): 100% 15503/15503 [1:05:45<00:00,  3.93it/s, loss=0.058]\n",
      "16/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.039]\n",
      "16/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.045]\n",
      "16/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.29it/s, loss=0.038]\n",
      "16/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.30it/s, loss=0.036]\n",
      "[2020-04-27 18:42:12,904] \n",
      "16/300 * Epoch 16 (_base): lr=1.032e-08 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): auc/_mean=0.5309 | auc/class_0=0.5309 | loss=0.0550\n",
      "16/300 * Epoch 16 (valid): auc/_mean=0.5285 | auc/class_0=0.5285 | es_auc/_mean=0.5489 | es_auc/class_0=0.5489 | es_loss=0.0406 | it_auc/_mean=0.5361 | it_auc/class_0=0.5361 | it_loss=0.0413 | loss=0.0398 | tr_auc/_mean=0.4831 | tr_auc/class_0=0.4831 | tr_loss=0.0380\n",
      "16/300 * Epoch 16 (valid_es): auc/_mean=0.5489 | auc/class_0=0.5489 | loss=0.0406\n",
      "16/300 * Epoch 16 (valid_it): auc/_mean=0.5361 | auc/class_0=0.5361 | loss=0.0413\n",
      "16/300 * Epoch 16 (valid_tr): auc/_mean=0.4831 | auc/class_0=0.4831 | loss=0.0380\n",
      "17/300 * Epoch (train): 100% 15503/15503 [1:05:45<00:00,  3.93it/s, loss=0.061]\n",
      "17/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.38it/s, loss=0.042]\n",
      "17/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.25it/s, loss=0.045]\n",
      "17/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.25it/s, loss=0.042]\n",
      "17/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.26it/s, loss=0.037]\n",
      "[2020-04-27 19:51:42,083] \n",
      "17/300 * Epoch 17 (_base): lr=1.097e-08 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): auc/_mean=0.5391 | auc/class_0=0.5391 | loss=0.0545\n",
      "17/300 * Epoch 17 (valid): auc/_mean=0.5244 | auc/class_0=0.5244 | es_auc/_mean=0.5511 | es_auc/class_0=0.5511 | es_loss=0.0406 | it_auc/_mean=0.5380 | it_auc/class_0=0.5380 | it_loss=0.0413 | loss=0.0399 | tr_auc/_mean=0.4692 | tr_auc/class_0=0.4692 | tr_loss=0.0381\n",
      "17/300 * Epoch 17 (valid_es): auc/_mean=0.5511 | auc/class_0=0.5511 | loss=0.0406\n",
      "17/300 * Epoch 17 (valid_it): auc/_mean=0.5380 | auc/class_0=0.5380 | loss=0.0413\n",
      "17/300 * Epoch 17 (valid_tr): auc/_mean=0.4692 | auc/class_0=0.4692 | loss=0.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/300 * Epoch (train): 100% 15503/15503 [1:05:48<00:00,  3.93it/s, loss=0.052]\n",
      "18/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.40it/s, loss=0.041]\n",
      "18/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.29it/s, loss=0.045]\n",
      "18/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.27it/s, loss=0.044]\n",
      "18/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.037]\n",
      "[2020-04-27 21:01:13,429] \n",
      "18/300 * Epoch 18 (_base): lr=1.161e-08 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): auc/_mean=0.5346 | auc/class_0=0.5346 | loss=0.0545\n",
      "18/300 * Epoch 18 (valid): auc/_mean=0.5196 | auc/class_0=0.5196 | es_auc/_mean=0.5420 | es_auc/class_0=0.5420 | es_loss=0.0405 | it_auc/_mean=0.5412 | it_auc/class_0=0.5412 | it_loss=0.0411 | loss=0.0398 | tr_auc/_mean=0.4688 | tr_auc/class_0=0.4688 | tr_loss=0.0381\n",
      "18/300 * Epoch 18 (valid_es): auc/_mean=0.5420 | auc/class_0=0.5420 | loss=0.0405\n",
      "18/300 * Epoch 18 (valid_it): auc/_mean=0.5412 | auc/class_0=0.5412 | loss=0.0411\n",
      "18/300 * Epoch 18 (valid_tr): auc/_mean=0.4688 | auc/class_0=0.4688 | loss=0.0381\n",
      "19/300 * Epoch (train): 100% 15503/15503 [1:05:35<00:00,  3.94it/s, loss=0.044]\n",
      "19/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.041]\n",
      "19/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.044]\n",
      "19/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.043]\n",
      "19/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.32it/s, loss=0.037]\n",
      "[2020-04-27 22:10:31,881] \n",
      "19/300 * Epoch 19 (_base): lr=1.226e-08 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): auc/_mean=0.5355 | auc/class_0=0.5355 | loss=0.0542\n",
      "19/300 * Epoch 19 (valid): auc/_mean=0.5197 | auc/class_0=0.5197 | es_auc/_mean=0.5417 | es_auc/class_0=0.5417 | es_loss=0.0404 | it_auc/_mean=0.5402 | it_auc/class_0=0.5402 | it_loss=0.0411 | loss=0.0398 | tr_auc/_mean=0.4742 | tr_auc/class_0=0.4742 | tr_loss=0.0381\n",
      "19/300 * Epoch 19 (valid_es): auc/_mean=0.5417 | auc/class_0=0.5417 | loss=0.0404\n",
      "19/300 * Epoch 19 (valid_it): auc/_mean=0.5402 | auc/class_0=0.5402 | loss=0.0411\n",
      "19/300 * Epoch 19 (valid_tr): auc/_mean=0.4742 | auc/class_0=0.4742 | loss=0.0381\n",
      "20/300 * Epoch (train): 100% 15503/15503 [1:05:39<00:00,  3.94it/s, loss=0.065]\n",
      "20/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.37it/s, loss=0.044]\n",
      "20/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.24it/s, loss=0.044]\n",
      "20/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.26it/s, loss=0.042]\n",
      "20/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.23it/s, loss=0.038]\n",
      "[2020-04-27 23:19:55,126] \n",
      "20/300 * Epoch 20 (_base): lr=1.290e-08 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): auc/_mean=0.5387 | auc/class_0=0.5387 | loss=0.0540\n",
      "20/300 * Epoch 20 (valid): auc/_mean=0.5183 | auc/class_0=0.5183 | es_auc/_mean=0.5375 | es_auc/class_0=0.5375 | es_loss=0.0406 | it_auc/_mean=0.5331 | it_auc/class_0=0.5331 | it_loss=0.0413 | loss=0.0400 | tr_auc/_mean=0.4879 | tr_auc/class_0=0.4879 | tr_loss=0.0383\n",
      "20/300 * Epoch 20 (valid_es): auc/_mean=0.5375 | auc/class_0=0.5375 | loss=0.0406\n",
      "20/300 * Epoch 20 (valid_it): auc/_mean=0.5331 | auc/class_0=0.5331 | loss=0.0413\n",
      "20/300 * Epoch 20 (valid_tr): auc/_mean=0.4879 | auc/class_0=0.4879 | loss=0.0383\n",
      "21/300 * Epoch (train): 100% 15503/15503 [1:05:36<00:00,  3.94it/s, loss=0.053]\n",
      "21/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.45it/s, loss=0.047]\n",
      "21/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.35it/s, loss=0.044]\n",
      "21/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.34it/s, loss=0.038]\n",
      "21/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.36it/s, loss=0.040]\n",
      "[2020-04-28 00:29:15,184] \n",
      "21/300 * Epoch 21 (_base): lr=1.355e-08 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): auc/_mean=0.5418 | auc/class_0=0.5418 | loss=0.0538\n",
      "21/300 * Epoch 21 (valid): auc/_mean=0.5090 | auc/class_0=0.5090 | es_auc/_mean=0.5262 | es_auc/class_0=0.5262 | es_loss=0.0405 | it_auc/_mean=0.5203 | it_auc/class_0=0.5203 | it_loss=0.0412 | loss=0.0399 | tr_auc/_mean=0.4922 | tr_auc/class_0=0.4922 | tr_loss=0.0384\n",
      "21/300 * Epoch 21 (valid_es): auc/_mean=0.5262 | auc/class_0=0.5262 | loss=0.0405\n",
      "21/300 * Epoch 21 (valid_it): auc/_mean=0.5203 | auc/class_0=0.5203 | loss=0.0412\n",
      "21/300 * Epoch 21 (valid_tr): auc/_mean=0.4922 | auc/class_0=0.4922 | loss=0.0384\n",
      "22/300 * Epoch (train): 100% 15503/15503 [1:05:32<00:00,  3.94it/s, loss=0.036]\n",
      "22/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.43it/s, loss=0.047]\n",
      "22/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.33it/s, loss=0.042]\n",
      "22/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.33it/s, loss=0.035]\n",
      "22/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.35it/s, loss=0.041]\n",
      "[2020-04-28 01:38:30,330] \n",
      "22/300 * Epoch 22 (_base): lr=1.419e-08 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): auc/_mean=0.5427 | auc/class_0=0.5427 | loss=0.0537\n",
      "22/300 * Epoch 22 (valid): auc/_mean=0.4964 | auc/class_0=0.4964 | es_auc/_mean=0.5119 | es_auc/class_0=0.5119 | es_loss=0.0405 | it_auc/_mean=0.4999 | it_auc/class_0=0.4999 | it_loss=0.0413 | loss=0.0399 | tr_auc/_mean=0.5022 | tr_auc/class_0=0.5022 | tr_loss=0.0384\n",
      "22/300 * Epoch 22 (valid_es): auc/_mean=0.5119 | auc/class_0=0.5119 | loss=0.0405\n",
      "22/300 * Epoch 22 (valid_it): auc/_mean=0.4999 | auc/class_0=0.4999 | loss=0.0413\n",
      "22/300 * Epoch 22 (valid_tr): auc/_mean=0.5022 | auc/class_0=0.5022 | loss=0.0384\n",
      "23/300 * Epoch (train): 100% 15503/15503 [1:05:30<00:00,  3.94it/s, loss=0.037]\n",
      "23/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.47it/s, loss=0.039]\n",
      "23/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.36it/s, loss=0.042]\n",
      "23/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.36it/s, loss=0.032]\n",
      "23/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.38it/s, loss=0.038]\n",
      "[2020-04-28 02:47:42,913] \n",
      "23/300 * Epoch 23 (_base): lr=1.484e-08 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): auc/_mean=0.5404 | auc/class_0=0.5404 | loss=0.0536\n",
      "23/300 * Epoch 23 (valid): auc/_mean=0.4751 | auc/class_0=0.4751 | es_auc/_mean=0.5046 | es_auc/class_0=0.5046 | es_loss=0.0398 | it_auc/_mean=0.4704 | it_auc/class_0=0.4704 | it_loss=0.0409 | loss=0.0393 | tr_auc/_mean=0.4842 | tr_auc/class_0=0.4842 | tr_loss=0.0377\n",
      "23/300 * Epoch 23 (valid_es): auc/_mean=0.5046 | auc/class_0=0.5046 | loss=0.0398\n",
      "23/300 * Epoch 23 (valid_it): auc/_mean=0.4704 | auc/class_0=0.4704 | loss=0.0409\n",
      "23/300 * Epoch 23 (valid_tr): auc/_mean=0.4842 | auc/class_0=0.4842 | loss=0.0377\n",
      "24/300 * Epoch (train): 100% 15503/15503 [1:05:26<00:00,  3.95it/s, loss=0.029]\n",
      "24/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.47it/s, loss=0.041]\n",
      "24/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.36it/s, loss=0.042]\n",
      "24/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.37it/s, loss=0.033]\n",
      "24/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.37it/s, loss=0.039]\n",
      "[2020-04-28 03:56:52,313] \n",
      "24/300 * Epoch 24 (_base): lr=1.548e-08 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): auc/_mean=0.5441 | auc/class_0=0.5441 | loss=0.0534\n",
      "24/300 * Epoch 24 (valid): auc/_mean=0.4806 | auc/class_0=0.4806 | es_auc/_mean=0.5071 | es_auc/class_0=0.5071 | es_loss=0.0401 | it_auc/_mean=0.4783 | it_auc/class_0=0.4783 | it_loss=0.0412 | loss=0.0397 | tr_auc/_mean=0.4856 | tr_auc/class_0=0.4856 | tr_loss=0.0381\n",
      "24/300 * Epoch 24 (valid_es): auc/_mean=0.5071 | auc/class_0=0.5071 | loss=0.0401\n",
      "24/300 * Epoch 24 (valid_it): auc/_mean=0.4783 | auc/class_0=0.4783 | loss=0.0412\n",
      "24/300 * Epoch 24 (valid_tr): auc/_mean=0.4856 | auc/class_0=0.4856 | loss=0.0381\n",
      "25/300 * Epoch (train): 100% 15503/15503 [1:05:25<00:00,  3.95it/s, loss=0.054]\n",
      "25/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.47it/s, loss=0.039]\n",
      "25/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.35it/s, loss=0.042]\n",
      "25/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.35it/s, loss=0.032]\n",
      "25/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.36it/s, loss=0.038]\n",
      "[2020-04-28 05:06:00,398] \n",
      "25/300 * Epoch 25 (_base): lr=1.613e-08 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): auc/_mean=0.5451 | auc/class_0=0.5451 | loss=0.0533\n",
      "25/300 * Epoch 25 (valid): auc/_mean=0.4761 | auc/class_0=0.4761 | es_auc/_mean=0.5055 | es_auc/class_0=0.5055 | es_loss=0.0400 | it_auc/_mean=0.4684 | it_auc/class_0=0.4684 | it_loss=0.0411 | loss=0.0396 | tr_auc/_mean=0.4904 | tr_auc/class_0=0.4904 | tr_loss=0.0380\n",
      "25/300 * Epoch 25 (valid_es): auc/_mean=0.5055 | auc/class_0=0.5055 | loss=0.0400\n",
      "25/300 * Epoch 25 (valid_it): auc/_mean=0.4684 | auc/class_0=0.4684 | loss=0.0411\n",
      "25/300 * Epoch 25 (valid_tr): auc/_mean=0.4904 | auc/class_0=0.4904 | loss=0.0380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/300 * Epoch (train): 100% 15503/15503 [1:05:26<00:00,  3.95it/s, loss=0.050]\n",
      "26/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.45it/s, loss=0.036]\n",
      "26/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.35it/s, loss=0.042]\n",
      "26/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.34it/s, loss=0.032]\n",
      "26/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.36it/s, loss=0.038]\n",
      "[2020-04-28 06:15:09,084] \n",
      "26/300 * Epoch 26 (_base): lr=1.677e-08 | momentum=0.9000\n",
      "26/300 * Epoch 26 (train): auc/_mean=0.5476 | auc/class_0=0.5476 | loss=0.0531\n",
      "26/300 * Epoch 26 (valid): auc/_mean=0.4706 | auc/class_0=0.4706 | es_auc/_mean=0.4999 | es_auc/class_0=0.4999 | es_loss=0.0399 | it_auc/_mean=0.4601 | it_auc/class_0=0.4601 | it_loss=0.0411 | loss=0.0395 | tr_auc/_mean=0.4930 | tr_auc/class_0=0.4930 | tr_loss=0.0379\n",
      "26/300 * Epoch 26 (valid_es): auc/_mean=0.4999 | auc/class_0=0.4999 | loss=0.0399\n",
      "26/300 * Epoch 26 (valid_it): auc/_mean=0.4601 | auc/class_0=0.4601 | loss=0.0411\n",
      "26/300 * Epoch 26 (valid_tr): auc/_mean=0.4930 | auc/class_0=0.4930 | loss=0.0379\n",
      "27/300 * Epoch (train): 100% 15503/15503 [1:05:29<00:00,  3.95it/s, loss=0.065]\n",
      "27/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.46it/s, loss=0.033]\n",
      "27/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.35it/s, loss=0.041]\n",
      "27/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.36it/s, loss=0.031]\n",
      "27/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.36it/s, loss=0.035]\n",
      "[2020-04-28 07:24:21,095] \n",
      "27/300 * Epoch 27 (_base): lr=1.742e-08 | momentum=0.9000\n",
      "27/300 * Epoch 27 (train): auc/_mean=0.5513 | auc/class_0=0.5513 | loss=0.0529\n",
      "27/300 * Epoch 27 (valid): auc/_mean=0.4695 | auc/class_0=0.4695 | es_auc/_mean=0.4995 | es_auc/class_0=0.4995 | es_loss=0.0392 | it_auc/_mean=0.4603 | it_auc/class_0=0.4603 | it_loss=0.0404 | loss=0.0388 | tr_auc/_mean=0.4896 | tr_auc/class_0=0.4896 | tr_loss=0.0371\n",
      "27/300 * Epoch 27 (valid_es): auc/_mean=0.4995 | auc/class_0=0.4995 | loss=0.0392\n",
      "27/300 * Epoch 27 (valid_it): auc/_mean=0.4603 | auc/class_0=0.4603 | loss=0.0404\n",
      "27/300 * Epoch 27 (valid_tr): auc/_mean=0.4896 | auc/class_0=0.4896 | loss=0.0371\n",
      "28/300 * Epoch (train): 100% 15503/15503 [1:05:29<00:00,  3.95it/s, loss=0.034]\n",
      "28/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.45it/s, loss=0.032]\n",
      "28/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.34it/s, loss=0.041]\n",
      "28/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.031]\n",
      "28/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.35it/s, loss=0.033]\n",
      "[2020-04-28 08:33:33,505] \n",
      "28/300 * Epoch 28 (_base): lr=1.806e-08 | momentum=0.9000\n",
      "28/300 * Epoch 28 (train): auc/_mean=0.5545 | auc/class_0=0.5545 | loss=0.0527\n",
      "28/300 * Epoch 28 (valid): auc/_mean=0.4743 | auc/class_0=0.4743 | es_auc/_mean=0.5012 | es_auc/class_0=0.5012 | es_loss=0.0390 | it_auc/_mean=0.4712 | it_auc/class_0=0.4712 | it_loss=0.0401 | loss=0.0385 | tr_auc/_mean=0.4873 | tr_auc/class_0=0.4873 | tr_loss=0.0367\n",
      "28/300 * Epoch 28 (valid_es): auc/_mean=0.5012 | auc/class_0=0.5012 | loss=0.0390\n",
      "28/300 * Epoch 28 (valid_it): auc/_mean=0.4712 | auc/class_0=0.4712 | loss=0.0401\n",
      "28/300 * Epoch 28 (valid_tr): auc/_mean=0.4873 | auc/class_0=0.4873 | loss=0.0367\n",
      "29/300 * Epoch (train): 100% 15503/15503 [1:05:25<00:00,  3.95it/s, loss=0.046]\n",
      "29/300 * Epoch (valid): 100% 1334/1334 [01:38<00:00, 13.47it/s, loss=0.032]\n",
      "29/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.36it/s, loss=0.040]\n",
      "29/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.37it/s, loss=0.031]\n",
      "29/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.36it/s, loss=0.032]\n",
      "[2020-04-28 09:42:41,676] \n",
      "29/300 * Epoch 29 (_base): lr=1.871e-08 | momentum=0.9000\n",
      "29/300 * Epoch 29 (train): auc/_mean=0.5509 | auc/class_0=0.5509 | loss=0.0527\n",
      "29/300 * Epoch 29 (valid): auc/_mean=0.4759 | auc/class_0=0.4759 | es_auc/_mean=0.5019 | es_auc/class_0=0.5019 | es_loss=0.0389 | it_auc/_mean=0.4853 | it_auc/class_0=0.4853 | it_loss=0.0399 | loss=0.0382 | tr_auc/_mean=0.4743 | tr_auc/class_0=0.4743 | tr_loss=0.0364\n",
      "29/300 * Epoch 29 (valid_es): auc/_mean=0.5019 | auc/class_0=0.5019 | loss=0.0389\n",
      "29/300 * Epoch 29 (valid_it): auc/_mean=0.4853 | auc/class_0=0.4853 | loss=0.0399\n",
      "29/300 * Epoch 29 (valid_tr): auc/_mean=0.4743 | auc/class_0=0.4743 | loss=0.0364\n",
      "30/300 * Epoch (train): 100% 15503/15503 [1:05:29<00:00,  3.95it/s, loss=0.047]\n",
      "30/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.43it/s, loss=0.032]\n",
      "30/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.041]\n",
      "30/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.031]\n",
      "30/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.33it/s, loss=0.032]\n",
      "[2020-04-28 10:51:53,978] \n",
      "30/300 * Epoch 30 (_base): lr=1.935e-08 | momentum=0.9000\n",
      "30/300 * Epoch 30 (train): auc/_mean=0.5546 | auc/class_0=0.5546 | loss=0.0527\n",
      "30/300 * Epoch 30 (valid): auc/_mean=0.4766 | auc/class_0=0.4766 | es_auc/_mean=0.5027 | es_auc/class_0=0.5027 | es_loss=0.0388 | it_auc/_mean=0.4881 | it_auc/class_0=0.4881 | it_loss=0.0399 | loss=0.0382 | tr_auc/_mean=0.4686 | tr_auc/class_0=0.4686 | tr_loss=0.0363\n",
      "30/300 * Epoch 30 (valid_es): auc/_mean=0.5027 | auc/class_0=0.5027 | loss=0.0388\n",
      "30/300 * Epoch 30 (valid_it): auc/_mean=0.4881 | auc/class_0=0.4881 | loss=0.0399\n",
      "30/300 * Epoch 30 (valid_tr): auc/_mean=0.4686 | auc/class_0=0.4686 | loss=0.0363\n",
      "31/300 * Epoch (train): 100% 15503/15503 [1:05:37<00:00,  3.94it/s, loss=0.050]\n",
      "31/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.033]\n",
      "31/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.042]\n",
      "31/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.032]\n",
      "31/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.032]\n",
      "[2020-04-28 12:01:13,903] \n",
      "31/300 * Epoch 31 (_base): lr=2.000e-08 | momentum=0.9000\n",
      "31/300 * Epoch 31 (train): auc/_mean=0.5585 | auc/class_0=0.5585 | loss=0.0523\n",
      "31/300 * Epoch 31 (valid): auc/_mean=0.4837 | auc/class_0=0.4837 | es_auc/_mean=0.5110 | es_auc/class_0=0.5110 | es_loss=0.0387 | it_auc/_mean=0.4974 | it_auc/class_0=0.4974 | it_loss=0.0398 | loss=0.0381 | tr_auc/_mean=0.4649 | tr_auc/class_0=0.4649 | tr_loss=0.0361\n",
      "31/300 * Epoch 31 (valid_es): auc/_mean=0.5110 | auc/class_0=0.5110 | loss=0.0387\n",
      "31/300 * Epoch 31 (valid_it): auc/_mean=0.4974 | auc/class_0=0.4974 | loss=0.0398\n",
      "31/300 * Epoch 31 (valid_tr): auc/_mean=0.4649 | auc/class_0=0.4649 | loss=0.0361\n",
      "32/300 * Epoch (train): 100% 15503/15503 [1:05:34<00:00,  3.94it/s, loss=0.045]\n",
      "32/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.43it/s, loss=0.034]\n",
      "32/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.043]\n",
      "32/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.033]\n",
      "32/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.32it/s, loss=0.032]\n",
      "[2020-04-28 13:10:31,541] \n",
      "32/300 * Epoch 32 (_base): lr=2.064e-08 | momentum=0.9000\n",
      "32/300 * Epoch 32 (train): auc/_mean=0.5593 | auc/class_0=0.5593 | loss=0.0522\n",
      "32/300 * Epoch 32 (valid): auc/_mean=0.4967 | auc/class_0=0.4967 | es_auc/_mean=0.5242 | es_auc/class_0=0.5242 | es_loss=0.0390 | it_auc/_mean=0.5085 | it_auc/class_0=0.5085 | it_loss=0.0401 | loss=0.0384 | tr_auc/_mean=0.4661 | tr_auc/class_0=0.4661 | tr_loss=0.0364\n",
      "32/300 * Epoch 32 (valid_es): auc/_mean=0.5242 | auc/class_0=0.5242 | loss=0.0390\n",
      "32/300 * Epoch 32 (valid_it): auc/_mean=0.5085 | auc/class_0=0.5085 | loss=0.0401\n",
      "32/300 * Epoch 32 (valid_tr): auc/_mean=0.4661 | auc/class_0=0.4661 | loss=0.0364\n",
      "33/300 * Epoch (train): 100% 15503/15503 [1:05:39<00:00,  3.94it/s, loss=0.056]\n",
      "33/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.035]\n",
      "33/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.29it/s, loss=0.043]\n",
      "33/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.29it/s, loss=0.034]\n",
      "33/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.033]\n",
      "[2020-04-28 14:19:54,846] \n",
      "33/300 * Epoch 33 (_base): lr=2.129e-08 | momentum=0.9000\n",
      "33/300 * Epoch 33 (train): auc/_mean=0.5618 | auc/class_0=0.5618 | loss=0.0520\n",
      "33/300 * Epoch 33 (valid): auc/_mean=0.5132 | auc/class_0=0.5132 | es_auc/_mean=0.5405 | es_auc/class_0=0.5405 | es_loss=0.0395 | it_auc/_mean=0.5202 | it_auc/class_0=0.5202 | it_loss=0.0405 | loss=0.0388 | tr_auc/_mean=0.4596 | tr_auc/class_0=0.4596 | tr_loss=0.0367\n",
      "33/300 * Epoch 33 (valid_es): auc/_mean=0.5405 | auc/class_0=0.5405 | loss=0.0395\n",
      "33/300 * Epoch 33 (valid_it): auc/_mean=0.5202 | auc/class_0=0.5202 | loss=0.0405\n",
      "33/300 * Epoch 33 (valid_tr): auc/_mean=0.4596 | auc/class_0=0.4596 | loss=0.0367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/300 * Epoch (train): 100% 15503/15503 [1:05:40<00:00,  3.93it/s, loss=0.051]\n",
      "34/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.42it/s, loss=0.037]\n",
      "34/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.044]\n",
      "34/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.036]\n",
      "34/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.034]\n",
      "[2020-04-28 15:29:18,261] \n",
      "34/300 * Epoch 34 (_base): lr=2.193e-08 | momentum=0.9000\n",
      "34/300 * Epoch 34 (train): auc/_mean=0.5682 | auc/class_0=0.5682 | loss=0.0517\n",
      "34/300 * Epoch 34 (valid): auc/_mean=0.5302 | auc/class_0=0.5302 | es_auc/_mean=0.5556 | es_auc/class_0=0.5556 | es_loss=0.0402 | it_auc/_mean=0.5331 | it_auc/class_0=0.5331 | it_loss=0.0411 | loss=0.0394 | tr_auc/_mean=0.4652 | tr_auc/class_0=0.4652 | tr_loss=0.0374\n",
      "34/300 * Epoch 34 (valid_es): auc/_mean=0.5556 | auc/class_0=0.5556 | loss=0.0402\n",
      "34/300 * Epoch 34 (valid_it): auc/_mean=0.5331 | auc/class_0=0.5331 | loss=0.0411\n",
      "34/300 * Epoch 34 (valid_tr): auc/_mean=0.4652 | auc/class_0=0.4652 | loss=0.0374\n",
      "35/300 * Epoch (train): 100% 15503/15503 [1:05:38<00:00,  3.94it/s, loss=0.058]\n",
      "35/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.42it/s, loss=0.039]\n",
      "35/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.045]\n",
      "35/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.038]\n",
      "35/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.34it/s, loss=0.034]\n",
      "[2020-04-28 16:38:39,069] \n",
      "35/300 * Epoch 35 (_base): lr=2.258e-08 | momentum=0.9000\n",
      "35/300 * Epoch 35 (train): auc/_mean=0.5690 | auc/class_0=0.5690 | loss=0.0516\n",
      "35/300 * Epoch 35 (valid): auc/_mean=0.5406 | auc/class_0=0.5406 | es_auc/_mean=0.5625 | es_auc/class_0=0.5625 | es_loss=0.0408 | it_auc/_mean=0.5371 | it_auc/class_0=0.5371 | it_loss=0.0416 | loss=0.0399 | tr_auc/_mean=0.4837 | tr_auc/class_0=0.4837 | tr_loss=0.0379\n",
      "35/300 * Epoch 35 (valid_es): auc/_mean=0.5625 | auc/class_0=0.5625 | loss=0.0408\n",
      "35/300 * Epoch 35 (valid_it): auc/_mean=0.5371 | auc/class_0=0.5371 | loss=0.0416\n",
      "35/300 * Epoch 35 (valid_tr): auc/_mean=0.4837 | auc/class_0=0.4837 | loss=0.0379\n",
      "36/300 * Epoch (train): 100% 15503/15503 [1:05:39<00:00,  3.94it/s, loss=0.035]\n",
      "36/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.43it/s, loss=0.042]\n",
      "36/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.047]\n",
      "36/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.32it/s, loss=0.039]\n",
      "36/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.33it/s, loss=0.035]\n",
      "[2020-04-28 17:48:37,805] \n",
      "36/300 * Epoch 36 (_base): lr=2.322e-08 | momentum=0.9000\n",
      "36/300 * Epoch 36 (train): auc/_mean=0.5684 | auc/class_0=0.5684 | loss=0.0516\n",
      "36/300 * Epoch 36 (valid): auc/_mean=0.5448 | auc/class_0=0.5448 | es_auc/_mean=0.5635 | es_auc/class_0=0.5635 | es_loss=0.0412 | it_auc/_mean=0.5372 | it_auc/class_0=0.5372 | it_loss=0.0420 | loss=0.0404 | tr_auc/_mean=0.4887 | tr_auc/class_0=0.4887 | tr_loss=0.0383\n",
      "36/300 * Epoch 36 (valid_es): auc/_mean=0.5635 | auc/class_0=0.5635 | loss=0.0412\n",
      "36/300 * Epoch 36 (valid_it): auc/_mean=0.5372 | auc/class_0=0.5372 | loss=0.0420\n",
      "36/300 * Epoch 36 (valid_tr): auc/_mean=0.4887 | auc/class_0=0.4887 | loss=0.0383\n",
      "37/300 * Epoch (train): 100% 15503/15503 [1:05:42<00:00,  3.93it/s, loss=0.040]\n",
      "37/300 * Epoch (valid): 100% 1334/1334 [01:39<00:00, 13.41it/s, loss=0.048]\n",
      "37/300 * Epoch (valid_es): 100% 417/417 [00:31<00:00, 13.31it/s, loss=0.048]\n",
      "37/300 * Epoch (valid_it): 100% 417/417 [00:31<00:00, 13.30it/s, loss=0.043]\n",
      "37/300 * Epoch (valid_tr): 100% 500/500 [00:37<00:00, 13.31it/s, loss=0.037]\n",
      "[2020-04-28 18:58:39,211] \n",
      "37/300 * Epoch 37 (_base): lr=2.387e-08 | momentum=0.9000\n",
      "37/300 * Epoch 37 (train): auc/_mean=0.5739 | auc/class_0=0.5739 | loss=0.0513\n",
      "37/300 * Epoch 37 (valid): auc/_mean=0.5373 | auc/class_0=0.5373 | es_auc/_mean=0.5450 | es_auc/class_0=0.5450 | es_loss=0.0424 | it_auc/_mean=0.5255 | it_auc/class_0=0.5255 | it_loss=0.0430 | loss=0.0414 | tr_auc/_mean=0.4991 | tr_auc/class_0=0.4991 | tr_loss=0.0393\n",
      "37/300 * Epoch 37 (valid_es): auc/_mean=0.5450 | auc/class_0=0.5450 | loss=0.0424\n",
      "37/300 * Epoch 37 (valid_it): auc/_mean=0.5255 | auc/class_0=0.5255 | loss=0.0430\n",
      "37/300 * Epoch 37 (valid_tr): auc/_mean=0.4991 | auc/class_0=0.4991 | loss=0.0393\n",
      "38/300 * Epoch (train):  68% 10592/15503 [44:55<20:54,  3.91it/s, loss=0.047] "
     ]
    }
   ],
   "source": [
    "# CHECKPOINT = './checkpoints/from_v4.pth'\n",
    "project = \"jigsaw_v8_xlm_roberta_base\"\n",
    "num_epochs = 300\n",
    "\n",
    "group = datetime.now().strftime(\"%m_%d_%Y__%H_%M_%S\")\n",
    "\n",
    "    \n",
    "if SERVER:\n",
    "    group = f'{group}_server'\n",
    "    \n",
    "if STRIDE > 1:\n",
    "    group = f'{group}_str{STRIDE}'\n",
    "\n",
    "variants = {\n",
    "    'learn_both':{\n",
    "        'train': ['bias', 'toxic'],\n",
    "        'valid': 'valid',\n",
    "#         'valid2': 'valid'\n",
    "    },\n",
    "#     'learn_toxic':{\n",
    "#         'train': 'toxic',\n",
    "#         'valid': 'valid',\n",
    "# #         'valid2': 'bias',\n",
    "#     },\n",
    "#     'learn_bias':{\n",
    "#         'train': 'bias',\n",
    "#         'valid': 'valid',\n",
    "#         'valid2': 'toxic',\n",
    "#     },\n",
    "    \n",
    "    \n",
    "}\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "lr = 3e-5#0.0001\n",
    "group += f'_lr{lr}'\n",
    "\n",
    "group = group.replace('.', '')\n",
    "\n",
    "runner = SupervisedRunner(input_key=('features'), input_target_key=('targets'), output_key=('logits'))\n",
    "\n",
    "for experiment in variants.keys():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    logdir = f\"{LOG_PATH}/{project}/{group}/{experiment}\"\n",
    "\n",
    "    model = QuestModel(2)\n",
    "#     checkpoint = torch.load(CHECKPOINT)#, map_location=device)   \n",
    "\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     del checkpoint\n",
    "#     model = model.to(device)\n",
    "\n",
    "    # model runner\n",
    "    if 'valid2' in variants[experiment].keys():\n",
    "        test_var= variants[experiment]['valid2']\n",
    "    else:\n",
    "        test_var=None\n",
    "\n",
    "    loaders = get_loaders(variants[experiment]['train'], \n",
    "                          variants[experiment]['valid'],\n",
    "                          test_var, to_balance=True)\n",
    "            \n",
    "    \n",
    "    t_total = len(loaders['train'])//gradient_accumulation_steps*num_epochs\n",
    "    warmup_proportion = 0.01\n",
    "    num_warmup_steps = t_total * warmup_proportion\n",
    "    \n",
    "#     criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    criterion = FocalLoss(alpha=0.2, gamma=1.5, logits=True, reduce=True)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "#     criterion = torch.nn.BCELoss()\n",
    "    optimizer = AdamW(model.parameters(), lr = lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total) \n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.25)\n",
    "    print(f'----------------Experiment: {experiment}')\n",
    "\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loaders=loaders,\n",
    "        logdir=logdir,\n",
    "        num_epochs=num_epochs,\n",
    "        verbose=True,\n",
    "        distributed=False if is_jupyter() else True,\n",
    "        callbacks=[\n",
    "            AlchemyLogger(\n",
    "                    token=token, # your Alchemy token\n",
    "                    project=project,\n",
    "                    experiment=experiment,\n",
    "                    group=group,\n",
    "                ),\n",
    "            MyAUCCallback()\n",
    "#             AUCCallback(input_key = 'targets',\n",
    "#                                 output_key = 'logits',\n",
    "#                                 prefix = 'auc',\n",
    "#                                 class_names = None,\n",
    "#                                 num_classes = 2,\n",
    "#                                 activation = 'Sigmoid',)\n",
    "        ],\n",
    "        main_metric='auc/_mean',\n",
    "        minimize_metric=False,\n",
    "#         fp16={\"opt_level\": \"O1\"}\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBertTokenizer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jig_env",
   "language": "python",
   "name": "jig_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "086421f7eec44c769f08f5f68fafafdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e7c81c0da784e04b530236bad005c33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18b951cd8c1447eaa1e12f972ac37d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  9%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e743ecd26cd4877a539f9bbbd23d114",
       "max": 308,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e34fafda1e234d9c981322beff1068e7",
       "value": 29
      }
     },
     "35645b239e914aee807cfdc234fc5b75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfdee9b109bc4176a0bc3a26ae38f7a3",
       "placeholder": "​",
       "style": "IPY_MODEL_086421f7eec44c769f08f5f68fafafdc",
       "value": " 29/308 [7:12:46&lt;66:18:40, 855.63s/it]"
      }
     },
     "554271f3ed5d48efa844608a0b72fdac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "685ecca481e3463d83a2465f15f7b33f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80ae0d356c3e4b1bbe511c5f5a2694b5",
       "max": 4059,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a34804b28be74d7c9972a0a13410ba77",
       "value": 4059
      }
     },
     "7f49d7d685554687bc2d131959058cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80ae0d356c3e4b1bbe511c5f5a2694b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "840e74b11eb44a58b1ed0433e924dc82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e743ecd26cd4877a539f9bbbd23d114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a34804b28be74d7c9972a0a13410ba77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a61c8f56dbd74e29a155fad0d7095f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_18b951cd8c1447eaa1e12f972ac37d42",
        "IPY_MODEL_35645b239e914aee807cfdc234fc5b75"
       ],
       "layout": "IPY_MODEL_7f49d7d685554687bc2d131959058cb3"
      }
     },
     "c9ab84b07a32426282543b5ff054ddec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_840e74b11eb44a58b1ed0433e924dc82",
       "placeholder": "​",
       "style": "IPY_MODEL_554271f3ed5d48efa844608a0b72fdac",
       "value": " 4059/4059 [14:53&lt;00:00,  4.54it/s]"
      }
     },
     "dfdee9b109bc4176a0bc3a26ae38f7a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e34fafda1e234d9c981322beff1068e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fd692cff30e343aa8afa007a05d66acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_685ecca481e3463d83a2465f15f7b33f",
        "IPY_MODEL_c9ab84b07a32426282543b5ff054ddec"
       ],
       "layout": "IPY_MODEL_0e7c81c0da784e04b530236bad005c33"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
