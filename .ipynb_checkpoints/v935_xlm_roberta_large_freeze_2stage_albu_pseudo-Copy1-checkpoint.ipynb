{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch BERT baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, I convert https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic into pytorch version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please upvote the kernel if you find it helpful**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are not allowed to use internet I've created required datasets and commands to setup Hugging Face Transformers setup in offline mode. You can find the required github codebases in the datasets.\n",
    "\n",
    "* sacremoses dependency - https://www.kaggle.com/axel81/sacremoses\n",
    "* transformers - https://www.kaggle.com/axel81/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# !pip install ./sacremoses/sacremoses-master/\n",
    "# !pip install ./transformers/transformers-master/\n",
    "\n",
    "STRIDE = 1\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        ipy_str = str(type(get_ipython()))\n",
    "        if 'zmqshell' in ipy_str:\n",
    "            return True\n",
    "        \n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports\n",
    "\n",
    "I've added imports that will be used in training too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/kb/jig_env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from random import shuffle as shfl\n",
    "from auc import MyAUCCallback\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max.columns', 500)\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] ='1'\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-10.1/lib64'\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from shutil import copyfile\n",
    "from catalyst.dl import SupervisedRunner, AlchemyLogger, CriterionCallback\n",
    "from catalyst.dl.callbacks.metrics import AUCCallback\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler,Dataset\n",
    "batch_size =32\n",
    "token = \"d1dd16f08d518293bcbeddd313b49aa4\"\n",
    "DATA_DIR = '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on desktop\n"
     ]
    }
   ],
   "source": [
    "if os.uname()[1] == 'kb-Z370P-D3':\n",
    "    # desktop\n",
    "    LOG_PATH = '/media/ssd/logs/jigsaw'\n",
    "    SERVER = False\n",
    "    print('Working on desktop')\n",
    "elif os.uname()[1] == 'kb-server':\n",
    "    # server\n",
    "    LOG_PATH = '/home/kb/logs/jigsaw'\n",
    "    SERVER = True\n",
    "    print('Working on server')\n",
    "else:\n",
    "    raise Exception('which hostname???')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\[\n",
      "\n",
      "<>:5: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\d\n",
      "\n",
      "<>:6: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text = text.fillna(\"fillna\")#.str.lower()\n",
    "    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\(http://.*?\\s\\(http://.*\\)\",'',str(x)))\n",
    "    return text\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"couldnt\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"doesnt\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"havent\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"shouldnt\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"thats\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"theres\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"theyre\":  \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"}\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = tokenizer.tokenize(x)\n",
    "    return x\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x).replace(\"\\n\",\"\")\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def clean_data(df, columns: list):\n",
    "    for col in columns:\n",
    "        pass\n",
    "        df[col] = df[col].apply(lambda x: clean_numbers(x))\n",
    "        df[col] = clean(df[col])\n",
    "        df[col] = df[col].apply(lambda x: clean_text(x)) \n",
    "        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n",
    "# #         df[col] = df[col].apply(lambda x: handle_contractions(x))  \n",
    "#         df[col] = df[col].apply(lambda x: fix_quote(x))   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPTransform(BasicTransform):\n",
    "    \"\"\" Transform for nlp task.\"\"\"\n",
    "    LANGS = {\n",
    "        'en': 'english',\n",
    "        'it': 'italian', \n",
    "        'fr': 'french', \n",
    "        'es': 'spanish',\n",
    "        'tr': 'turkish', \n",
    "        'ru': 'russian',\n",
    "        'pt': 'portuguese'\n",
    "    }\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "    def get_sentences(self, text, lang='en'):\n",
    "        return sent_tokenize(text, self.LANGS.get(lang, 'english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Sentence5>. <Sentence3>. <Sentence1>. <Sentence4>. <Sentence6>. <Sentence2>.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ShuffleSentencesTransform(NLPTransform):\n",
    "    \"\"\" Do shuffle by sentence \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        random.shuffle(sentences)\n",
    "        return ' '.join(sentences), lang\n",
    "    \n",
    "transform = ShuffleSentencesTransform(p=1.0)\n",
    "\n",
    "text = '<Sentence1>. <Sentence2>. <Sentence3>. <Sentence4>. <Sentence5>. <Sentence6>.'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Sentence1>. <Sentence2>. <Sentence4>. <Sentence5>.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExcludeDuplicateSentencesTransform(NLPTransform):\n",
    "    \"\"\" Exclude equal sentences \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeDuplicateSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = []\n",
    "        for sentence in self.get_sentences(text, lang):\n",
    "            sentence = sentence.strip()\n",
    "            if sentence not in sentences:\n",
    "                sentences.append(sentence)\n",
    "        return ' '.join(sentences), lang\n",
    "transform = ExcludeDuplicateSentencesTransform(p=1.0)\n",
    "\n",
    "text = '<Sentence1>. <Sentence2>. <Sentence4>. <Sentence4>. <Sentence5>. <Sentence5>.'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Word> <Word> <Word> <Word> <Word> <Word> <Word> <Word> <Word> <Word>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExcludeNumbersTransform(NLPTransform):\n",
    "    \"\"\" exclude any numbers \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeNumbersTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'[0-9]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "transform = ExcludeNumbersTransform(p=1.0)\n",
    "\n",
    "text = '<Word1> <Word2> <Word3> <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Word1> <Word2> <Word3> <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExcludeHashtagsTransform(NLPTransform):\n",
    "    \"\"\" Exclude any hashtags with # \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeHashtagsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'#[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "transform = ExcludeHashtagsTransform(p=1.0)\n",
    "\n",
    "text = '<Word1> <Word2> <Word3> #kaggle <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Word1> <Word2> <Word3> <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExcludeUsersMentionedTransform(NLPTransform):\n",
    "    \"\"\" Exclude @users \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUsersMentionedTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'@[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "transform = ExcludeUsersMentionedTransform(p=1.0)\n",
    "\n",
    "text = '<Word1> <Word2> <Word3> @kaggle <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Word1> <Word2> <Word3> <Word4> <Word6> <Word7> <Word8> <Word9> <Word10>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExcludeUrlsTransform(NLPTransform):\n",
    "    \"\"\" Exclude urls \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUrlsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'https?\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "transform = ExcludeUrlsTransform(p=1.0)\n",
    "\n",
    "text = '<Word1> <Word2> <Word3> <Word4> https://www.kaggle.com/shonenkov/nlp-albumentations/ <Word6> <Word7> <Word8> <Word9> <Word10>'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Word1> <Word2> <Word3> <Word4> <Word6> <Word5> <Word7> <Word9> <Word8> <Word10>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SwapWordsTransform(NLPTransform):\n",
    "    \"\"\" Swap words next to each other \"\"\"\n",
    "    def __init__(self, swap_distance=1, swap_probability=0.1, always_apply=False, p=0.5):\n",
    "        \"\"\"  \n",
    "        swap_distance - distance for swapping words\n",
    "        swap_probability - probability of swapping for one word\n",
    "        \"\"\"\n",
    "        super(SwapWordsTransform, self).__init__(always_apply, p)\n",
    "        self.swap_distance = swap_distance\n",
    "        self.swap_probability = swap_probability\n",
    "        self.swap_range_list = list(range(1, swap_distance+1))\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        words = text.split()\n",
    "        words_count = len(words)\n",
    "        if words_count <= 1:\n",
    "            return text, lang\n",
    "\n",
    "        new_words = {}\n",
    "        for i in range(words_count):\n",
    "            if random.random() > self.swap_probability:\n",
    "                new_words[i] = words[i]\n",
    "                continue\n",
    "    \n",
    "            if i < self.swap_distance:\n",
    "                new_words[i] = words[i]\n",
    "                continue\n",
    "    \n",
    "            swap_idx = i - random.choice(self.swap_range_list)\n",
    "            new_words[i] = new_words[swap_idx]\n",
    "            new_words[swap_idx] = words[i]\n",
    "\n",
    "        return ' '.join([v for k, v in sorted(new_words.items(), key=lambda x: x[0])]), lang\n",
    "\n",
    "transform = SwapWordsTransform(p=1.0, swap_distance=1, swap_probability=0.2)\n",
    "\n",
    "text = '<Word1> <Word2> <Word3> <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Word2> <Word3> <Word5> <Word7> <Word8> <Word10>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CutOutWordsTransform(NLPTransform):\n",
    "    \"\"\" Remove random words \"\"\"\n",
    "    def __init__(self, cutout_probability=0.05, always_apply=False, p=0.5):\n",
    "        super(CutOutWordsTransform, self).__init__(always_apply, p)\n",
    "        self.cutout_probability = cutout_probability\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        words = text.split()\n",
    "        words_count = len(words)\n",
    "        if words_count <= 1:\n",
    "            return text, lang\n",
    "        \n",
    "        new_words = []\n",
    "        for i in range(words_count):\n",
    "            if random.random() < self.cutout_probability:\n",
    "                continue\n",
    "            new_words.append(words[i])\n",
    "\n",
    "        if len(new_words) == 0:\n",
    "            return words[random.randint(0, words_count-1)], lang\n",
    "\n",
    "        return ' '.join(new_words), lang\n",
    "transform = CutOutWordsTransform(p=1.0, cutout_probability=0.2)\n",
    "\n",
    "text = '<Word1> <Word2> <Word3> <Word4> <Word5> <Word6> <Word7> <Word8> <Word9> <Word10>'\n",
    "lang = 'en'\n",
    "\n",
    "transform(data=(text, lang))['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNonToxicSentencesTransform(NLPTransform):\n",
    "    \"\"\" Add random non toxic statement \"\"\"\n",
    "    def __init__(self, non_toxic_sentences, sentence_range=(1, 3), always_apply=False, p=0.5):\n",
    "        super(AddNonToxicSentencesTransform, self).__init__(always_apply, p)\n",
    "        self.sentence_range = sentence_range\n",
    "        self.non_toxic_sentences = non_toxic_sentences\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        for i in range(random.randint(*self.sentence_range)):\n",
    "            sentences.append(random.choice(self.non_toxic_sentences))\n",
    "        \n",
    "        random.shuffle(sentences)\n",
    "        return ' '.join(sentences), lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 895/895 [00:00<00:00, 8645.94it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_transform = NLPTransform()\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv', nrows=1000)\n",
    "df = df[df.toxic == 0]\n",
    "df['lang'] = 'en'\n",
    "non_toxic_sentences = set()\n",
    "for comment_text in tqdm(df['comment_text'], total=df.shape[0]):\n",
    "    non_toxic_sentences.update(nlp_transform.get_sentences(comment_text), 'en')\n",
    "\n",
    "transform = AddNonToxicSentencesTransform(non_toxic_sentences=list(non_toxic_sentences), p=1.0, sentence_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "\n",
    "def get_train_transforms():\n",
    "    return albumentations.Compose([\n",
    "        ExcludeDuplicateSentencesTransform(p=0.9),  # here not p=1.0 because your nets should get some difficulties\n",
    "        albumentations.OneOf([\n",
    "            AddNonToxicSentencesTransform(non_toxic_sentences=list(non_toxic_sentences), p=0.8, sentence_range=(1,3)),\n",
    "            ShuffleSentencesTransform(p=0.8),\n",
    "        ]),\n",
    "        ExcludeNumbersTransform(p=0.8),\n",
    "        ExcludeHashtagsTransform(p=0.5),\n",
    "        ExcludeUsersMentionedTransform(p=0.9),\n",
    "        ExcludeUrlsTransform(p=0.9),\n",
    "        CutOutWordsTransform(p=0.1),\n",
    "        SwapWordsTransform(p=0.1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
    "train2 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\n",
    "train2.toxic = train2.toxic.round().astype(int)\n",
    "\n",
    "df_valid = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train1 with a subset of train2\n",
    "df_train = pd.concat([\n",
    "    train1[['comment_text', 'toxic']],\n",
    "    train2[['comment_text', 'toxic']].query('toxic==1'),\n",
    "    train2[['comment_text', 'toxic']].query('toxic==0').sample(n=100000, random_state=0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>3872</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>I finished editing cosmic ray ultra-high energ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>2078</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>You are right! It 's unpleasant deleted seeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1794</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>I see several reasons to cancel User: Wikikamo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>3085</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Sites usually the minimum required information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>4130</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>if it is true Paramore is not the emo EMO suck...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id lang  toxic                                       comment_text\n",
       "3872  3872   es      0  I finished editing cosmic ray ultra-high energ...\n",
       "2078  2078   it      0  You are right! It 's unpleasant deleted seeing...\n",
       "1794  1794   it      0  I see several reasons to cancel User: Wikikamo...\n",
       "3085  3085   tr      0  Sites usually the minimum required information...\n",
       "4130  4130   es      0  if it is true Paramore is not the emo EMO suck..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_en = shuffle(pd.read_csv(DATA_DIR + 'validation_en.csv'))\n",
    "df_valid_en = df_valid_en.drop(['comment_text'],axis=1).rename(columns={'comment_text_en':'comment_text'})\n",
    "# df_valid_en = clean_data(df_valid_en, ['comment_text'])\n",
    "df_valid_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">es</th>\n",
       "      <th>0</th>\n",
       "      <td>2078</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">it</th>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">tr</th>\n",
       "      <th>0</th>\n",
       "      <td>2680</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  comment_text\n",
       "lang toxic                    \n",
       "es   0      2078          2078\n",
       "     1       422           422\n",
       "it   0      2012          2012\n",
       "     1       488           488\n",
       "tr   0      2680          2680\n",
       "     1       320           320"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_en.groupby(['lang', 'toxic']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.173887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic\n",
       "0   0  0.000060\n",
       "1   1  0.000020\n",
       "2   2  0.173887\n",
       "3   3  0.000015\n",
       "4   4  0.000019"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_pseudo = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/pseudo_labelling_09459.csv')\n",
    "df_pseudo = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/pseudo_labelling_09393.csv')\n",
    "df_pseudo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.269427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.008064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic\n",
       "0   0  0.004235\n",
       "1   1  0.020938\n",
       "2   2  0.269427\n",
       "3   3  0.008064\n",
       "4   4  0.007442"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pseudo2 = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/pseudo_labelling_09459.csv')\n",
    "df_pseudo2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1904acc1d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pseudo.toxic.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8fbbaf1c90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pseudo2.toxic.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic_x</th>\n",
       "      <th>toxic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.004235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.020938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.173887</td>\n",
       "      <td>0.269427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.008064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.007442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   toxic_x   toxic_y\n",
       "0   0  0.000060  0.004235\n",
       "1   1  0.000020  0.020938\n",
       "2   2  0.173887  0.269427\n",
       "3   3  0.000015  0.008064\n",
       "4   4  0.000019  0.007442"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pseudo = df_pseudo.merge(df_pseudo2, on='id')\n",
    "df_pseudo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pseudo = df_pseudo[((df_pseudo['toxic_x']>0.9) & (df_pseudo['toxic_y']>0.9)) | ((df_pseudo['toxic_x']<0.1) & (df_pseudo['toxic_y']<0.1))]\n",
    "df_pseudo['toxic'] = (df_pseudo['toxic_y'] + df_pseudo['toxic_x'])/2\n",
    "df_pseudo = df_pseudo[['id', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pseudo = df_pseudo[(df_pseudo['toxic']>0.9) | (df_pseudo['toxic']<0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pseudo.loc[df_pseudo['toxic']>0.5, 'toxic'] = 1.0\n",
    "df_pseudo.loc[df_pseudo['toxic']<=0.5, 'toxic'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42421"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Le truc le plus important dans ta tirade c est...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  toxic                                       comment_text lang\n",
       "0   0    0.0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n",
       "1   1    0.0   Вполне возможно, но я пока не вижу необходимо...   ru\n",
       "2   3    0.0  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr\n",
       "3   4    0.0  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr\n",
       "4   5    0.0  Le truc le plus important dans ta tirade c est...   fr"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pseudo = df_pseudo.merge(df_test, on='id').rename(columns={'content':'comment_text'})\n",
    "df_pseudo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Este usuario ni siquiera llega al rango de    ...</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Il testo di questa voce pare esser scopiazzato...</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text lang  toxic\n",
       "0   0  Este usuario ni siquiera llega al rango de    ...   es      0\n",
       "1   1  Il testo di questa voce pare esser scopiazzato...   it      0\n",
       "2   2  Vale. Sólo expongo mi pasado. Todo tiempo pasa...   es      1\n",
       "3   3  Bu maddenin alt başlığı olarak  uluslararası i...   tr      0\n",
       "4   4  Belçika nın şehirlerinin yanında ilçe ve belde...   tr      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang  toxic\n",
       "es    0.0       4133\n",
       "      1.0        919\n",
       "fr    0.0       5379\n",
       "      1.0        600\n",
       "it    0.0       5179\n",
       "      1.0        447\n",
       "pt    0.0       6616\n",
       "      1.0        481\n",
       "ru    0.0       6019\n",
       "      1.0        452\n",
       "tr    0.0      11803\n",
       "      1.0        393\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pseudo.groupby(['lang', 'toxic'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  toxic\n",
       "0   0    0.5\n",
       "1   1    0.5\n",
       "2   2    0.5\n",
       "3   3    0.5\n",
       "4   4    0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'toxic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import time\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "#import torch.utils.data as data\n",
    "from torchvision import datasets, models, transforms\n",
    "from transformers import *\n",
    "import random\n",
    "from math import floor, ceil\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "MAX_LEN = 96#192#192#512\n",
    "SEP_TOKEN_ID = 102\n",
    "\n",
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train_mode=True, labeled=True, train_transforms=None):\n",
    "        \n",
    "        self.train_transforms = train_transforms\n",
    "        self.df = df\n",
    "        if train_mode:\n",
    "            self.labels = df.toxic.values\n",
    "            self.toxic_inds = np.where(self.labels==1)[0]\n",
    "            self.normal_inds = np.where(self.labels==0)[0]            \n",
    "            \n",
    "            \n",
    "            print(f'Here is {len(self.labels)} samples, {len(self.toxic_inds)} samples and {len(self.normal_inds)} samples')\n",
    "            print(f'Class balance is {len(self.toxic_inds)/len(self.labels):.2f}')\n",
    "            \n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')#, \n",
    "#                                                              return_attention_masks=False, \n",
    "#                                                                 return_token_type_ids=False,\n",
    "#                                                                 pad_to_max_length=True,\n",
    "#                                                                 max_length=MAX_LEN)\n",
    "#         self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased',\n",
    "#                                                                 do_lower_case=False,\n",
    "#                                                                 do_basic_tokenize=True,\n",
    "#                                                                 never_split=None,\n",
    "#                                                                 unk_token='[UNK]',\n",
    "#                                                                 sep_token='[SEP]',\n",
    "#                                                                 pad_token='[PAD]',\n",
    "#                                                                 cls_token='[CLS]',\n",
    "#                                                                 mask_token='[MASK]',\n",
    "#                                                                 tokenize_chinese_chars=True,)\n",
    "        #distil\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        token_ids = self.get_token_ids(row)\n",
    "        \n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return {'features': token_ids, 'targets': labels}\n",
    "\n",
    "        else:\n",
    "            return {'features': token_ids}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def trim_input(self, text, max_sequence_length=MAX_LEN):\n",
    "        t = self.tokenizer.tokenize(text)\n",
    "        t_len = len(t)\n",
    "\n",
    "        if t_len + 2 > max_sequence_length:\n",
    "\n",
    "            t_new_len = int(max_sequence_length) - 2\n",
    "\n",
    "            t = t[:t_new_len]\n",
    "\n",
    "        return t\n",
    "        \n",
    "    def get_token_ids(self, row):\n",
    "        \n",
    "        text = row.comment_text\n",
    "        if self.train_transforms:\n",
    "            lang = 'en' if 'lang' not in list(row.keys().values) else row.lang\n",
    "            text, _ = self.train_transforms(data=(row.comment_text, lang))['data']\n",
    "        \n",
    "#         token_ids = self.tokenizer.encode(text, max_length=MAX_LEN)\n",
    "#         if len(token_ids) < MAX_LEN:\n",
    "#             ids = torch.tensor(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "#         else:\n",
    "#             ids = torch.tensor(token_ids[:MAX_LEN])\n",
    "        if self.train_mode:\n",
    "            token_ids = self.tokenizer.encode(text, max_length=1024)\n",
    "            if len(token_ids) < MAX_LEN:\n",
    "                ids = torch.tensor(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "            else:\n",
    "                ind_beg = random.randint(0, len(token_ids)-MAX_LEN)\n",
    "                ids = torch.tensor(token_ids[ind_beg:ind_beg+MAX_LEN])\n",
    "        else:\n",
    "            token_ids = self.tokenizer.encode(text, max_length=MAX_LEN)\n",
    "            if len(token_ids) < MAX_LEN:\n",
    "                ids = torch.tensor(token_ids + [0] * (MAX_LEN - len(token_ids)))\n",
    "            else:\n",
    "                ids = torch.tensor(token_ids[:MAX_LEN])\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def get_label(self, row):\n",
    "#         label = torch.tensor(row[target_column].astype(np.long))\n",
    "        label = np.round(row[target_column])\n",
    "        return torch.tensor([1-label, label]).float()\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "\n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[1] for x in batch])\n",
    "            return {'features': token_ids, 'targets': labels}\n",
    "        else:\n",
    "            return {'features': token_ids}\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text=\"\"\"Ситуация с заболеваемостью COVID-19 в России постепенно стабилизируется, заявил главный эпидемиолог Минздрава, академик РАН Николай Брико. По его прогнозам, начало снижения заболеваемости возможно в июне.\"\"\"\n",
    "# tokenized = tokenizer.encode(text, max_length=MAX_LEN)\n",
    "# len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid['len_token'] = df_valid['comment_text'].apply(lambda x: len(tokenizer.encode(x, max_length=1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.len_token.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid[df_valid.len_token==860]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(QuestModel, self).__init__()\n",
    "        self.model_name = 'QuestModel'\n",
    "        \n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    "#         self.bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "#        self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base', \n",
    "                                                          #output_hidden_states=False, \n",
    "                                                          #output_attentions=False)\n",
    "#         self.bert_model = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "        self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-large')#,\n",
    "#                                                           output_hidden_states=False, \n",
    "#                                                           output_attentions=False)\n",
    "    \n",
    "#         self.fc = nn.Linear(768, n_classes)\n",
    "        self.fc = nn.Linear(1024, n_classes)\n",
    "\n",
    "    def forward(self, ids):\n",
    "#         attention_mask = (ids > 0)\n",
    "#         print(ids.shape)\n",
    "        layers = self.bert_model(input_ids=ids)#, attention_mask=attention_mask)\n",
    "#         print(layers[0].shape)\n",
    "#         out = F.dropout(layers[0][:, 0, :], p=0.2, training=self.training)\n",
    "#         print(layers[0].shape)\n",
    "#         print([l.shape for l in layers])\n",
    "#         out = F.dropout(layers[-1][:, 0, :], p=0.35, training=self.training)\n",
    "        out = F.dropout(layers[0][:, 0, :], p=0.2, training=self.training)\n",
    "        logit = self.fc(out)#.unsqueeze(1)\n",
    "        return logit #, 'for_auc': logit[:, 1]}#[:,1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, dataset):\n",
    "       \n",
    "        self.toxic_inds = dataset.toxic_inds.copy()\n",
    "        self.normal_inds = dataset.normal_inds.copy()\n",
    "        \n",
    "        self.num_samples = 2*min(len(self.toxic_inds), len(self.normal_inds))\n",
    "        \n",
    "        shfl(self.toxic_inds)\n",
    "        shfl(self.normal_inds)\n",
    "        \n",
    "        self.inds = []\n",
    "        for i in range(min(len(self.toxic_inds), len(self.normal_inds))):\n",
    "            self.inds.append(self.normal_inds[i%len(self.normal_inds)])\n",
    "            self.inds.append(self.toxic_inds[i%len(self.toxic_inds)])\n",
    "\n",
    "    def __iter__(self):\n",
    "        #print ('\\tcalling Sampler:__iter__')\n",
    "        return iter(self.inds)\n",
    "\n",
    "    def __len__(self):\n",
    "        #print ('\\tcalling Sampler:__len__')\n",
    "        return self.num_samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "\n",
    "        # define custom callback\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        if self.callback_get_label:\n",
    "            return self.callback_get_label(dataset, idx)\n",
    "        else:\n",
    "            dataset.labels[idx]\n",
    "#             raise NotImplementedError\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(to_balance=True, shuffle_before=True):\n",
    "    if SERVER:\n",
    "        workers=1\n",
    "    else:\n",
    "        workers = 6    \n",
    "    \n",
    "    df_train_sp, df_valid_sp = train_test_split(df_valid, random_state=12345, \n",
    "                                                stratify=df_valid.toxic.values, test_size=0.2,)\n",
    "    \n",
    "    df_train_sp = df_train_sp.reset_index(drop=True)\n",
    "    df_train_sp = df_train_sp.append(df_pseudo[df_train_sp.columns]).reset_index(drop=True)\n",
    "    \n",
    "    df_valid_sp = df_valid_sp.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    train_dataset = QuestDataset(df_train_sp, train_mode=True)#, train_transforms=get_train_transforms())\n",
    "    valid_dataset = QuestDataset(df_valid_sp, train_mode=False)\n",
    "    \n",
    "    \n",
    "#     train_dataset = QuestDataset(df_pseudo, train_mode=True, train_transforms=get_train_transforms())\n",
    "#     valid_dataset = QuestDataset(df_valid, train_mode=False)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        num_workers=workers,\n",
    "        sampler=BalancedSampler(train_dataset) if to_balance else None,#ImbalancedDatasetSampler(train_dataset) if to_balance else None,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        num_workers=workers,\n",
    "        batch_size=batch_size,\n",
    "    )    \n",
    "    \n",
    "       \n",
    "    loaders = {}\n",
    "    loaders['train'] = train_loader\n",
    "    loaders['valid'] = valid_loader\n",
    "    \n",
    "    \n",
    "    for i in ['es', 'it', 'tr']:\n",
    "        df = df_valid_sp\n",
    "        df = df[df['lang']==i]\n",
    "\n",
    "        loaders['valid_'+ i] = DataLoader(\n",
    "            QuestDataset(df, train_mode=False),\n",
    "            num_workers=workers,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is 48821 samples, 4276 samples and 44545 samples\n",
      "Class balance is 0.09\n",
      "----------------Experiment: simple\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "1/300 * Epoch (train):   0% 1/268 [00:00<02:11,  2.03it/s, loss=0.009]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/jig_env/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning:\n",
      "\n",
      "This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.03it/s, loss=0.001]\n",
      "1/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.51it/s, loss=0.033]\n",
      "1/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.17it/s, loss=0.052]\n",
      "1/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.52it/s, loss=0.041]\n",
      "1/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 11.22it/s, loss=0.014]\n",
      "[2020-05-04 14:18:26,331] \n",
      "1/300 * Epoch 1 (_base): lr=1.000e-06 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): auc/_mean=0.9842 | auc/class_0=0.9842 | loss=0.0119\n",
      "1/300 * Epoch 1 (valid): auc/_mean=0.9113 | auc/class_0=0.9113 | es_auc/_mean=0.8961 | es_auc/class_0=0.8961 | es_loss=0.0411 | it_auc/_mean=0.8844 | it_auc/class_0=0.8844 | it_loss=0.0464 | loss=0.0318 | tr_auc/_mean=0.9728 | tr_auc/class_0=0.9728 | tr_loss=0.0104\n",
      "1/300 * Epoch 1 (valid_es): auc/_mean=0.8961 | auc/class_0=0.8961 | loss=0.0411\n",
      "1/300 * Epoch 1 (valid_it): auc/_mean=0.8844 | auc/class_0=0.8844 | loss=0.0464\n",
      "1/300 * Epoch 1 (valid_tr): auc/_mean=0.9728 | auc/class_0=0.9728 | loss=0.0104\n",
      "2/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.98it/s, loss=0.002]\n",
      "2/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.64it/s, loss=0.032]\n",
      "2/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.28it/s, loss=0.053]\n",
      "2/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.28it/s, loss=0.035]\n",
      "2/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.41it/s, loss=0.017]\n",
      "[2020-05-04 14:20:11,416] \n",
      "2/300 * Epoch 2 (_base): lr=1.000e-06 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): auc/_mean=0.9887 | auc/class_0=0.9887 | loss=0.0099\n",
      "2/300 * Epoch 2 (valid): auc/_mean=0.9211 | auc/class_0=0.9211 | es_auc/_mean=0.8885 | es_auc/class_0=0.8885 | es_loss=0.0361 | it_auc/_mean=0.8854 | it_auc/class_0=0.8854 | it_loss=0.0400 | loss=0.0271 | tr_auc/_mean=0.9737 | tr_auc/class_0=0.9737 | tr_loss=0.0101\n",
      "2/300 * Epoch 2 (valid_es): auc/_mean=0.8885 | auc/class_0=0.8885 | loss=0.0361\n",
      "2/300 * Epoch 2 (valid_it): auc/_mean=0.8854 | auc/class_0=0.8854 | loss=0.0400\n",
      "2/300 * Epoch 2 (valid_tr): auc/_mean=0.9737 | auc/class_0=0.9737 | loss=0.0101\n",
      "3/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=0.002]    \n",
      "3/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.79it/s, loss=0.030]\n",
      "3/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.11it/s, loss=0.059]\n",
      "3/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.96it/s, loss=0.037]\n",
      "3/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.45it/s, loss=0.012]\n",
      "[2020-05-04 14:23:02,025] \n",
      "3/300 * Epoch 3 (_base): lr=1.000e-06 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): auc/_mean=0.9914 | auc/class_0=0.9914 | loss=0.0087\n",
      "3/300 * Epoch 3 (valid): auc/_mean=0.9325 | auc/class_0=0.9325 | es_auc/_mean=0.8988 | es_auc/class_0=0.8988 | es_loss=0.0363 | it_auc/_mean=0.8858 | it_auc/class_0=0.8858 | it_loss=0.0434 | loss=0.0267 | tr_auc/_mean=0.9794 | tr_auc/class_0=0.9794 | tr_loss=0.0093\n",
      "3/300 * Epoch 3 (valid_es): auc/_mean=0.8988 | auc/class_0=0.8988 | loss=0.0363\n",
      "3/300 * Epoch 3 (valid_it): auc/_mean=0.8858 | auc/class_0=0.8858 | loss=0.0434\n",
      "3/300 * Epoch 3 (valid_tr): auc/_mean=0.9794 | auc/class_0=0.9794 | loss=0.0093\n",
      "4/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.98it/s, loss=0.001]    \n",
      "4/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.79it/s, loss=0.034]\n",
      "4/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 11.48it/s, loss=0.060]\n",
      "4/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.42it/s, loss=0.035]\n",
      "4/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 11.56it/s, loss=0.014]   \n",
      "[2020-05-04 14:25:46,681] \n",
      "4/300 * Epoch 4 (_base): lr=1.000e-06 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): auc/_mean=0.9928 | auc/class_0=0.9928 | loss=0.0079\n",
      "4/300 * Epoch 4 (valid): auc/_mean=0.9281 | auc/class_0=0.9281 | es_auc/_mean=0.9057 | es_auc/class_0=0.9057 | es_loss=0.0340 | it_auc/_mean=0.8936 | it_auc/class_0=0.8936 | it_loss=0.0409 | loss=0.0280 | tr_auc/_mean=0.9803 | tr_auc/class_0=0.9803 | tr_loss=0.0094\n",
      "4/300 * Epoch 4 (valid_es): auc/_mean=0.9057 | auc/class_0=0.9057 | loss=0.0340\n",
      "4/300 * Epoch 4 (valid_it): auc/_mean=0.8936 | auc/class_0=0.8936 | loss=0.0409\n",
      "4/300 * Epoch 4 (valid_tr): auc/_mean=0.9803 | auc/class_0=0.9803 | loss=0.0094\n",
      "5/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.96it/s, loss=8.131e-04]\n",
      "5/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.80it/s, loss=0.029]\n",
      "5/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.00it/s, loss=0.057]\n",
      "5/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.84it/s, loss=0.039]\n",
      "5/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.59it/s, loss=0.014]\n",
      "[2020-05-04 14:27:34,990] \n",
      "5/300 * Epoch 5 (_base): lr=1.000e-06 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): auc/_mean=0.9936 | auc/class_0=0.9936 | loss=0.0073\n",
      "5/300 * Epoch 5 (valid): auc/_mean=0.9313 | auc/class_0=0.9313 | es_auc/_mean=0.9076 | es_auc/class_0=0.9076 | es_loss=0.0366 | it_auc/_mean=0.8995 | it_auc/class_0=0.8995 | it_loss=0.0471 | loss=0.0301 | tr_auc/_mean=0.9745 | tr_auc/class_0=0.9745 | tr_loss=0.0117\n",
      "5/300 * Epoch 5 (valid_es): auc/_mean=0.9076 | auc/class_0=0.9076 | loss=0.0366\n",
      "5/300 * Epoch 5 (valid_it): auc/_mean=0.8995 | auc/class_0=0.8995 | loss=0.0471\n",
      "5/300 * Epoch 5 (valid_tr): auc/_mean=0.9745 | auc/class_0=0.9745 | loss=0.0117\n",
      "6/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=7.380e-04]\n",
      "6/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.84it/s, loss=0.035]\n",
      "6/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.36it/s, loss=0.059]\n",
      "6/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.94it/s, loss=0.041]\n",
      "6/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.44it/s, loss=0.011]\n",
      "[2020-05-04 14:29:19,852] \n",
      "6/300 * Epoch 6 (_base): lr=1.000e-06 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): auc/_mean=0.9947 | auc/class_0=0.9947 | loss=0.0067\n",
      "6/300 * Epoch 6 (valid): auc/_mean=0.9273 | auc/class_0=0.9273 | es_auc/_mean=0.8992 | es_auc/class_0=0.8992 | es_loss=0.0363 | it_auc/_mean=0.9053 | it_auc/class_0=0.9053 | it_loss=0.0417 | loss=0.0289 | tr_auc/_mean=0.9783 | tr_auc/class_0=0.9783 | tr_loss=0.0105\n",
      "6/300 * Epoch 6 (valid_es): auc/_mean=0.8992 | auc/class_0=0.8992 | loss=0.0363\n",
      "6/300 * Epoch 6 (valid_it): auc/_mean=0.9053 | auc/class_0=0.9053 | loss=0.0417\n",
      "6/300 * Epoch 6 (valid_tr): auc/_mean=0.9783 | auc/class_0=0.9783 | loss=0.0105\n",
      "7/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.98it/s, loss=8.135e-04]\n",
      "7/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.80it/s, loss=0.033]\n",
      "7/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.22it/s, loss=0.068]\n",
      "7/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.02it/s, loss=0.041]\n",
      "7/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.53it/s, loss=0.014]   \n",
      "[2020-05-04 14:31:05,604] \n",
      "7/300 * Epoch 7 (_base): lr=2.500e-07 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): auc/_mean=0.9951 | auc/class_0=0.9951 | loss=0.0064\n",
      "7/300 * Epoch 7 (valid): auc/_mean=0.9313 | auc/class_0=0.9313 | es_auc/_mean=0.9102 | es_auc/class_0=0.9102 | es_loss=0.0357 | it_auc/_mean=0.9014 | it_auc/class_0=0.9014 | it_loss=0.0440 | loss=0.0284 | tr_auc/_mean=0.9813 | tr_auc/class_0=0.9813 | tr_loss=0.0095\n",
      "7/300 * Epoch 7 (valid_es): auc/_mean=0.9102 | auc/class_0=0.9102 | loss=0.0357\n",
      "7/300 * Epoch 7 (valid_it): auc/_mean=0.9014 | auc/class_0=0.9014 | loss=0.0440\n",
      "7/300 * Epoch 7 (valid_tr): auc/_mean=0.9813 | auc/class_0=0.9813 | loss=0.0095\n",
      "8/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.04it/s, loss=0.001]    \n",
      "8/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.66it/s, loss=0.031]\n",
      "8/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 11.99it/s, loss=0.065]\n",
      "8/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.28it/s, loss=0.047]\n",
      "8/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.67it/s, loss=0.015]   \n",
      "[2020-05-04 14:32:55,205] \n",
      "8/300 * Epoch 8 (_base): lr=2.500e-07 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): auc/_mean=0.9956 | auc/class_0=0.9956 | loss=0.0061\n",
      "8/300 * Epoch 8 (valid): auc/_mean=0.9310 | auc/class_0=0.9310 | es_auc/_mean=0.9104 | es_auc/class_0=0.9104 | es_loss=0.0403 | it_auc/_mean=0.8964 | it_auc/class_0=0.8964 | it_loss=0.0528 | loss=0.0335 | tr_auc/_mean=0.9778 | tr_auc/class_0=0.9778 | tr_loss=0.0117\n",
      "8/300 * Epoch 8 (valid_es): auc/_mean=0.9104 | auc/class_0=0.9104 | loss=0.0403\n",
      "8/300 * Epoch 8 (valid_it): auc/_mean=0.8964 | auc/class_0=0.8964 | loss=0.0528\n",
      "8/300 * Epoch 8 (valid_tr): auc/_mean=0.9778 | auc/class_0=0.9778 | loss=0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/300 * Epoch (train):  46% 123/268 [00:20<00:23,  6.10it/s, loss=0.007]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "9/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.97it/s, loss=8.135e-04]\n",
      "9/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.03it/s, loss=0.034]\n",
      "9/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.36it/s, loss=0.066]\n",
      "9/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.35it/s, loss=0.043]\n",
      "9/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.54it/s, loss=0.015]\n",
      "[2020-05-04 14:34:47,835] \n",
      "9/300 * Epoch 9 (_base): lr=2.500e-07 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): auc/_mean=0.9959 | auc/class_0=0.9959 | loss=0.0060\n",
      "9/300 * Epoch 9 (valid): auc/_mean=0.9355 | auc/class_0=0.9355 | es_auc/_mean=0.9148 | es_auc/class_0=0.9148 | es_loss=0.0396 | it_auc/_mean=0.8931 | it_auc/class_0=0.8931 | it_loss=0.0508 | loss=0.0313 | tr_auc/_mean=0.9797 | tr_auc/class_0=0.9797 | tr_loss=0.0110\n",
      "9/300 * Epoch 9 (valid_es): auc/_mean=0.9148 | auc/class_0=0.9148 | loss=0.0396\n",
      "9/300 * Epoch 9 (valid_it): auc/_mean=0.8931 | auc/class_0=0.8931 | loss=0.0508\n",
      "9/300 * Epoch 9 (valid_tr): auc/_mean=0.9797 | auc/class_0=0.9797 | loss=0.0110\n",
      "10/300 * Epoch (train):  18% 49/268 [00:08<00:36,  6.06it/s, loss=0.008]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "10/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=4.190e-04]\n",
      "10/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.90it/s, loss=0.031]\n",
      "10/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.24it/s, loss=0.065]\n",
      "10/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.81it/s, loss=0.045]\n",
      "10/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.39it/s, loss=0.012]   \n",
      "[2020-05-04 14:37:23,849] \n",
      "10/300 * Epoch 10 (_base): lr=2.500e-07 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): auc/_mean=0.9960 | auc/class_0=0.9960 | loss=0.0059\n",
      "10/300 * Epoch 10 (valid): auc/_mean=0.9340 | auc/class_0=0.9340 | es_auc/_mean=0.9106 | es_auc/class_0=0.9106 | es_loss=0.0405 | it_auc/_mean=0.9064 | it_auc/class_0=0.9064 | it_loss=0.0483 | loss=0.0319 | tr_auc/_mean=0.9795 | tr_auc/class_0=0.9795 | tr_loss=0.0111\n",
      "10/300 * Epoch 10 (valid_es): auc/_mean=0.9106 | auc/class_0=0.9106 | loss=0.0405\n",
      "10/300 * Epoch 10 (valid_it): auc/_mean=0.9064 | auc/class_0=0.9064 | loss=0.0483\n",
      "10/300 * Epoch 10 (valid_tr): auc/_mean=0.9795 | auc/class_0=0.9795 | loss=0.0111\n",
      "11/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=5.386e-04]\n",
      "11/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.02it/s, loss=0.031]\n",
      "11/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.49it/s, loss=0.064]\n",
      "11/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.03it/s, loss=0.045]\n",
      "11/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.70it/s, loss=0.009]   \n",
      "[2020-05-04 14:39:08,338] \n",
      "11/300 * Epoch 11 (_base): lr=2.500e-07 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): auc/_mean=0.9960 | auc/class_0=0.9960 | loss=0.0058\n",
      "11/300 * Epoch 11 (valid): auc/_mean=0.9341 | auc/class_0=0.9341 | es_auc/_mean=0.9145 | es_auc/class_0=0.9145 | es_loss=0.0397 | it_auc/_mean=0.9037 | it_auc/class_0=0.9037 | it_loss=0.0519 | loss=0.0322 | tr_auc/_mean=0.9807 | tr_auc/class_0=0.9807 | tr_loss=0.0110\n",
      "11/300 * Epoch 11 (valid_es): auc/_mean=0.9145 | auc/class_0=0.9145 | loss=0.0397\n",
      "11/300 * Epoch 11 (valid_it): auc/_mean=0.9037 | auc/class_0=0.9037 | loss=0.0519\n",
      "11/300 * Epoch 11 (valid_tr): auc/_mean=0.9807 | auc/class_0=0.9807 | loss=0.0110\n",
      "12/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=7.723e-04]\n",
      "12/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.99it/s, loss=0.030]\n",
      "12/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.49it/s, loss=0.062]\n",
      "12/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.01it/s, loss=0.044]\n",
      "12/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.45it/s, loss=0.013]\n",
      "[2020-05-04 14:40:58,573] \n",
      "12/300 * Epoch 12 (_base): lr=2.500e-07 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): auc/_mean=0.9960 | auc/class_0=0.9960 | loss=0.0059\n",
      "12/300 * Epoch 12 (valid): auc/_mean=0.9305 | auc/class_0=0.9305 | es_auc/_mean=0.9082 | es_auc/class_0=0.9082 | es_loss=0.0440 | it_auc/_mean=0.8944 | it_auc/class_0=0.8944 | it_loss=0.0529 | loss=0.0341 | tr_auc/_mean=0.9810 | tr_auc/class_0=0.9810 | tr_loss=0.0117\n",
      "12/300 * Epoch 12 (valid_es): auc/_mean=0.9082 | auc/class_0=0.9082 | loss=0.0440\n",
      "12/300 * Epoch 12 (valid_it): auc/_mean=0.8944 | auc/class_0=0.8944 | loss=0.0529\n",
      "12/300 * Epoch 12 (valid_tr): auc/_mean=0.9810 | auc/class_0=0.9810 | loss=0.0117\n",
      "13/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=4.742e-04]\n",
      "13/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.97it/s, loss=0.031]\n",
      "13/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.40it/s, loss=0.068]\n",
      "13/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.26it/s, loss=0.047]\n",
      "13/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.42it/s, loss=0.017]\n",
      "[2020-05-04 14:42:44,390] \n",
      "13/300 * Epoch 13 (_base): lr=6.250e-08 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0056\n",
      "13/300 * Epoch 13 (valid): auc/_mean=0.9350 | auc/class_0=0.9350 | es_auc/_mean=0.9117 | es_auc/class_0=0.9117 | es_loss=0.0393 | it_auc/_mean=0.9068 | it_auc/class_0=0.9068 | it_loss=0.0493 | loss=0.0315 | tr_auc/_mean=0.9791 | tr_auc/class_0=0.9791 | tr_loss=0.0113\n",
      "13/300 * Epoch 13 (valid_es): auc/_mean=0.9117 | auc/class_0=0.9117 | loss=0.0393\n",
      "13/300 * Epoch 13 (valid_it): auc/_mean=0.9068 | auc/class_0=0.9068 | loss=0.0493\n",
      "13/300 * Epoch 13 (valid_tr): auc/_mean=0.9791 | auc/class_0=0.9791 | loss=0.0113\n",
      "14/300 * Epoch (train):  43% 114/268 [00:19<00:25,  5.97it/s, loss=0.001]   Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "14/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.96it/s, loss=5.739e-04]\n",
      "14/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.69it/s, loss=0.035]\n",
      "14/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.37it/s, loss=0.063]\n",
      "14/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 10.96it/s, loss=0.043]\n",
      "14/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.11it/s, loss=0.012]   \n",
      "[2020-05-04 14:44:30,474] \n",
      "14/300 * Epoch 14 (_base): lr=6.250e-08 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): auc/_mean=0.9964 | auc/class_0=0.9964 | loss=0.0056\n",
      "14/300 * Epoch 14 (valid): auc/_mean=0.9336 | auc/class_0=0.9336 | es_auc/_mean=0.9146 | es_auc/class_0=0.9146 | es_loss=0.0402 | it_auc/_mean=0.9026 | it_auc/class_0=0.9026 | it_loss=0.0504 | loss=0.0334 | tr_auc/_mean=0.9813 | tr_auc/class_0=0.9813 | tr_loss=0.0107\n",
      "14/300 * Epoch 14 (valid_es): auc/_mean=0.9146 | auc/class_0=0.9146 | loss=0.0402\n",
      "14/300 * Epoch 14 (valid_it): auc/_mean=0.9026 | auc/class_0=0.9026 | loss=0.0504\n",
      "14/300 * Epoch 14 (valid_tr): auc/_mean=0.9813 | auc/class_0=0.9813 | loss=0.0107\n",
      "15/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=3.643e-04]\n",
      "15/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.89it/s, loss=0.032]\n",
      "15/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.47it/s, loss=0.062]\n",
      "15/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.36it/s, loss=0.053]\n",
      "15/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.22it/s, loss=0.014]   \n",
      "[2020-05-04 14:46:16,124] \n",
      "15/300 * Epoch 15 (_base): lr=6.250e-08 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): auc/_mean=0.9964 | auc/class_0=0.9964 | loss=0.0055\n",
      "15/300 * Epoch 15 (valid): auc/_mean=0.9349 | auc/class_0=0.9349 | es_auc/_mean=0.9120 | es_auc/class_0=0.9120 | es_loss=0.0412 | it_auc/_mean=0.9081 | it_auc/class_0=0.9081 | it_loss=0.0525 | loss=0.0336 | tr_auc/_mean=0.9804 | tr_auc/class_0=0.9804 | tr_loss=0.0113\n",
      "15/300 * Epoch 15 (valid_es): auc/_mean=0.9120 | auc/class_0=0.9120 | loss=0.0412\n",
      "15/300 * Epoch 15 (valid_it): auc/_mean=0.9081 | auc/class_0=0.9081 | loss=0.0525\n",
      "15/300 * Epoch 15 (valid_tr): auc/_mean=0.9804 | auc/class_0=0.9804 | loss=0.0113\n",
      "16/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=0.001]    \n",
      "16/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.99it/s, loss=0.027]\n",
      "16/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.28it/s, loss=0.062]\n",
      "16/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.07it/s, loss=0.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.55it/s, loss=0.012]   \n",
      "[2020-05-04 14:48:04,491] \n",
      "16/300 * Epoch 16 (_base): lr=6.250e-08 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): auc/_mean=0.9964 | auc/class_0=0.9964 | loss=0.0056\n",
      "16/300 * Epoch 16 (valid): auc/_mean=0.9350 | auc/class_0=0.9350 | es_auc/_mean=0.9073 | es_auc/class_0=0.9073 | es_loss=0.0428 | it_auc/_mean=0.8965 | it_auc/class_0=0.8965 | it_loss=0.0558 | loss=0.0336 | tr_auc/_mean=0.9797 | tr_auc/class_0=0.9797 | tr_loss=0.0118\n",
      "16/300 * Epoch 16 (valid_es): auc/_mean=0.9073 | auc/class_0=0.9073 | loss=0.0428\n",
      "16/300 * Epoch 16 (valid_it): auc/_mean=0.8965 | auc/class_0=0.8965 | loss=0.0558\n",
      "16/300 * Epoch 16 (valid_tr): auc/_mean=0.9797 | auc/class_0=0.9797 | loss=0.0118\n",
      "17/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=5.806e-04]\n",
      "17/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.95it/s, loss=0.030]\n",
      "17/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.10it/s, loss=0.064]\n",
      "17/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.18it/s, loss=0.054]\n",
      "17/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 11.69it/s, loss=0.010]\n",
      "[2020-05-04 14:49:57,791] \n",
      "17/300 * Epoch 17 (_base): lr=6.250e-08 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0053\n",
      "17/300 * Epoch 17 (valid): auc/_mean=0.9312 | auc/class_0=0.9312 | es_auc/_mean=0.9073 | es_auc/class_0=0.9073 | es_loss=0.0425 | it_auc/_mean=0.8955 | it_auc/class_0=0.8955 | it_loss=0.0554 | loss=0.0346 | tr_auc/_mean=0.9845 | tr_auc/class_0=0.9845 | tr_loss=0.0099\n",
      "17/300 * Epoch 17 (valid_es): auc/_mean=0.9073 | auc/class_0=0.9073 | loss=0.0425\n",
      "17/300 * Epoch 17 (valid_it): auc/_mean=0.8955 | auc/class_0=0.8955 | loss=0.0554\n",
      "17/300 * Epoch 17 (valid_tr): auc/_mean=0.9845 | auc/class_0=0.9845 | loss=0.0099\n",
      "18/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=0.001]    \n",
      "18/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.83it/s, loss=0.031]\n",
      "18/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 11.72it/s, loss=0.063]\n",
      "18/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.00it/s, loss=0.051]\n",
      "18/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.75it/s, loss=0.014]   \n",
      "[2020-05-04 14:51:54,021] \n",
      "18/300 * Epoch 18 (_base): lr=6.250e-08 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0054\n",
      "18/300 * Epoch 18 (valid): auc/_mean=0.9375 | auc/class_0=0.9375 | es_auc/_mean=0.9041 | es_auc/class_0=0.9041 | es_loss=0.0442 | it_auc/_mean=0.9001 | it_auc/class_0=0.9001 | it_loss=0.0537 | loss=0.0351 | tr_auc/_mean=0.9812 | tr_auc/class_0=0.9812 | tr_loss=0.0119\n",
      "18/300 * Epoch 18 (valid_es): auc/_mean=0.9041 | auc/class_0=0.9041 | loss=0.0442\n",
      "18/300 * Epoch 18 (valid_it): auc/_mean=0.9001 | auc/class_0=0.9001 | loss=0.0537\n",
      "18/300 * Epoch 18 (valid_tr): auc/_mean=0.9812 | auc/class_0=0.9812 | loss=0.0119\n",
      "19/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.97it/s, loss=7.484e-04]\n",
      "19/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.34it/s, loss=0.032]\n",
      "19/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.07it/s, loss=0.063]\n",
      "19/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.80it/s, loss=0.046]\n",
      "19/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.26it/s, loss=0.010]   \n",
      "[2020-05-04 14:54:27,511] \n",
      "19/300 * Epoch 19 (_base): lr=1.562e-08 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): auc/_mean=0.9966 | auc/class_0=0.9966 | loss=0.0054\n",
      "19/300 * Epoch 19 (valid): auc/_mean=0.9376 | auc/class_0=0.9376 | es_auc/_mean=0.9112 | es_auc/class_0=0.9112 | es_loss=0.0426 | it_auc/_mean=0.9081 | it_auc/class_0=0.9081 | it_loss=0.0519 | loss=0.0343 | tr_auc/_mean=0.9803 | tr_auc/class_0=0.9803 | tr_loss=0.0114\n",
      "19/300 * Epoch 19 (valid_es): auc/_mean=0.9112 | auc/class_0=0.9112 | loss=0.0426\n",
      "19/300 * Epoch 19 (valid_it): auc/_mean=0.9081 | auc/class_0=0.9081 | loss=0.0519\n",
      "19/300 * Epoch 19 (valid_tr): auc/_mean=0.9803 | auc/class_0=0.9803 | loss=0.0114\n",
      "20/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=5.240e-04]\n",
      "20/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.40it/s, loss=0.032]\n",
      "20/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.24it/s, loss=0.063]\n",
      "20/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.72it/s, loss=0.044]\n",
      "20/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.97it/s, loss=0.015]   \n",
      "[2020-05-04 14:57:04,628] \n",
      "20/300 * Epoch 20 (_base): lr=1.562e-08 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): auc/_mean=0.9969 | auc/class_0=0.9969 | loss=0.0052\n",
      "20/300 * Epoch 20 (valid): auc/_mean=0.9332 | auc/class_0=0.9332 | es_auc/_mean=0.9175 | es_auc/class_0=0.9175 | es_loss=0.0420 | it_auc/_mean=0.8994 | it_auc/class_0=0.8994 | it_loss=0.0559 | loss=0.0346 | tr_auc/_mean=0.9798 | tr_auc/class_0=0.9798 | tr_loss=0.0121\n",
      "20/300 * Epoch 20 (valid_es): auc/_mean=0.9175 | auc/class_0=0.9175 | loss=0.0420\n",
      "20/300 * Epoch 20 (valid_it): auc/_mean=0.8994 | auc/class_0=0.8994 | loss=0.0559\n",
      "20/300 * Epoch 20 (valid_tr): auc/_mean=0.9798 | auc/class_0=0.9798 | loss=0.0121\n",
      "21/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=8.378e-04]\n",
      "21/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.46it/s, loss=0.031]\n",
      "21/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.22it/s, loss=0.058]\n",
      "21/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.98it/s, loss=0.045]\n",
      "21/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.38it/s, loss=0.015]\n",
      "[2020-05-04 14:58:54,726] \n",
      "21/300 * Epoch 21 (_base): lr=1.562e-08 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0055\n",
      "21/300 * Epoch 21 (valid): auc/_mean=0.9325 | auc/class_0=0.9325 | es_auc/_mean=0.9044 | es_auc/class_0=0.9044 | es_loss=0.0439 | it_auc/_mean=0.8990 | it_auc/class_0=0.8990 | it_loss=0.0550 | loss=0.0340 | tr_auc/_mean=0.9768 | tr_auc/class_0=0.9768 | tr_loss=0.0126\n",
      "21/300 * Epoch 21 (valid_es): auc/_mean=0.9044 | auc/class_0=0.9044 | loss=0.0439\n",
      "21/300 * Epoch 21 (valid_it): auc/_mean=0.8990 | auc/class_0=0.8990 | loss=0.0550\n",
      "21/300 * Epoch 21 (valid_tr): auc/_mean=0.9768 | auc/class_0=0.9768 | loss=0.0126\n",
      "22/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=6.127e-04]\n",
      "22/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.28it/s, loss=0.028]\n",
      "22/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.38it/s, loss=0.062]\n",
      "22/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.98it/s, loss=0.045]\n",
      "22/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.12it/s, loss=0.012]\n",
      "[2020-05-04 15:00:42,258] \n",
      "22/300 * Epoch 22 (_base): lr=1.562e-08 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): auc/_mean=0.9964 | auc/class_0=0.9964 | loss=0.0055\n",
      "22/300 * Epoch 22 (valid): auc/_mean=0.9373 | auc/class_0=0.9373 | es_auc/_mean=0.9123 | es_auc/class_0=0.9123 | es_loss=0.0426 | it_auc/_mean=0.9114 | it_auc/class_0=0.9114 | it_loss=0.0511 | loss=0.0340 | tr_auc/_mean=0.9802 | tr_auc/class_0=0.9802 | tr_loss=0.0115\n",
      "22/300 * Epoch 22 (valid_es): auc/_mean=0.9123 | auc/class_0=0.9123 | loss=0.0426\n",
      "22/300 * Epoch 22 (valid_it): auc/_mean=0.9114 | auc/class_0=0.9114 | loss=0.0511\n",
      "22/300 * Epoch 22 (valid_tr): auc/_mean=0.9802 | auc/class_0=0.9802 | loss=0.0115\n",
      "23/300 * Epoch (train):  21% 57/268 [00:09<00:34,  6.10it/s, loss=0.003]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "23/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.03it/s, loss=0.001]    \n",
      "23/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.32it/s, loss=0.033]\n",
      "23/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.25it/s, loss=0.056]\n",
      "23/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 13.00it/s, loss=0.046]\n",
      "23/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.41it/s, loss=0.012]\n",
      "[2020-05-04 15:02:31,634] \n",
      "23/300 * Epoch 23 (_base): lr=1.562e-08 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0053\n",
      "23/300 * Epoch 23 (valid): auc/_mean=0.9364 | auc/class_0=0.9364 | es_auc/_mean=0.9036 | es_auc/class_0=0.9036 | es_loss=0.0433 | it_auc/_mean=0.9036 | it_auc/class_0=0.9036 | it_loss=0.0528 | loss=0.0347 | tr_auc/_mean=0.9814 | tr_auc/class_0=0.9814 | tr_loss=0.0114\n",
      "23/300 * Epoch 23 (valid_es): auc/_mean=0.9036 | auc/class_0=0.9036 | loss=0.0433\n",
      "23/300 * Epoch 23 (valid_it): auc/_mean=0.9036 | auc/class_0=0.9036 | loss=0.0528\n",
      "23/300 * Epoch 23 (valid_tr): auc/_mean=0.9814 | auc/class_0=0.9814 | loss=0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.01it/s, loss=6.601e-04]\n",
      "24/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.44it/s, loss=0.034]\n",
      "24/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.19it/s, loss=0.062]\n",
      "24/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.76it/s, loss=0.047]\n",
      "24/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.18it/s, loss=0.010]   \n",
      "[2020-05-04 15:04:24,525] \n",
      "24/300 * Epoch 24 (_base): lr=1.562e-08 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): auc/_mean=0.9966 | auc/class_0=0.9966 | loss=0.0055\n",
      "24/300 * Epoch 24 (valid): auc/_mean=0.9358 | auc/class_0=0.9358 | es_auc/_mean=0.9111 | es_auc/class_0=0.9111 | es_loss=0.0424 | it_auc/_mean=0.9103 | it_auc/class_0=0.9103 | it_loss=0.0522 | loss=0.0343 | tr_auc/_mean=0.9816 | tr_auc/class_0=0.9816 | tr_loss=0.0108\n",
      "24/300 * Epoch 24 (valid_es): auc/_mean=0.9111 | auc/class_0=0.9111 | loss=0.0424\n",
      "24/300 * Epoch 24 (valid_it): auc/_mean=0.9103 | auc/class_0=0.9103 | loss=0.0522\n",
      "24/300 * Epoch 24 (valid_tr): auc/_mean=0.9816 | auc/class_0=0.9816 | loss=0.0108\n",
      "25/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=0.001]    \n",
      "25/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.36it/s, loss=0.034]\n",
      "25/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.25it/s, loss=0.055]\n",
      "25/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.89it/s, loss=0.051]\n",
      "25/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.33it/s, loss=0.012]\n",
      "[2020-05-04 15:06:33,487] \n",
      "25/300 * Epoch 25 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): auc/_mean=0.9968 | auc/class_0=0.9968 | loss=0.0053\n",
      "25/300 * Epoch 25 (valid): auc/_mean=0.9357 | auc/class_0=0.9357 | es_auc/_mean=0.9174 | es_auc/class_0=0.9174 | es_loss=0.0421 | it_auc/_mean=0.9098 | it_auc/class_0=0.9098 | it_loss=0.0526 | loss=0.0336 | tr_auc/_mean=0.9807 | tr_auc/class_0=0.9807 | tr_loss=0.0108\n",
      "25/300 * Epoch 25 (valid_es): auc/_mean=0.9174 | auc/class_0=0.9174 | loss=0.0421\n",
      "25/300 * Epoch 25 (valid_it): auc/_mean=0.9098 | auc/class_0=0.9098 | loss=0.0526\n",
      "25/300 * Epoch 25 (valid_tr): auc/_mean=0.9807 | auc/class_0=0.9807 | loss=0.0108\n",
      "26/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.03it/s, loss=0.001]    \n",
      "26/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.35it/s, loss=0.035]\n",
      "26/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.28it/s, loss=0.053]\n",
      "26/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.82it/s, loss=0.042]\n",
      "26/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.27it/s, loss=0.014]\n",
      "[2020-05-04 15:08:32,488] \n",
      "26/300 * Epoch 26 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "26/300 * Epoch 26 (train): auc/_mean=0.9969 | auc/class_0=0.9969 | loss=0.0051\n",
      "26/300 * Epoch 26 (valid): auc/_mean=0.9338 | auc/class_0=0.9338 | es_auc/_mean=0.9081 | es_auc/class_0=0.9081 | es_loss=0.0423 | it_auc/_mean=0.9068 | it_auc/class_0=0.9068 | it_loss=0.0522 | loss=0.0339 | tr_auc/_mean=0.9797 | tr_auc/class_0=0.9797 | tr_loss=0.0122\n",
      "26/300 * Epoch 26 (valid_es): auc/_mean=0.9081 | auc/class_0=0.9081 | loss=0.0423\n",
      "26/300 * Epoch 26 (valid_it): auc/_mean=0.9068 | auc/class_0=0.9068 | loss=0.0522\n",
      "26/300 * Epoch 26 (valid_tr): auc/_mean=0.9797 | auc/class_0=0.9797 | loss=0.0122\n",
      "27/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=0.001]    \n",
      "27/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.40it/s, loss=0.030]\n",
      "27/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.32it/s, loss=0.054]\n",
      "27/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.90it/s, loss=0.051]\n",
      "27/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.35it/s, loss=0.011]\n",
      "[2020-05-04 15:10:20,185] \n",
      "27/300 * Epoch 27 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "27/300 * Epoch 27 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0053\n",
      "27/300 * Epoch 27 (valid): auc/_mean=0.9354 | auc/class_0=0.9354 | es_auc/_mean=0.9124 | es_auc/class_0=0.9124 | es_loss=0.0430 | it_auc/_mean=0.9033 | it_auc/class_0=0.9033 | it_loss=0.0544 | loss=0.0339 | tr_auc/_mean=0.9805 | tr_auc/class_0=0.9805 | tr_loss=0.0113\n",
      "27/300 * Epoch 27 (valid_es): auc/_mean=0.9124 | auc/class_0=0.9124 | loss=0.0430\n",
      "27/300 * Epoch 27 (valid_it): auc/_mean=0.9033 | auc/class_0=0.9033 | loss=0.0544\n",
      "27/300 * Epoch 27 (valid_tr): auc/_mean=0.9805 | auc/class_0=0.9805 | loss=0.0113\n",
      "28/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=6.496e-04]\n",
      "28/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.40it/s, loss=0.030]\n",
      "28/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.20it/s, loss=0.053]\n",
      "28/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.90it/s, loss=0.053]\n",
      "28/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.22it/s, loss=0.009]\n",
      "[2020-05-04 15:12:08,173] \n",
      "28/300 * Epoch 28 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "28/300 * Epoch 28 (train): auc/_mean=0.9970 | auc/class_0=0.9970 | loss=0.0051\n",
      "28/300 * Epoch 28 (valid): auc/_mean=0.9363 | auc/class_0=0.9363 | es_auc/_mean=0.9094 | es_auc/class_0=0.9094 | es_loss=0.0428 | it_auc/_mean=0.9062 | it_auc/class_0=0.9062 | it_loss=0.0536 | loss=0.0336 | tr_auc/_mean=0.9801 | tr_auc/class_0=0.9801 | tr_loss=0.0119\n",
      "28/300 * Epoch 28 (valid_es): auc/_mean=0.9094 | auc/class_0=0.9094 | loss=0.0428\n",
      "28/300 * Epoch 28 (valid_it): auc/_mean=0.9062 | auc/class_0=0.9062 | loss=0.0536\n",
      "28/300 * Epoch 28 (valid_tr): auc/_mean=0.9801 | auc/class_0=0.9801 | loss=0.0119\n",
      "29/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.01it/s, loss=3.607e-04]\n",
      "29/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.42it/s, loss=0.033]\n",
      "29/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.31it/s, loss=0.054]\n",
      "29/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.96it/s, loss=0.052]\n",
      "29/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.08it/s, loss=0.017]\n",
      "[2020-05-04 15:13:56,355] \n",
      "29/300 * Epoch 29 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "29/300 * Epoch 29 (train): auc/_mean=0.9966 | auc/class_0=0.9966 | loss=0.0054\n",
      "29/300 * Epoch 29 (valid): auc/_mean=0.9319 | auc/class_0=0.9319 | es_auc/_mean=0.9195 | es_auc/class_0=0.9195 | es_loss=0.0401 | it_auc/_mean=0.9043 | it_auc/class_0=0.9043 | it_loss=0.0530 | loss=0.0355 | tr_auc/_mean=0.9761 | tr_auc/class_0=0.9761 | tr_loss=0.0127\n",
      "29/300 * Epoch 29 (valid_es): auc/_mean=0.9195 | auc/class_0=0.9195 | loss=0.0401\n",
      "29/300 * Epoch 29 (valid_it): auc/_mean=0.9043 | auc/class_0=0.9043 | loss=0.0530\n",
      "29/300 * Epoch 29 (valid_tr): auc/_mean=0.9761 | auc/class_0=0.9761 | loss=0.0127\n",
      "30/300 * Epoch (train): 100% 268/268 [00:45<00:00,  5.95it/s, loss=4.684e-04]\n",
      "30/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.36it/s, loss=0.032]\n",
      "30/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.96it/s, loss=0.053]\n",
      "30/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 11.92it/s, loss=0.048]\n",
      "30/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.91it/s, loss=0.016]   \n",
      "[2020-05-04 15:15:44,633] \n",
      "30/300 * Epoch 30 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "30/300 * Epoch 30 (train): auc/_mean=0.9969 | auc/class_0=0.9969 | loss=0.0052\n",
      "30/300 * Epoch 30 (valid): auc/_mean=0.9345 | auc/class_0=0.9345 | es_auc/_mean=0.9086 | es_auc/class_0=0.9086 | es_loss=0.0426 | it_auc/_mean=0.9016 | it_auc/class_0=0.9016 | it_loss=0.0542 | loss=0.0334 | tr_auc/_mean=0.9783 | tr_auc/class_0=0.9783 | tr_loss=0.0123\n",
      "30/300 * Epoch 30 (valid_es): auc/_mean=0.9086 | auc/class_0=0.9086 | loss=0.0426\n",
      "30/300 * Epoch 30 (valid_it): auc/_mean=0.9016 | auc/class_0=0.9016 | loss=0.0542\n",
      "30/300 * Epoch 30 (valid_tr): auc/_mean=0.9783 | auc/class_0=0.9783 | loss=0.0123\n",
      "31/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=4.139e-04]\n",
      "31/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.26it/s, loss=0.033]\n",
      "31/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.05it/s, loss=0.053]\n",
      "31/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.79it/s, loss=0.048]\n",
      "31/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.38it/s, loss=0.010]   \n",
      "[2020-05-04 15:17:30,916] \n",
      "31/300 * Epoch 31 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "31/300 * Epoch 31 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0053\n",
      "31/300 * Epoch 31 (valid): auc/_mean=0.9311 | auc/class_0=0.9311 | es_auc/_mean=0.9117 | es_auc/class_0=0.9117 | es_loss=0.0421 | it_auc/_mean=0.8976 | it_auc/class_0=0.8976 | it_loss=0.0564 | loss=0.0345 | tr_auc/_mean=0.9821 | tr_auc/class_0=0.9821 | tr_loss=0.0109\n",
      "31/300 * Epoch 31 (valid_es): auc/_mean=0.9117 | auc/class_0=0.9117 | loss=0.0421\n",
      "31/300 * Epoch 31 (valid_it): auc/_mean=0.8976 | auc/class_0=0.8976 | loss=0.0564\n",
      "31/300 * Epoch 31 (valid_tr): auc/_mean=0.9821 | auc/class_0=0.9821 | loss=0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=1.083e-04]\n",
      "32/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.42it/s, loss=0.030]\n",
      "32/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.17it/s, loss=0.053]\n",
      "32/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.79it/s, loss=0.047]\n",
      "32/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.20it/s, loss=0.015]\n",
      "[2020-05-04 15:19:14,847] \n",
      "32/300 * Epoch 32 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "32/300 * Epoch 32 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0054\n",
      "32/300 * Epoch 32 (valid): auc/_mean=0.9351 | auc/class_0=0.9351 | es_auc/_mean=0.9173 | es_auc/class_0=0.9173 | es_loss=0.0427 | it_auc/_mean=0.9090 | it_auc/class_0=0.9090 | it_loss=0.0535 | loss=0.0343 | tr_auc/_mean=0.9816 | tr_auc/class_0=0.9816 | tr_loss=0.0114\n",
      "32/300 * Epoch 32 (valid_es): auc/_mean=0.9173 | auc/class_0=0.9173 | loss=0.0427\n",
      "32/300 * Epoch 32 (valid_it): auc/_mean=0.9090 | auc/class_0=0.9090 | loss=0.0535\n",
      "32/300 * Epoch 32 (valid_tr): auc/_mean=0.9816 | auc/class_0=0.9816 | loss=0.0114\n",
      "33/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.04it/s, loss=2.325e-04]\n",
      "33/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.48it/s, loss=0.029]\n",
      "33/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.31it/s, loss=0.053]\n",
      "33/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.82it/s, loss=0.049]\n",
      "33/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.36it/s, loss=0.013]\n",
      "[2020-05-04 15:21:13,704] \n",
      "33/300 * Epoch 33 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "33/300 * Epoch 33 (train): auc/_mean=0.9969 | auc/class_0=0.9969 | loss=0.0052\n",
      "33/300 * Epoch 33 (valid): auc/_mean=0.9357 | auc/class_0=0.9357 | es_auc/_mean=0.9092 | es_auc/class_0=0.9092 | es_loss=0.0415 | it_auc/_mean=0.9068 | it_auc/class_0=0.9068 | it_loss=0.0541 | loss=0.0340 | tr_auc/_mean=0.9805 | tr_auc/class_0=0.9805 | tr_loss=0.0113\n",
      "33/300 * Epoch 33 (valid_es): auc/_mean=0.9092 | auc/class_0=0.9092 | loss=0.0415\n",
      "33/300 * Epoch 33 (valid_it): auc/_mean=0.9068 | auc/class_0=0.9068 | loss=0.0541\n",
      "33/300 * Epoch 33 (valid_tr): auc/_mean=0.9805 | auc/class_0=0.9805 | loss=0.0113\n",
      "34/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.07it/s, loss=7.759e-04]\n",
      "34/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.43it/s, loss=0.031]\n",
      "34/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.05it/s, loss=0.053]\n",
      "34/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.87it/s, loss=0.049]\n",
      "34/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.16it/s, loss=0.016]\n",
      "[2020-05-04 15:23:06,498] \n",
      "34/300 * Epoch 34 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "34/300 * Epoch 34 (train): auc/_mean=0.9968 | auc/class_0=0.9968 | loss=0.0053\n",
      "34/300 * Epoch 34 (valid): auc/_mean=0.9346 | auc/class_0=0.9346 | es_auc/_mean=0.9031 | es_auc/class_0=0.9031 | es_loss=0.0441 | it_auc/_mean=0.8975 | it_auc/class_0=0.8975 | it_loss=0.0539 | loss=0.0339 | tr_auc/_mean=0.9789 | tr_auc/class_0=0.9789 | tr_loss=0.0119\n",
      "34/300 * Epoch 34 (valid_es): auc/_mean=0.9031 | auc/class_0=0.9031 | loss=0.0441\n",
      "34/300 * Epoch 34 (valid_it): auc/_mean=0.8975 | auc/class_0=0.8975 | loss=0.0539\n",
      "34/300 * Epoch 34 (valid_tr): auc/_mean=0.9789 | auc/class_0=0.9789 | loss=0.0119\n",
      "35/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=0.001]    \n",
      "35/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.34it/s, loss=0.030]\n",
      "35/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.36it/s, loss=0.053]\n",
      "35/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.94it/s, loss=0.050]\n",
      "35/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.31it/s, loss=0.013]   \n",
      "[2020-05-04 15:24:58,049] \n",
      "35/300 * Epoch 35 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "35/300 * Epoch 35 (train): auc/_mean=0.9969 | auc/class_0=0.9969 | loss=0.0052\n",
      "35/300 * Epoch 35 (valid): auc/_mean=0.9345 | auc/class_0=0.9345 | es_auc/_mean=0.9121 | es_auc/class_0=0.9121 | es_loss=0.0421 | it_auc/_mean=0.9106 | it_auc/class_0=0.9106 | it_loss=0.0532 | loss=0.0343 | tr_auc/_mean=0.9779 | tr_auc/class_0=0.9779 | tr_loss=0.0125\n",
      "35/300 * Epoch 35 (valid_es): auc/_mean=0.9121 | auc/class_0=0.9121 | loss=0.0421\n",
      "35/300 * Epoch 35 (valid_it): auc/_mean=0.9106 | auc/class_0=0.9106 | loss=0.0532\n",
      "35/300 * Epoch 35 (valid_tr): auc/_mean=0.9779 | auc/class_0=0.9779 | loss=0.0125\n",
      "36/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=3.964e-04]\n",
      "36/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.50it/s, loss=0.030]\n",
      "36/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.31it/s, loss=0.055]\n",
      "36/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.94it/s, loss=0.044]\n",
      "36/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.31it/s, loss=0.013]\n",
      "[2020-05-04 15:26:47,655] \n",
      "36/300 * Epoch 36 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "36/300 * Epoch 36 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0053\n",
      "36/300 * Epoch 36 (valid): auc/_mean=0.9374 | auc/class_0=0.9374 | es_auc/_mean=0.9040 | es_auc/class_0=0.9040 | es_loss=0.0432 | it_auc/_mean=0.9027 | it_auc/class_0=0.9027 | it_loss=0.0528 | loss=0.0331 | tr_auc/_mean=0.9800 | tr_auc/class_0=0.9800 | tr_loss=0.0113\n",
      "36/300 * Epoch 36 (valid_es): auc/_mean=0.9040 | auc/class_0=0.9040 | loss=0.0432\n",
      "36/300 * Epoch 36 (valid_it): auc/_mean=0.9027 | auc/class_0=0.9027 | loss=0.0528\n",
      "36/300 * Epoch 36 (valid_tr): auc/_mean=0.9800 | auc/class_0=0.9800 | loss=0.0113\n",
      "37/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=8.382e-04]\n",
      "37/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.32it/s, loss=0.032]\n",
      "37/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.16it/s, loss=0.054]\n",
      "37/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.79it/s, loss=0.045]\n",
      "37/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.13it/s, loss=0.009]   \n",
      "[2020-05-04 15:28:35,193] \n",
      "37/300 * Epoch 37 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "37/300 * Epoch 37 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0054\n",
      "37/300 * Epoch 37 (valid): auc/_mean=0.9336 | auc/class_0=0.9336 | es_auc/_mean=0.9171 | es_auc/class_0=0.9171 | es_loss=0.0408 | it_auc/_mean=0.9112 | it_auc/class_0=0.9112 | it_loss=0.0529 | loss=0.0354 | tr_auc/_mean=0.9812 | tr_auc/class_0=0.9812 | tr_loss=0.0112\n",
      "37/300 * Epoch 37 (valid_es): auc/_mean=0.9171 | auc/class_0=0.9171 | loss=0.0408\n",
      "37/300 * Epoch 37 (valid_it): auc/_mean=0.9112 | auc/class_0=0.9112 | loss=0.0529\n",
      "37/300 * Epoch 37 (valid_tr): auc/_mean=0.9812 | auc/class_0=0.9812 | loss=0.0112\n",
      "38/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=9.073e-04]\n",
      "38/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.28it/s, loss=0.029]\n",
      "38/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.00it/s, loss=0.056]\n",
      "38/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.88it/s, loss=0.046]\n",
      "38/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.44it/s, loss=0.014]   \n",
      "[2020-05-04 15:30:18,828] \n",
      "38/300 * Epoch 38 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "38/300 * Epoch 38 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0054\n",
      "38/300 * Epoch 38 (valid): auc/_mean=0.9346 | auc/class_0=0.9346 | es_auc/_mean=0.9119 | es_auc/class_0=0.9119 | es_loss=0.0416 | it_auc/_mean=0.8991 | it_auc/class_0=0.8991 | it_loss=0.0532 | loss=0.0343 | tr_auc/_mean=0.9803 | tr_auc/class_0=0.9803 | tr_loss=0.0120\n",
      "38/300 * Epoch 38 (valid_es): auc/_mean=0.9119 | auc/class_0=0.9119 | loss=0.0416\n",
      "38/300 * Epoch 38 (valid_it): auc/_mean=0.8991 | auc/class_0=0.8991 | loss=0.0532\n",
      "38/300 * Epoch 38 (valid_tr): auc/_mean=0.9803 | auc/class_0=0.9803 | loss=0.0120\n",
      "39/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=8.619e-04]\n",
      "39/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.24it/s, loss=0.032]\n",
      "39/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.30it/s, loss=0.055]\n",
      "39/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.98it/s, loss=0.051]\n",
      "39/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.26it/s, loss=0.011]   \n",
      "[2020-05-04 15:32:06,469] \n",
      "39/300 * Epoch 39 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "39/300 * Epoch 39 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0056\n",
      "39/300 * Epoch 39 (valid): auc/_mean=0.9346 | auc/class_0=0.9346 | es_auc/_mean=0.9155 | es_auc/class_0=0.9155 | es_loss=0.0410 | it_auc/_mean=0.9043 | it_auc/class_0=0.9043 | it_loss=0.0528 | loss=0.0342 | tr_auc/_mean=0.9807 | tr_auc/class_0=0.9807 | tr_loss=0.0116\n",
      "39/300 * Epoch 39 (valid_es): auc/_mean=0.9155 | auc/class_0=0.9155 | loss=0.0410\n",
      "39/300 * Epoch 39 (valid_it): auc/_mean=0.9043 | auc/class_0=0.9043 | loss=0.0528\n",
      "39/300 * Epoch 39 (valid_tr): auc/_mean=0.9807 | auc/class_0=0.9807 | loss=0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=8.763e-04]\n",
      "40/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.24it/s, loss=0.033]\n",
      "40/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.97it/s, loss=0.053]\n",
      "40/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.60it/s, loss=0.048]\n",
      "40/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.03it/s, loss=0.012]\n",
      "[2020-05-04 15:34:06,394] \n",
      "40/300 * Epoch 40 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "40/300 * Epoch 40 (train): auc/_mean=0.9966 | auc/class_0=0.9966 | loss=0.0054\n",
      "40/300 * Epoch 40 (valid): auc/_mean=0.9347 | auc/class_0=0.9347 | es_auc/_mean=0.9144 | es_auc/class_0=0.9144 | es_loss=0.0415 | it_auc/_mean=0.9001 | it_auc/class_0=0.9001 | it_loss=0.0527 | loss=0.0347 | tr_auc/_mean=0.9799 | tr_auc/class_0=0.9799 | tr_loss=0.0116\n",
      "40/300 * Epoch 40 (valid_es): auc/_mean=0.9144 | auc/class_0=0.9144 | loss=0.0415\n",
      "40/300 * Epoch 40 (valid_it): auc/_mean=0.9001 | auc/class_0=0.9001 | loss=0.0527\n",
      "40/300 * Epoch 40 (valid_tr): auc/_mean=0.9799 | auc/class_0=0.9799 | loss=0.0116\n",
      "41/300 * Epoch (train):  46% 123/268 [00:20<00:23,  6.06it/s, loss=0.006]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "41/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.03it/s, loss=5.588e-04]\n",
      "41/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.40it/s, loss=0.029]\n",
      "41/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.39it/s, loss=0.056]\n",
      "41/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.89it/s, loss=0.047]\n",
      "41/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.30it/s, loss=0.009]\n",
      "[2020-05-04 15:35:52,901] \n",
      "41/300 * Epoch 41 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "41/300 * Epoch 41 (train): auc/_mean=0.9971 | auc/class_0=0.9971 | loss=0.0051\n",
      "41/300 * Epoch 41 (valid): auc/_mean=0.9351 | auc/class_0=0.9351 | es_auc/_mean=0.9108 | es_auc/class_0=0.9108 | es_loss=0.0417 | it_auc/_mean=0.9094 | it_auc/class_0=0.9094 | it_loss=0.0519 | loss=0.0341 | tr_auc/_mean=0.9803 | tr_auc/class_0=0.9803 | tr_loss=0.0118\n",
      "41/300 * Epoch 41 (valid_es): auc/_mean=0.9108 | auc/class_0=0.9108 | loss=0.0417\n",
      "41/300 * Epoch 41 (valid_it): auc/_mean=0.9094 | auc/class_0=0.9094 | loss=0.0519\n",
      "41/300 * Epoch 41 (valid_tr): auc/_mean=0.9803 | auc/class_0=0.9803 | loss=0.0118\n",
      "42/300 * Epoch (train):  44% 118/268 [00:19<00:24,  6.07it/s, loss=0.003]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "42/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=0.001]    \n",
      "42/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.32it/s, loss=0.031]\n",
      "42/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.00it/s, loss=0.056]\n",
      "42/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.91it/s, loss=0.047]\n",
      "42/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.11it/s, loss=0.012]\n",
      "[2020-05-04 15:37:41,316] \n",
      "42/300 * Epoch 42 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "42/300 * Epoch 42 (train): auc/_mean=0.9972 | auc/class_0=0.9972 | loss=0.0050\n",
      "42/300 * Epoch 42 (valid): auc/_mean=0.9335 | auc/class_0=0.9335 | es_auc/_mean=0.9147 | es_auc/class_0=0.9147 | es_loss=0.0427 | it_auc/_mean=0.9081 | it_auc/class_0=0.9081 | it_loss=0.0528 | loss=0.0352 | tr_auc/_mean=0.9812 | tr_auc/class_0=0.9812 | tr_loss=0.0114\n",
      "42/300 * Epoch 42 (valid_es): auc/_mean=0.9147 | auc/class_0=0.9147 | loss=0.0427\n",
      "42/300 * Epoch 42 (valid_it): auc/_mean=0.9081 | auc/class_0=0.9081 | loss=0.0528\n",
      "42/300 * Epoch 42 (valid_tr): auc/_mean=0.9812 | auc/class_0=0.9812 | loss=0.0114\n",
      "43/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.01it/s, loss=3.517e-04]\n",
      "43/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.40it/s, loss=0.032]\n",
      "43/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.28it/s, loss=0.055]\n",
      "43/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 13.07it/s, loss=0.048]\n",
      "43/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.09it/s, loss=0.009]   \n",
      "[2020-05-04 15:39:28,464] \n",
      "43/300 * Epoch 43 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "43/300 * Epoch 43 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0054\n",
      "43/300 * Epoch 43 (valid): auc/_mean=0.9339 | auc/class_0=0.9339 | es_auc/_mean=0.9045 | es_auc/class_0=0.9045 | es_loss=0.0427 | it_auc/_mean=0.8992 | it_auc/class_0=0.8992 | it_loss=0.0564 | loss=0.0343 | tr_auc/_mean=0.9804 | tr_auc/class_0=0.9804 | tr_loss=0.0118\n",
      "43/300 * Epoch 43 (valid_es): auc/_mean=0.9045 | auc/class_0=0.9045 | loss=0.0427\n",
      "43/300 * Epoch 43 (valid_it): auc/_mean=0.8992 | auc/class_0=0.8992 | loss=0.0564\n",
      "43/300 * Epoch 43 (valid_tr): auc/_mean=0.9804 | auc/class_0=0.9804 | loss=0.0118\n",
      "44/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.01it/s, loss=5.503e-04]\n",
      "44/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.35it/s, loss=0.029]\n",
      "44/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.24it/s, loss=0.054]\n",
      "44/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.78it/s, loss=0.058]\n",
      "44/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.24it/s, loss=0.013]\n",
      "[2020-05-04 15:41:13,107] \n",
      "44/300 * Epoch 44 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "44/300 * Epoch 44 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0054\n",
      "44/300 * Epoch 44 (valid): auc/_mean=0.9357 | auc/class_0=0.9357 | es_auc/_mean=0.9184 | es_auc/class_0=0.9184 | es_loss=0.0413 | it_auc/_mean=0.8945 | it_auc/class_0=0.8945 | it_loss=0.0556 | loss=0.0340 | tr_auc/_mean=0.9813 | tr_auc/class_0=0.9813 | tr_loss=0.0110\n",
      "44/300 * Epoch 44 (valid_es): auc/_mean=0.9184 | auc/class_0=0.9184 | loss=0.0413\n",
      "44/300 * Epoch 44 (valid_it): auc/_mean=0.8945 | auc/class_0=0.8945 | loss=0.0556\n",
      "44/300 * Epoch 44 (valid_tr): auc/_mean=0.9813 | auc/class_0=0.9813 | loss=0.0110\n",
      "45/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.01it/s, loss=6.457e-04]\n",
      "45/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.39it/s, loss=0.033]\n",
      "45/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.86it/s, loss=0.056]\n",
      "45/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.86it/s, loss=0.043]\n",
      "45/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.05it/s, loss=0.014]   \n",
      "[2020-05-04 15:43:04,691] \n",
      "45/300 * Epoch 45 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "45/300 * Epoch 45 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0055\n",
      "45/300 * Epoch 45 (valid): auc/_mean=0.9378 | auc/class_0=0.9378 | es_auc/_mean=0.9117 | es_auc/class_0=0.9117 | es_loss=0.0411 | it_auc/_mean=0.9031 | it_auc/class_0=0.9031 | it_loss=0.0541 | loss=0.0338 | tr_auc/_mean=0.9802 | tr_auc/class_0=0.9802 | tr_loss=0.0119\n",
      "45/300 * Epoch 45 (valid_es): auc/_mean=0.9117 | auc/class_0=0.9117 | loss=0.0411\n",
      "45/300 * Epoch 45 (valid_it): auc/_mean=0.9031 | auc/class_0=0.9031 | loss=0.0541\n",
      "45/300 * Epoch 45 (valid_tr): auc/_mean=0.9802 | auc/class_0=0.9802 | loss=0.0119\n",
      "46/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.04it/s, loss=0.001]    \n",
      "46/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.43it/s, loss=0.029]\n",
      "46/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.40it/s, loss=0.053]\n",
      "46/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.99it/s, loss=0.050]\n",
      "46/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.38it/s, loss=0.013]   \n",
      "[2020-05-04 15:45:39,310] \n",
      "46/300 * Epoch 46 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "46/300 * Epoch 46 (train): auc/_mean=0.9968 | auc/class_0=0.9968 | loss=0.0053\n",
      "46/300 * Epoch 46 (valid): auc/_mean=0.9367 | auc/class_0=0.9367 | es_auc/_mean=0.9176 | es_auc/class_0=0.9176 | es_loss=0.0409 | it_auc/_mean=0.8990 | it_auc/class_0=0.8990 | it_loss=0.0562 | loss=0.0342 | tr_auc/_mean=0.9811 | tr_auc/class_0=0.9811 | tr_loss=0.0115\n",
      "46/300 * Epoch 46 (valid_es): auc/_mean=0.9176 | auc/class_0=0.9176 | loss=0.0409\n",
      "46/300 * Epoch 46 (valid_it): auc/_mean=0.8990 | auc/class_0=0.8990 | loss=0.0562\n",
      "46/300 * Epoch 46 (valid_tr): auc/_mean=0.9811 | auc/class_0=0.9811 | loss=0.0115\n",
      "47/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.01it/s, loss=6.768e-04]\n",
      "47/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.27it/s, loss=0.034]\n",
      "47/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.25it/s, loss=0.054]\n",
      "47/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.75it/s, loss=0.052]\n",
      "47/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.32it/s, loss=0.016]   \n",
      "[2020-05-04 15:47:27,329] \n",
      "47/300 * Epoch 47 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "47/300 * Epoch 47 (train): auc/_mean=0.9971 | auc/class_0=0.9971 | loss=0.0051\n",
      "47/300 * Epoch 47 (valid): auc/_mean=0.9340 | auc/class_0=0.9340 | es_auc/_mean=0.9059 | es_auc/class_0=0.9059 | es_loss=0.0422 | it_auc/_mean=0.9017 | it_auc/class_0=0.9017 | it_loss=0.0552 | loss=0.0343 | tr_auc/_mean=0.9818 | tr_auc/class_0=0.9818 | tr_loss=0.0107\n",
      "47/300 * Epoch 47 (valid_es): auc/_mean=0.9059 | auc/class_0=0.9059 | loss=0.0422\n",
      "47/300 * Epoch 47 (valid_it): auc/_mean=0.9017 | auc/class_0=0.9017 | loss=0.0552\n",
      "47/300 * Epoch 47 (valid_tr): auc/_mean=0.9818 | auc/class_0=0.9818 | loss=0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=4.227e-04]\n",
      "48/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.41it/s, loss=0.029]\n",
      "48/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.38it/s, loss=0.053]\n",
      "48/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.87it/s, loss=0.047]\n",
      "48/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.22it/s, loss=0.014]\n",
      "[2020-05-04 15:49:11,112] \n",
      "48/300 * Epoch 48 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "48/300 * Epoch 48 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0054\n",
      "48/300 * Epoch 48 (valid): auc/_mean=0.9374 | auc/class_0=0.9374 | es_auc/_mean=0.9076 | es_auc/class_0=0.9076 | es_loss=0.0442 | it_auc/_mean=0.8993 | it_auc/class_0=0.8993 | it_loss=0.0560 | loss=0.0335 | tr_auc/_mean=0.9784 | tr_auc/class_0=0.9784 | tr_loss=0.0120\n",
      "48/300 * Epoch 48 (valid_es): auc/_mean=0.9076 | auc/class_0=0.9076 | loss=0.0442\n",
      "48/300 * Epoch 48 (valid_it): auc/_mean=0.8993 | auc/class_0=0.8993 | loss=0.0560\n",
      "48/300 * Epoch 48 (valid_tr): auc/_mean=0.9784 | auc/class_0=0.9784 | loss=0.0120\n",
      "49/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.03it/s, loss=1.764e-04]\n",
      "49/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.40it/s, loss=0.030]\n",
      "49/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.09it/s, loss=0.056]\n",
      "49/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.84it/s, loss=0.049]\n",
      "49/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.35it/s, loss=0.015]\n",
      "[2020-05-04 15:51:02,808] \n",
      "49/300 * Epoch 49 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "49/300 * Epoch 49 (train): auc/_mean=0.9967 | auc/class_0=0.9967 | loss=0.0054\n",
      "49/300 * Epoch 49 (valid): auc/_mean=0.9352 | auc/class_0=0.9352 | es_auc/_mean=0.9064 | es_auc/class_0=0.9064 | es_loss=0.0421 | it_auc/_mean=0.9119 | it_auc/class_0=0.9119 | it_loss=0.0517 | loss=0.0339 | tr_auc/_mean=0.9798 | tr_auc/class_0=0.9798 | tr_loss=0.0120\n",
      "49/300 * Epoch 49 (valid_es): auc/_mean=0.9064 | auc/class_0=0.9064 | loss=0.0421\n",
      "49/300 * Epoch 49 (valid_it): auc/_mean=0.9119 | auc/class_0=0.9119 | loss=0.0517\n",
      "49/300 * Epoch 49 (valid_tr): auc/_mean=0.9798 | auc/class_0=0.9798 | loss=0.0120\n",
      "50/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.00it/s, loss=5.249e-04]\n",
      "50/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.78it/s, loss=0.030]\n",
      "50/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.60it/s, loss=0.054]\n",
      "50/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.75it/s, loss=0.046]\n",
      "50/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.33it/s, loss=0.014]   \n",
      "[2020-05-04 15:52:48,314] \n",
      "50/300 * Epoch 50 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "50/300 * Epoch 50 (train): auc/_mean=0.9971 | auc/class_0=0.9971 | loss=0.0050\n",
      "50/300 * Epoch 50 (valid): auc/_mean=0.9357 | auc/class_0=0.9357 | es_auc/_mean=0.9137 | es_auc/class_0=0.9137 | es_loss=0.0420 | it_auc/_mean=0.9038 | it_auc/class_0=0.9038 | it_loss=0.0534 | loss=0.0348 | tr_auc/_mean=0.9800 | tr_auc/class_0=0.9800 | tr_loss=0.0119\n",
      "50/300 * Epoch 50 (valid_es): auc/_mean=0.9137 | auc/class_0=0.9137 | loss=0.0420\n",
      "50/300 * Epoch 50 (valid_it): auc/_mean=0.9038 | auc/class_0=0.9038 | loss=0.0534\n",
      "50/300 * Epoch 50 (valid_tr): auc/_mean=0.9800 | auc/class_0=0.9800 | loss=0.0119\n",
      "51/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=0.004]    \n",
      "51/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.16it/s, loss=0.031]\n",
      "51/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.06it/s, loss=0.053]\n",
      "51/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.79it/s, loss=0.050]\n",
      "51/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.28it/s, loss=0.012]   \n",
      "[2020-05-04 15:54:35,376] \n",
      "51/300 * Epoch 51 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "51/300 * Epoch 51 (train): auc/_mean=0.9968 | auc/class_0=0.9968 | loss=0.0053\n",
      "51/300 * Epoch 51 (valid): auc/_mean=0.9403 | auc/class_0=0.9403 | es_auc/_mean=0.9076 | es_auc/class_0=0.9076 | es_loss=0.0428 | it_auc/_mean=0.8986 | it_auc/class_0=0.8986 | it_loss=0.0533 | loss=0.0328 | tr_auc/_mean=0.9815 | tr_auc/class_0=0.9815 | tr_loss=0.0114\n",
      "51/300 * Epoch 51 (valid_es): auc/_mean=0.9076 | auc/class_0=0.9076 | loss=0.0428\n",
      "51/300 * Epoch 51 (valid_it): auc/_mean=0.8986 | auc/class_0=0.8986 | loss=0.0533\n",
      "51/300 * Epoch 51 (valid_tr): auc/_mean=0.9815 | auc/class_0=0.9815 | loss=0.0114\n",
      "52/300 * Epoch (train): 100% 268/268 [00:44<00:00,  6.02it/s, loss=3.117e-04]\n",
      "52/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.09it/s, loss=0.030]\n",
      "52/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 13.03it/s, loss=0.054]\n",
      "52/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.87it/s, loss=0.046]\n",
      "52/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.31it/s, loss=0.012]\n",
      "[2020-05-04 15:57:09,323] \n",
      "52/300 * Epoch 52 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "52/300 * Epoch 52 (train): auc/_mean=0.9965 | auc/class_0=0.9965 | loss=0.0054\n",
      "52/300 * Epoch 52 (valid): auc/_mean=0.9349 | auc/class_0=0.9349 | es_auc/_mean=0.9153 | es_auc/class_0=0.9153 | es_loss=0.0416 | it_auc/_mean=0.9022 | it_auc/class_0=0.9022 | it_loss=0.0528 | loss=0.0348 | tr_auc/_mean=0.9781 | tr_auc/class_0=0.9781 | tr_loss=0.0126\n",
      "52/300 * Epoch 52 (valid_es): auc/_mean=0.9153 | auc/class_0=0.9153 | loss=0.0416\n",
      "52/300 * Epoch 52 (valid_it): auc/_mean=0.9022 | auc/class_0=0.9022 | loss=0.0528\n",
      "52/300 * Epoch 52 (valid_tr): auc/_mean=0.9781 | auc/class_0=0.9781 | loss=0.0126\n",
      "53/300 * Epoch (train): 100% 268/268 [00:44<00:00,  5.99it/s, loss=6.348e-04]\n",
      "53/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 15.31it/s, loss=0.030]\n",
      "53/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.96it/s, loss=0.053]\n",
      "53/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.87it/s, loss=0.052]\n",
      "53/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 13.01it/s, loss=0.013]   \n",
      "[2020-05-04 15:59:04,601] \n",
      "53/300 * Epoch 53 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "53/300 * Epoch 53 (train): auc/_mean=0.9970 | auc/class_0=0.9970 | loss=0.0052\n",
      "53/300 * Epoch 53 (valid): auc/_mean=0.9382 | auc/class_0=0.9382 | es_auc/_mean=0.9139 | es_auc/class_0=0.9139 | es_loss=0.0433 | it_auc/_mean=0.9141 | it_auc/class_0=0.9141 | it_loss=0.0525 | loss=0.0335 | tr_auc/_mean=0.9831 | tr_auc/class_0=0.9831 | tr_loss=0.0105\n",
      "53/300 * Epoch 53 (valid_es): auc/_mean=0.9139 | auc/class_0=0.9139 | loss=0.0433\n",
      "53/300 * Epoch 53 (valid_it): auc/_mean=0.9141 | auc/class_0=0.9141 | loss=0.0525\n",
      "53/300 * Epoch 53 (valid_tr): auc/_mean=0.9831 | auc/class_0=0.9831 | loss=0.0105\n",
      "54/300 * Epoch (train):  24% 63/268 [00:10<00:34,  5.97it/s, loss=0.015]    Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "54/300 * Epoch (train): 100% 268/268 [00:45<00:00,  5.90it/s, loss=8.182e-04]\n",
      "54/300 * Epoch (valid): 100% 50/50 [00:03<00:00, 14.83it/s, loss=0.031]\n",
      "54/300 * Epoch (valid_es): 100% 16/16 [00:01<00:00, 12.47it/s, loss=0.053]\n",
      "54/300 * Epoch (valid_it): 100% 16/16 [00:01<00:00, 12.30it/s, loss=0.052]\n",
      "54/300 * Epoch (valid_tr): 100% 19/19 [00:01<00:00, 12.71it/s, loss=0.015]\n",
      "[2020-05-04 16:00:57,429] \n",
      "54/300 * Epoch 54 (_base): lr=3.906e-09 | momentum=0.9000\n",
      "54/300 * Epoch 54 (train): auc/_mean=0.9968 | auc/class_0=0.9968 | loss=0.0053\n",
      "54/300 * Epoch 54 (valid): auc/_mean=0.9367 | auc/class_0=0.9367 | es_auc/_mean=0.9085 | es_auc/class_0=0.9085 | es_loss=0.0425 | it_auc/_mean=0.8987 | it_auc/class_0=0.8987 | it_loss=0.0556 | loss=0.0348 | tr_auc/_mean=0.9790 | tr_auc/class_0=0.9790 | tr_loss=0.0117\n",
      "54/300 * Epoch 54 (valid_es): auc/_mean=0.9085 | auc/class_0=0.9085 | loss=0.0425\n",
      "54/300 * Epoch 54 (valid_it): auc/_mean=0.8987 | auc/class_0=0.8987 | loss=0.0556\n",
      "54/300 * Epoch 54 (valid_tr): auc/_mean=0.9790 | auc/class_0=0.9790 | loss=0.0117\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/callbacks/checkpoint.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mmain_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mminimize_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         )\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/callbacks/checkpoint.py\u001b[0m in \u001b[0;36mprocess_checkpoint\u001b[0;34m(self, logdir, checkpoint, is_best, main_metric, minimize_metric)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mis_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         )\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/utils/checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(checkpoint, logdir, suffix, is_best, is_last, special_suffix)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{logdir}/last{special_suffix}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3942d1f8057b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m     ],\n\u001b[1;32m     90\u001b[0m     \u001b[0mmain_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auc/_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mminimize_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m#fp16={\"opt_level\": \"O1\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/dl/runner/core.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, distributed, monitoring_params, check, timeit)\u001b[0m\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     ):\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    508\u001b[0m             ):\n\u001b[1;32m    509\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \"\"\"\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     def _batch2device(\n",
      "\u001b[0;32m~/jig_env/lib/python3.7/site-packages/catalyst/core/callbacks/logging.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Early exiting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_exception_reraise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "def freeze_until(net, param_name):\n",
    "    found_name = False\n",
    "    for name, params in net.named_parameters():\n",
    "        if name == param_name:\n",
    "            found_name = True\n",
    "        params.requires_grad = found_name\n",
    "        \n",
    "# param_name = 'bert_model.encoder.layer.10.attention.self.query.weight'\n",
    "param_name = 'bert_model.encoder.layer.10.attention.self.query.weight'\n",
    "\n",
    "CHECKPOINT = './checkpoints/v93_xlm_roberta_large_ml96/best.pth'\n",
    "\n",
    "project = \"js_v935_xlmrbtlg_10fr_pseudo\"\n",
    "num_epochs = 300\n",
    "\n",
    "group = datetime.now().strftime(\"%m_%d_%Y__%H_%M_%S\")\n",
    "\n",
    "    \n",
    "if SERVER:\n",
    "    group = f'{group}_server'\n",
    "    \n",
    "if STRIDE > 1:\n",
    "    group = f'{group}_str{STRIDE}'\n",
    "\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "lr = 1e-6#1e-5#0.0001\n",
    "group += f'_lr{lr}_pseudo_train'\n",
    "\n",
    "group = group.replace('.', '')\n",
    "\n",
    "runner = SupervisedRunner(input_key=('features'), input_target_key=('targets'), output_key=('logits'))\n",
    "\n",
    "experiment = 'simple'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "logdir = f\"{LOG_PATH}/{project}/{group}/{experiment}\"\n",
    "\n",
    "model = QuestModel(2)\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT)#, map_location=device)   \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "del checkpoint\n",
    "\n",
    "freeze_until(model, param_name)\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "loaders = get_loaders(to_balance=True)\n",
    "\n",
    "\n",
    "t_total = len(loaders['train'])//gradient_accumulation_steps*num_epochs\n",
    "warmup_proportion = 0.01\n",
    "num_warmup_steps = t_total * warmup_proportion\n",
    "\n",
    "#     criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(alpha=0.2, gamma=1.5, logits=True, reduce=True)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "#     criterion = torch.nn.BCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr = lr)\n",
    "#    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.25)\n",
    "print(f'----------------Experiment: {experiment}')\n",
    "\n",
    "runner.train(\n",
    "    fp16=dict(opt_level=\"O2\") ,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=True,\n",
    "    distributed=False if is_jupyter() else True,\n",
    "    callbacks=[\n",
    "        AlchemyLogger(\n",
    "                token=token, # your Alchemy token\n",
    "                project=project,\n",
    "                experiment=experiment,\n",
    "                group=group,\n",
    "            ),\n",
    "        MyAUCCallback()\n",
    "\n",
    "    ],\n",
    "    main_metric='auc/_mean',\n",
    "    minimize_metric=False,\n",
    "    \n",
    "    #fp16={\"opt_level\": \"O1\"}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, params in model.named_parameters():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in df_train.iterrows():\n",
    "#     print(list(row.keys().values))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = '/media/ssd/logs/jigsaw/js_v935_xlmrbtlg_10fr_pseudo/05_04_2020__14_16_58_lr1e-06_pseudo_train/simple/checkpoints/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuestModel(2)\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT)#, map_location=device)   \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv').rename(columns={'content':'comment_text'})\n",
    "ds = QuestDataset(df_test, train_mode=False, labeled=False)\n",
    "loader = DataLoader(\n",
    "        ds,\n",
    "        num_workers=8,\n",
    "        batch_size=batch_size,\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text lang\n",
       "0   0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n",
       "1   1   Вполне возможно, но я пока не вижу необходимо...   ru\n",
       "2   2  Quindi tu sei uno di quelli   conservativi  , ...   it\n",
       "3   3  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr\n",
       "4   4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1995/1995 [06:00<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.zeros( len(ds), 2).to(device)\n",
    "\n",
    "j = 0\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(loader):\n",
    "        x = data['features'].to(device)\n",
    "        thish_batch_size = len(x)            \n",
    "        \n",
    "        \n",
    "        y_pred[j:j+thish_batch_size] = model(x)\n",
    "            \n",
    "        j += thish_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "y_pred_sigmoid = sigmoid(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sigmoid_one_np = y_pred_sigmoid.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['toxic'] = y_pred_sigmoid_one_np[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.117173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.701799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.073349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.037452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63807</th>\n",
       "      <td>63807</td>\n",
       "      <td>0.555552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63808</th>\n",
       "      <td>63808</td>\n",
       "      <td>0.020980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63809</th>\n",
       "      <td>63809</td>\n",
       "      <td>0.310008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63810</th>\n",
       "      <td>63810</td>\n",
       "      <td>0.042928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63811</th>\n",
       "      <td>63811</td>\n",
       "      <td>0.021307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63812 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     toxic\n",
       "0          0  0.043959\n",
       "1          1  0.117173\n",
       "2          2  0.701799\n",
       "3          3  0.073349\n",
       "4          4  0.037452\n",
       "...      ...       ...\n",
       "63807  63807  0.555552\n",
       "63808  63808  0.020980\n",
       "63809  63809  0.310008\n",
       "63810  63810  0.042928\n",
       "63811  63811  0.021307\n",
       "\n",
       "[63812 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jig_env",
   "language": "python",
   "name": "jig_env"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "086421f7eec44c769f08f5f68fafafdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e7c81c0da784e04b530236bad005c33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18b951cd8c1447eaa1e12f972ac37d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  9%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e743ecd26cd4877a539f9bbbd23d114",
       "max": 308,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e34fafda1e234d9c981322beff1068e7",
       "value": 29
      }
     },
     "35645b239e914aee807cfdc234fc5b75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfdee9b109bc4176a0bc3a26ae38f7a3",
       "placeholder": "​",
       "style": "IPY_MODEL_086421f7eec44c769f08f5f68fafafdc",
       "value": " 29/308 [7:12:46&lt;66:18:40, 855.63s/it]"
      }
     },
     "554271f3ed5d48efa844608a0b72fdac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "685ecca481e3463d83a2465f15f7b33f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80ae0d356c3e4b1bbe511c5f5a2694b5",
       "max": 4059,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a34804b28be74d7c9972a0a13410ba77",
       "value": 4059
      }
     },
     "7f49d7d685554687bc2d131959058cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80ae0d356c3e4b1bbe511c5f5a2694b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "840e74b11eb44a58b1ed0433e924dc82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e743ecd26cd4877a539f9bbbd23d114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a34804b28be74d7c9972a0a13410ba77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a61c8f56dbd74e29a155fad0d7095f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_18b951cd8c1447eaa1e12f972ac37d42",
        "IPY_MODEL_35645b239e914aee807cfdc234fc5b75"
       ],
       "layout": "IPY_MODEL_7f49d7d685554687bc2d131959058cb3"
      }
     },
     "c9ab84b07a32426282543b5ff054ddec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_840e74b11eb44a58b1ed0433e924dc82",
       "placeholder": "​",
       "style": "IPY_MODEL_554271f3ed5d48efa844608a0b72fdac",
       "value": " 4059/4059 [14:53&lt;00:00,  4.54it/s]"
      }
     },
     "dfdee9b109bc4176a0bc3a26ae38f7a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e34fafda1e234d9c981322beff1068e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fd692cff30e343aa8afa007a05d66acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_685ecca481e3463d83a2465f15f7b33f",
        "IPY_MODEL_c9ab84b07a32426282543b5ff054ddec"
       ],
       "layout": "IPY_MODEL_0e7c81c0da784e04b530236bad005c33"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
